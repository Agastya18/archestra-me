<!DOCTYPE html>
<!-- saved from url=(0109)https://levelup.gitconnected.com/how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="origin-trial" content="A7vZI3v+Gz7JfuRolKNM4Aff6zaGuT7X0mf3wtoZTnKv6497cVMnhy03KDqX7kBz/q/iidW7srW31oQbBt4VhgoAAACUeyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGUuY29tOjQ0MyIsImZlYXR1cmUiOiJEaXNhYmxlVGhpcmRQYXJ0eVN0b3JhZ2VQYXJ0aXRpb25pbmczIiwiZXhwaXJ5IjoxNzU3OTgwODAwLCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><title>How I Built a Tool-Calling Llama Agent with a Custom MCP Server | by Hyunjong Lee | May, 2025 | Level Up Coding</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" name="apple-itunes-app" content="app-id=828256236, app-argument=/how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85, affiliate-data=pt=698524&amp;ct=smart_app_banner&amp;mt=8"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-05-19T02:46:02.217Z"><meta data-rh="true" name="title" content="How I Built a Tool-Calling Llama Agent with a Custom MCP Server | by Hyunjong Lee | May, 2025 | Level Up Coding"><meta data-rh="true" property="og:title" content="How I Built a Tool-Calling Llama Agent with a Custom MCP Server"><meta data-rh="true" property="al:android:url" content="medium://p/3bc057d27e85"><meta data-rh="true" property="al:ios:url" content="medium://p/3bc057d27e85"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Learn how to build a local tool-calling LLM agent using Llama 3.2 and a custom MCP server that connects to your personal knowledge base in Obsidian."><meta data-rh="true" property="og:description" content="Integrating sLLMs, tool-calling, and custom context retrieval via a private MCP server"><meta data-rh="true" property="og:url" content="https://levelup.gitconnected.com/how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85"><meta data-rh="true" property="al:web:url" content="https://levelup.gitconnected.com/how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1200/1*atue7XX9h3JTZxhJQuGyxg.png"><meta data-rh="true" property="article:author" content="https://medium.com/@infin94"><meta data-rh="true" name="author" content="Hyunjong Lee"><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="How I Built a Tool-Calling Llama Agent with a Custom MCP Server"><meta data-rh="true" name="twitter:site" content="@gitconnected"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/3bc057d27e85"><meta data-rh="true" property="twitter:description" content="Integrating sLLMs, tool-calling, and custom context retrieval via a private MCP server"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1200/1*atue7XX9h3JTZxhJQuGyxg.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="22 min read"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*MMpkJtmeCME-6BmGNH5l8A.png"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://levelup.gitconnected.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"><link data-rh="true" rel="manifest" href="https://levelup.gitconnected.com/manifest.json"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@infin94"><link data-rh="true" rel="canonical" href="https://levelup.gitconnected.com/how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/3bc057d27e85"><script type="text/javascript" async="" charset="utf-8" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-8BePxg6Wh2fV0vTELhV40WIIkZzA8q6AbKptdf+cRazn9sNHQQTRJjigOcFB/dqA"></script><script async="" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/branch-latest.min.js"></script><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*atue7XX9h3JTZxhJQuGyxg.png"],"url":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85","dateCreated":"2025-05-19T02:46:02.217Z","datePublished":"2025-05-19T02:46:02.217Z","dateModified":"2025-05-20T02:26:28.948Z","headline":"How I Built a Tool-Calling Llama Agent with a Custom MCP Server","name":"How I Built a Tool-Calling Llama Agent with a Custom MCP Server","description":"Learn how to build a local tool-calling LLM agent using Llama 3.2 and a custom MCP server that connects to your personal knowledge base in Obsidian.","identifier":"3bc057d27e85","author":{"@type":"Person","name":"Hyunjong Lee","url":"https:\u002F\u002Flevelup.gitconnected.com\u002F@infin94"},"creator":["Hyunjong Lee"],"publisher":{"@type":"Organization","name":"Level Up Coding","url":"levelup.gitconnected.com","logo":{"@type":"ImageObject","width":272,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:544\u002F1*s0Iaylh9dPk6zGjlVZasIA.jpeg"}},"mainEntityOfPage":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85"}</script><style type="text/css" data-fela-rehydration="633" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="633" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@-moz-keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@keyframes k1{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.d{display:none}.m{display:block}.n{position:sticky}.o{top:0}.p{z-index:500}.q{padding:0 24px}.r{align-items:center}.s{border-bottom:solid 1px #F2F2F2}.z{height:41px}.ab{line-height:20px}.ac{display:flex}.ae{height:57px}.af{flex:1 0 auto}.ag{color:inherit}.ah{fill:inherit}.ai{font-size:inherit}.aj{border:none}.ak{font-family:inherit}.al{letter-spacing:inherit}.am{font-weight:inherit}.an{padding:0}.ao{margin:0}.ap{cursor:pointer}.aq:disabled{cursor:not-allowed}.ar:disabled{color:#6B6B6B}.as:disabled{fill:#6B6B6B}.av{width:auto}.aw path{fill:#242424}.ax{height:25px}.ay{margin-left:24px}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{flex:1 1 auto}.cb{justify-content:center}.ch{max-width:680px}.ci{min-width:0}.cj{animation:k1 1.2s ease-in-out infinite}.ck{height:100vh}.cl{margin-bottom:16px}.cm{margin-top:48px}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:space-between}.cq{margin-bottom:24px}.cw{width:80%}.cx{background-color:#F2F2F2}.dd{height:44px}.de{width:44px}.df{margin:auto 0}.dg{margin-bottom:4px}.dh{height:16px}.di{width:120px}.dj{width:80px}.dp{margin-bottom:8px}.dq{width:96%}.dr{width:98%}.ds{width:81%}.dt{margin-left:8px}.du{color:#6B6B6B}.dv{font-size:13px}.dw{height:100%}.ep{color:#FFFFFF}.eq{fill:#FFFFFF}.er{background:rgba(75, 132, 243, 1)}.es{border-color:rgba(75, 132, 243, 1)}.ew:disabled{cursor:inherit !important}.ex:disabled{opacity:0.3}.ey:disabled:hover{background:rgba(75, 132, 243, 1)}.ez:disabled:hover{border-color:rgba(75, 132, 243, 1)}.fa{border-radius:99em}.fb{border-width:1px}.fc{border-style:solid}.fd{box-sizing:border-box}.fe{text-decoration:none}.ff{text-align:center}.fg{margin-left:16px}.fh{border:inherit}.fk{margin-right:32px}.fl{position:relative}.fm{fill:#6B6B6B}.fp{background:transparent}.fq svg{margin-left:4px}.fr svg{fill:#6B6B6B}.ft{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fu{position:absolute}.fw{max-width:100%}.fx{overflow:hidden}.fy{text-overflow:ellipsis}.fz{white-space:nowrap}.ga{border-bottom:1px solid #F2F2F2}.gb{height:3px}.gc{background-color:rgba(75, 132, 243, 1)}.gd{max-width:1192px}.gj{font-weight:500}.gx{margin:0 8px}.gy{display:inline}.gz{font-size:16px}.ha{line-height:24px}.hb{text-decoration:underline}.hc{pointer-events:none}.hd{will-change:opacity, transform}.he{width:calc(100% - 0px)}.hh{opacity:0}.hi{transform:translateY(89px)}.hj{width:148px}.hk{border-radius:2px}.hl{height:38px}.hm{width:38px}.ho{margin-top:16px}.hp{word-wrap:break-word}.hq{word-break:break-word}.hw{margin:0 24px}.ia{background:rgba(255, 255, 255, 1)}.ib{border:1px solid #F2F2F2}.ic{box-shadow:0 1px 4px #F2F2F2}.id{max-height:100vh}.ie{overflow-y:auto}.if{left:0}.ig{top:calc(100vh + 100px)}.ih{bottom:calc(100vh + 100px)}.ii{width:10px}.ij:after{display:block}.ik:after{content:""}.il:after{clear:both}.im{line-height:1.23}.in{letter-spacing:0}.io{font-style:normal}.ip{font-weight:700}.jz{gap:12px}.ka{align-items:baseline}.kb{width:36px}.kc{height:36px}.kd{border:2px solid rgba(255, 255, 255, 1)}.ke{z-index:0}.kf{box-shadow:none}.kg{border:1px solid rgba(0, 0, 0, 0.05)}.kh{margin-bottom:2px}.ki{flex-wrap:nowrap}.kk{width:12px}.kl{flex-wrap:wrap}.km{padding-left:8px}.kn{padding-right:8px}.lo> *{flex-shrink:0}.lp{overflow-x:scroll}.lq::-webkit-scrollbar{display:none}.lr{scrollbar-width:none}.ls{-ms-overflow-style:none}.lt{width:74px}.lu{flex-direction:row}.lv{z-index:2}.lw{margin-right:4px}.lz{-webkit-user-select:none}.ma{border:0}.mb{fill:rgba(117, 117, 117, 1)}.me{outline:0}.mf{user-select:none}.mg> svg{pointer-events:none}.mp{cursor:progress}.mq{margin-left:4px}.mr{margin-top:0px}.ms{opacity:1}.mt{padding:4px 0}.mw{width:16px}.my{display:inline-flex}.ne{padding:8px 2px}.nf svg{color:#6B6B6B}.nw{margin-left:auto}.nx{margin-right:auto}.ny{max-width:1536px}.oe{clear:both}.og{cursor:zoom-in}.oh{z-index:auto}.oj{height:auto}.ok{margin-top:10px}.ol{max-width:728px}.oo{line-height:1.12}.op{letter-spacing:-0.022em}.oq{font-weight:600}.pj{margin-bottom:-0.28em}.pk{line-height:1.58}.pl{letter-spacing:-0.004em}.pm{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.qe{margin-bottom:-0.46em}.qk{list-style-type:disc}.ql{margin-left:30px}.qm{padding-left:0px}.qx{box-shadow:inset 0 0 0 1px #F2F2F2}.qy{padding:0px}.qz{flex:0 0 auto}.ra{padding:16px 20px}.rc{max-height:40px}.rd{display:-webkit-box}.re{-webkit-line-clamp:2}.rf{-webkit-box-orient:vertical}.rh{margin-top:8px}.ri{margin-top:12px}.rj{width:160px}.rk{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*ll8RQxFadewaqpiZ)}.rl{background-origin:border-box}.rm{background-size:cover}.rn{height:167px}.ro{background-position:50% 50%}.rp{line-height:1.18}.rv{margin-bottom:-0.31em}.rw{background-image:url(https://miro.medium.com/v2/resize:fit:320/1*53OcJXxL_p9yhhxD-jQ0Hw.png)}.rx{max-width:3840px}.sd{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*q2xQIQiK-PqOM16G)}.se{max-width:3304px}.sf{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*BbnA3BdmyA5ynjZq)}.sg{overflow-x:auto}.sh{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.si{padding:32px}.sj{border:1px solid #E5E5E5}.sk{line-height:1.4}.sl{margin-top:-0.2em}.sm{margin-bottom:-0.2em}.sn{white-space:pre}.so{min-width:fit-content}.sp{box-shadow:inset 3px 0 0 0 #242424}.sq{padding-left:23px}.sr{margin-left:-20px}.ss{font-style:italic}.st{max-width:840px}.su{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*8O6B5Rhy-tLsc9p7)}.sv{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*VKglBHUo4KfFBn89)}.sw{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*kEiDYW8QvG15UTOz)}.sx{max-width:1278px}.sy{list-style-type:decimal}.sz{max-width:3497px}.ta{max-width:1072px}.tb{max-width:1094px}.tc{max-width:1088px}.td{max-width:1116px}.te{max-width:1100px}.tf{max-width:1092px}.tg{margin-top:32px}.th{margin-bottom:14px}.ti{padding-top:24px}.tj{padding-bottom:10px}.tk{background-color:#000000}.tl{width:3px}.tm{margin-right:20px}.tn{margin-bottom:26px}.to{margin-top:6px}.tp{margin-right:8px}.tq{padding:8px 16px}.tr{border-radius:100px}.ts{transition:background 300ms ease}.tu{border-top:none}.tv{margin-bottom:50px}.tw{height:52px}.tx{max-height:52px}.ty{box-sizing:content-box}.tz{position:static}.ua{z-index:1}.uc{max-width:155px}.ui{margin-bottom:64px}.uj{margin-bottom:48px}.uw{height:48px}.ux{width:48px}.uy{height:64px}.uz{width:64px}.va{align-self:flex-end}.vg{padding-right:4px}.vn{white-space:pre-wrap}.vt{height:0px}.vu{gap:18px}.vv{fill:rgba(61, 61, 61, 1)}.vx{padding-bottom:20px}.wd{fill:#242424}.we{background:0}.wf{border-color:#242424}.wh:disabled:hover{color:#242424}.wi:disabled:hover{fill:#242424}.wj:disabled:hover{border-color:#242424}.wu{border-bottom:solid 1px #E5E5E5}.wv{margin-top:72px}.ww{padding:24px 0}.wx{margin-bottom:0px}.wy{margin-right:16px}.wz{background:#1A8917}.xa{border-color:#1A8917}.xd:disabled:hover{background:#1A8917}.xe:disabled:hover{border-color:#1A8917}.xf{background-color:#3972E0}.xg path{stroke:#242424}.xh{border-radius:19px}.xi{padding:9px 16px 9px 16px}.xj{word-break:keep-all}.at:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.au:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.et:hover{background:rgba(69, 114, 201, 1)}.eu:hover{border-color:rgba(69, 114, 201, 1)}.ev:hover{cursor:pointer}.fn:hover{color:#242424}.fo:hover{fill:#242424}.fs:hover svg{fill:#242424}.fv:hover{background-color:rgba(0, 0, 0, 0.1)}.hn:hover{background-color:none}.kj:hover{text-decoration:underline}.md:hover{fill:rgba(8, 8, 8, 1)}.mu:hover{fill:#000000}.mv:hover p{color:#000000}.mx:hover{color:#000000}.ng:hover svg{color:#000000}.tt:hover{background-color:#F2F2F2}.vw:hover{fill:rgba(25, 25, 25, 1)}.wg:hover{border-color:#242424}.xb:hover{background:#156D12}.xc:hover{border-color:#156D12}.bd:focus-within path{fill:#242424}.mc:focus{fill:rgba(8, 8, 8, 1)}.nh:focus svg{color:#000000}.oi:focus{transform:scale(1.01)}.mh:active{border-style:none}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (min-width: 1080px)">.e{display:none}.bv{width:64px}.cg{margin:0 64px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fj{display:flex}.gi{max-width:250px}.gu{font-size:20px}.gv{line-height:24px}.gw{letter-spacing:0}.hv{margin-bottom:50px}.hz{max-width:680px}.jk{font-size:42px}.jl{margin-top:1.19em}.jm{margin-bottom:32px}.jn{line-height:52px}.jo{letter-spacing:-0.011em}.jx{align-items:center}.jy{flex-direction:row}.la{border-top:solid 1px #F2F2F2}.lb{border-bottom:solid 1px #F2F2F2}.lc{margin:32px 0 0}.ld{padding:3px 8px}.lm> *{margin-right:24px}.ln> :last-child{margin-right:0}.mo{margin-top:0px}.nd{margin:0}.od{margin-top:40px}.pf{font-size:24px}.pg{margin-top:1.95em}.ph{line-height:30px}.pi{letter-spacing:-0.016em}.qb{margin-top:0.94em}.qc{line-height:32px}.qd{letter-spacing:-0.003em}.qj{margin-top:2.14em}.qr{margin-top:1.14em}.qw{margin-top:32px}.ru{margin-top:1.72em}.sc{margin-top:56px}.uh{display:inline-block}.um{margin-bottom:0}.un{margin-right:20px}.vb{max-width:500px}.vs{margin-bottom:88px}.wc{margin:40px 0 16px}.wo{width:min-width}.wt{padding-top:72px}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.f{display:none}.mn{margin-top:0px}.om{margin-left:auto}.on{text-align:center}.ug{display:inline-block}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (max-width: 903.98px)">.g{display:none}.mm{margin-top:0px}.uf{display:inline-block}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (max-width: 727.98px)">.h{display:none}.mk{margin-top:0px}.ml{margin-right:0px}.rb{padding:10px 12px 10px}.ue{display:inline-block}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (max-width: 551.98px)">.i{display:none}.t{display:flex}.u{justify-content:space-between}.br{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dx{font-size:13px}.dy{line-height:20px}.eh{padding:0px 8px 1px}.ge{max-width:150px}.gk{font-size:16px}.gl{letter-spacing:0}.hr{margin-bottom:2px}.iq{font-size:32px}.ir{margin-top:1.01em}.is{margin-bottom:24px}.it{line-height:38px}.iu{letter-spacing:-0.014em}.jp{align-items:flex-start}.jq{flex-direction:column-reverse}.ko{margin:24px -24px 0}.kp{padding:0}.le> *{margin-right:8px}.lf> :last-child{margin-right:24px}.lx{margin-left:0px}.mi{margin-top:0px}.mj{margin-right:0px}.mz{margin:0}.ni{border:1px solid #F2F2F2}.nj{border-radius:99em}.nk{padding:0px 16px 0px 12px}.nl{height:38px}.nm{align-items:center}.no svg{margin-right:8px}.nz{margin-top:32px}.or{font-size:20px}.os{margin-top:1.2em}.ot{line-height:24px}.pn{font-size:18px}.po{margin-top:0.67em}.pp{line-height:28px}.pq{letter-spacing:-0.003em}.qf{margin-top:1.56em}.qn{margin-top:1.34em}.qs{margin-top:24px}.rq{margin-top:1.23em}.ry{margin-top:40px}.ud{display:inline-block}.ul{flex-direction:column}.uu{margin-bottom:20px}.uv{margin-right:0}.vf{max-width:100%}.vh{font-size:24px}.vi{line-height:30px}.vj{letter-spacing:-0.016em}.vo{margin-bottom:64px}.vy{margin:32px 0 16px}.wk{width:100%}.wp{padding-top:48px}.nn:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.j{display:none}.bu{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ed{font-size:14px}.ee{line-height:20px}.ek{font-size:13px}.el{padding:5px 12px}.fi{display:flex}.gh{max-width:250px}.gr{font-size:20px}.gs{line-height:24px}.gt{letter-spacing:0}.hu{margin-bottom:50px}.hy{max-width:680px}.jf{font-size:42px}.jg{margin-top:1.19em}.jh{margin-bottom:32px}.ji{line-height:52px}.jj{letter-spacing:-0.011em}.jv{align-items:center}.jw{flex-direction:row}.kw{border-top:solid 1px #F2F2F2}.kx{border-bottom:solid 1px #F2F2F2}.ky{margin:32px 0 0}.kz{padding:3px 8px}.lk> *{margin-right:24px}.ll> :last-child{margin-right:0}.nc{margin:0}.oc{margin-top:40px}.pb{font-size:24px}.pc{margin-top:1.95em}.pd{line-height:30px}.pe{letter-spacing:-0.016em}.py{margin-top:0.94em}.pz{line-height:32px}.qa{letter-spacing:-0.003em}.qi{margin-top:2.14em}.qq{margin-top:1.14em}.qv{margin-top:32px}.rt{margin-top:1.72em}.sb{margin-top:56px}.uo{margin-bottom:0}.up{margin-right:20px}.vc{max-width:500px}.vr{margin-bottom:88px}.wb{margin:40px 0 16px}.wn{width:min-width}.ws{padding-top:72px}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.k{display:none}.x{display:flex}.y{justify-content:space-between}.bt{width:64px}.ce{margin:0 48px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{font-size:13px}.ec{line-height:20px}.ej{padding:0px 8px 1px}.gg{max-width:250px}.go{font-size:20px}.gp{line-height:24px}.gq{letter-spacing:0}.ht{margin-bottom:50px}.hx{max-width:680px}.ja{font-size:42px}.jb{margin-top:1.19em}.jc{margin-bottom:32px}.jd{line-height:52px}.je{letter-spacing:-0.011em}.jt{align-items:center}.ju{flex-direction:row}.ks{border-top:solid 1px #F2F2F2}.kt{border-bottom:solid 1px #F2F2F2}.ku{margin:32px 0 0}.kv{padding:3px 8px}.li> *{margin-right:24px}.lj> :last-child{margin-right:0}.nb{margin:0}.ob{margin-top:40px}.ox{font-size:24px}.oy{margin-top:1.95em}.oz{line-height:30px}.pa{letter-spacing:-0.016em}.pv{margin-top:0.94em}.pw{line-height:32px}.px{letter-spacing:-0.003em}.qh{margin-top:2.14em}.qp{margin-top:1.14em}.qu{margin-top:32px}.rs{margin-top:1.72em}.sa{margin-top:56px}.uq{margin-bottom:0}.ur{margin-right:20px}.vd{max-width:500px}.vq{margin-bottom:88px}.wa{margin:40px 0 16px}.wm{width:min-width}.wr{padding-top:72px}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.l{display:none}.v{display:flex}.w{justify-content:space-between}.bs{width:24px}.cd{margin:0 24px}.cs{height:40px}.cz{margin-bottom:44px}.dl{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ei{padding:0px 8px 1px}.gf{max-width:150px}.gm{font-size:16px}.gn{letter-spacing:0}.hs{margin-bottom:2px}.iv{font-size:32px}.iw{margin-top:1.01em}.ix{margin-bottom:24px}.iy{line-height:38px}.iz{letter-spacing:-0.014em}.jr{align-items:flex-start}.js{flex-direction:column-reverse}.kq{margin:24px 0 0}.kr{padding:0}.lg> *{margin-right:8px}.lh> :last-child{margin-right:8px}.ly{margin-left:0px}.na{margin:0}.np{border:1px solid #F2F2F2}.nq{border-radius:99em}.nr{padding:0px 16px 0px 12px}.ns{height:38px}.nt{align-items:center}.nv svg{margin-right:8px}.oa{margin-top:32px}.ou{font-size:20px}.ov{margin-top:1.2em}.ow{line-height:24px}.pr{font-size:18px}.ps{margin-top:0.67em}.pt{line-height:28px}.pu{letter-spacing:-0.003em}.qg{margin-top:1.56em}.qo{margin-top:1.34em}.qt{margin-top:24px}.rr{margin-top:1.23em}.rz{margin-top:40px}.uk{flex-direction:column}.us{margin-bottom:20px}.ut{margin-right:0}.ve{max-width:100%}.vk{font-size:24px}.vl{line-height:30px}.vm{letter-spacing:-0.016em}.vp{margin-bottom:64px}.vz{margin:32px 0 16px}.wl{width:100%}.wq{padding-top:48px}.nu:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="print">.ub{display:none}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.hf{transition:opacity 200ms}.of{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="all and (max-width: 1232px)">.hg{display:none}</style><style type="text/css" data-fela-rehydration="633" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.rg{max-height:none}</style><script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/enterprise.js" data-rh="true"></script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener banner closeBanner closeJourney data deepview deepviewCta first init link logout removeListener setBranchViewData setIdentity track trackCommerceEvent logEvent disableTracking getBrowserFingerprintId crossPlatformIds lastAttributedTouchData setAPIResponseCallback qrCode setRequestMetaData setAPIUrl getAPIUrl setDMAParamsForEEA".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><script async="true" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');
            </script></head><x-extension-template style="opacity: 1;"><template shadowrootmode="closed"><style data-emotion="x-global" data-s="">all:initial;</style><style data-emotion="x-global" data-s="">h1,h2,h3,h4,h5,h6{font-family:inherit;font-size:inherit;font-weight:inherit;}</style><style data-emotion="x-global" data-s="">a{color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit;}</style><style data-emotion="x-global" data-s="">blockquote,dl,dd,h1,h2,h3,h4,h5,h6,hr,figure,p,pre{margin:0;}</style><style data-emotion="x-global" data-s="">h1,h2,h3,h4,h5,h6,p{white-space:pre-wrap;}</style><style data-emotion="x-global" data-s="">button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0;padding:0;}</style><style data-emotion="x-global" data-s="">button,select{text-transform:none;}</style><style data-emotion="x-global" data-s="">button,[type='button'],[type='reset'],[type='submit']{background-color:transparent;background-image:none;border:none;}</style><style data-emotion="x-global" data-s="">button,[role='button']{cursor:pointer;}</style><style data-emotion="x-global" data-s="">:disabled{cursor:default;}</style><style data-emotion="x-global" data-s="">ol,ul,menu{list-style:none;margin:0;padding:0;}</style><style data-emotion="x-global" data-s="">*{font-family:'Inter',serif;font-synthesis:none!important;}</style><style data-emotion="x" data-s="">.x-cp5edu{display:none;background-color:#F9F9FB;border-radius:20px;box-shadow:0 0 8px rgba(0, 0, 0, 0.4);margin:16px;position:fixed;right:0;top:0;z-index:2147483647;padding:0;height:auto;width:400px;color:#2A2A2A;font-weight:400;letter-spacing:normal;-webkit-flex:1;-ms-flex:1;flex:1;overflow-y:auto;overflow-x:hidden;max-height:90vh;}</style><style data-emotion="x" data-s="">.x-cp5edu:focus-visible{outline:none;}</style><style data-emotion="x" data-s="">.x-cp5edu::-webkit-scrollbar{width:8px;}</style><style data-emotion="x" data-s="">.x-cp5edu::-webkit-scrollbar-track{background:transparent;}</style><style data-emotion="x" data-s="">.x-cp5edu::-webkit-scrollbar-thumb{background-color:#ACACAC;border-radius:20px;}</style><style data-emotion="x" data-s="">.x-iur50r{position:-webkit-sticky;position:sticky;top:0;right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding:20px 20px 12.5px;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;background-color:#F9F9FB;-webkit-align-items:start;-webkit-box-align:start;-ms-flex-align:start;align-items:start;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;z-index:20;}</style><style data-emotion="x" data-s="">.x-1d1xfdq{height:32px;}</style><style data-emotion="x" data-s="">.x-12yghq1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><style data-emotion="x" data-s="">.x-12jrmjw{height:18px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:#5D57FB;}</style><style data-emotion="x" data-s="">.x-12jrmjw>img{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><style data-emotion="x" data-s="">.x-12jrmjw:hover,.x-12jrmjw:focus,.x-12jrmjw:active{color:#292594;}</style><style data-emotion="x" data-s="">.x-z9ahs6{width:18px;height:18px;position:relative;cursor:pointer;color:#5D57FB;}</style><style data-emotion="x" data-s="">.x-z9ahs6>svg{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><style data-emotion="x" data-s="">.x-z9ahs6:hover,.x-z9ahs6:focus,.x-z9ahs6:active{color:#292594;}</style><style data-emotion="x" data-s="">.x-f0r4qe{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin-bottom:20px;}</style><style data-emotion="x" data-s="">.x-1sk31pk{height:120px;width:64px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><style data-emotion="x" data-s="">.x-11el403{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}</style><style data-emotion="x" data-s="">.x-9d1xtn{-webkit-animation:spin 2s infinite linear;animation:spin 2s infinite linear;width:68px;}</style><style data-emotion="x" data-s="">@-webkit-keyframes spin{from{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}to{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}</style><style data-emotion="x" data-s="">@keyframes spin{from{-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);}to{-webkit-transform:rotate(360deg);-moz-transform:rotate(360deg);-ms-transform:rotate(360deg);transform:rotate(360deg);}}</style><style data-emotion="x" data-s="">.x-2fbzfo{font-size:24px;font-weight:700;color:#2A2A2A;}</style><style data-emotion="x" data-s="">.x-23o788{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><style data-emotion="x" data-s="">.x-1fk5cv3{width:90%;}</style><style data-emotion="x" data-s="">.x-1dgiaom{height:32px;min-width:195px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:1px solid #F5F5F5;border-radius:40px;outline:none;margin-bottom:12px;padding:0 8px;background:#FFFFFF;}</style><style data-emotion="x" data-s="">.x-1xjble4{height:16.13px;margin-right:6px;color:#D4D4D4;}</style><style data-emotion="x" data-s="">.x-dcpxyk{-webkit-flex:1;-ms-flex:1;flex:1;color:#2A2A2A;font-size:16px;font-weight:400;width:100%;border:none;outline:none;padding-right:15px;background:#FFFFFF;}</style><style data-emotion="x" data-s="">.x-dcpxyk::-webkit-input-placeholder{color:#D4D4D4;font-size:'16px';}</style><style data-emotion="x" data-s="">.x-dcpxyk::-moz-placeholder{color:#D4D4D4;font-size:'16px';}</style><style data-emotion="x" data-s="">.x-dcpxyk:-ms-input-placeholder{color:#D4D4D4;font-size:'16px';}</style><style data-emotion="x" data-s="">.x-dcpxyk::placeholder{color:#D4D4D4;font-size:'16px';}</style><style data-emotion="x" data-s="">.x-1naxvcv{padding:20px 55px;}</style><style data-emotion="x" data-s="">.x-1sxwg4s{background-color:#5D57FB;color:#fff;border:none;font-weight:700;font-size:18px;line-height:22px;padding:20px 70px;border-radius:32px;text-align:center;cursor:pointer;padding:20px 55px;}</style><style data-emotion="x" data-s="">.x-1sxwg4s:hover,.x-1sxwg4s:focus-visible{color:#fff;background-color:#292594;}</style><style data-emotion="x" data-s="">.x-1sxwg4s:active{color:#5D57FB;background-color:#ffffff;}</style><div tabindex="-1" class="x-cp5edu"><div class="x-iur50r"><img src="chrome-extension://llmdgffkgdelaboimodllcpnaicneglm/img/partner/brand-logo.png" alt="Bold Rewards" data-testid="header-logo" class="x-1d1xfdq"><div class="x-12yghq1"><nav><button aria-label="Toggle Open Menu" aria-haspopup="true" aria-expanded="false" data-testid="header-menu-icon-button" class="x-12jrmjw"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="16" fill="none" aria-hidden="true" data-testid="header-menu-icon"><g fill="currentColor"><rect width="4" height="4" x="14" y="6" rx="2"></rect><rect width="4" height="4" x="6" y="6" rx="2"></rect><rect width="4" height="4" x="22" y="6" rx="2"></rect></g></svg></button></nav><button name="Close extension" data-testid="header-close-icon" class="x-z9ahs6"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-hidden="true"><g fill="currentColor"><rect width="18" height="2" x="1.414" y="13.727" rx="1" transform="rotate(-45 1.414 13.727)"></rect><rect width="18" height="2" x="2.414" y="1" rx="1" transform="rotate(45 2.414 1)"></rect></g></svg></button></div></div><div data-testid="NotEligible" class="x-23o788"><div class="x-1fk5cv3"><div class="x-1dgiaom"><button name="Focus search" class="x-1xjble4"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="18" fill="none" aria-hidden="true"><path fill="currentColor" d="M0 7.459c0 3.597 2.832 6.524 6.313 6.524a6.12 6.12 0 0 0 3.671-1.226l3.892 4.03c.182.188.42.278.673.278.538 0 .91-.417.91-.964a.96.96 0 0 0-.261-.67l-3.87-4.023a6.6 6.6 0 0 0 1.298-3.95c0-3.596-2.832-6.523-6.313-6.523S0 3.862 0 7.459m1.353 0c0-2.829 2.223-5.126 4.96-5.126s4.96 2.297 4.96 5.126-2.223 5.126-4.96 5.126-4.96-2.297-4.96-5.126"></path></svg></button><input placeholder="Search" data-testid="search-bar-input" class="x-dcpxyk" value=""></div></div><button class="x-1sxwg4s">View Rewards Dashboard</button></div></div></template><style>
  @font-face {
    font-family: 'Inter';
    src: url(chrome-extension://llmdgffkgdelaboimodllcpnaicneglm/source/fonts/Inter-VariableFont_opsz,wght.ttf) format('truetype');
  }
  @font-face {
    font-family: 'Inter';
    font-style: italic;
    src: url(chrome-extension://llmdgffkgdelaboimodllcpnaicneglm/source/fonts/Inter-Italic-VariableFont_opsz,wght.ttf) format('truetype');
  }
</style></x-extension-template><body><div id="root"><div class="a b c"><a href="https://levelup.gitconnected.com/sitemap/sitemap.xml" class="d">Sitemap</a><div class="e f g h i j k l"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="m c"><div class="m n o p c" style="transform: translateY(-57px);"><div class="q r s t u v w x y j e z ab"><a class="du ah dv bf al b an ao ap aq ar as at au t v x j e r dw ab" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3bc057d27e85&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;%7Estage=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dt"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ac r"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq wz xa xb xc ev ew ex xd xe fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign up</a></span></p><div class="fg m"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="q r s ac ae"><div class="ac r af"><a class="ag ah ai aj ak al am an ao ap aq ar as at au ac" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" aria-labelledby="wordmark-medium-desc" viewBox="0 0 719 160" class="av aw ax"><desc id="wordmark-medium-desc">Medium Logo</desc><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="ay i"><div class="ac aj az ba bb r bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ac"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="aj be bf bg ab bh bi bj bk bl" placeholder="Search" value=""></div></div></div><div class="i l x fi fj"><div class="fk ac"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------" rel="noopener follow"><div class="bf b bg ab du fl fm ac r fn fo"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dt m">Write</div></div></a></span></div></div><div class="l k j e"><div class="fk ac"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerSearchButton" href="https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><div class="bf b bg ab du fl fm ac r fn fo"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fk i l k"><div class="ac r"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq wz xa xb xc ev ew ex xd xe fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign up</a></span></p><div class="fg m"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="m" aria-hidden="false"><button class="aj fp an ac r ap fl fq fr fs" aria-label="user options menu" data-testid="headerUserIcon"><div class="m fl"><img alt="" class="m fd bx by bz cx" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"><div class="ft bx m by bz fu o aj fv"></div></div></button></div></div></div><div class="ac"><div class="qz" style="width: 0px;"></div><div class="ca bh" style="width: calc(100% + 0px);"><div class="m"><div><div class="ga bh m"><div class="gb bh xf"></div><div class="ac cb"><div class="cc cd ce cf cg gd ci bh"><div class="ae ac r"><div class="ge gf gg gh gi m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://levelup.gitconnected.com/?source=post_page---publication_nav-5517fd7b58a6-3bc057d27e85---------------------------------------" rel="noopener follow"><h2 class="bf gj gk dy gl gm ea gn go gp gq gr gs gt gu gv gw bk"><div class="fw fx fy fz">Level Up Coding</div></h2></a></div><div class="t v k j e"><span class="gx gy" aria-hidden="true"><span class="bf b gz ha bk">·</span></span><p class="bf b gz ha bk"><span><a class="ag ah ai fh ak al am an ao ap aq ar as hb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fgitconnected&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;collection=Level+Up+Coding&amp;collectionId=5517fd7b58a6&amp;source=post_page---publication_nav-5517fd7b58a6-3bc057d27e85---------------------publication_nav------------------" rel="noopener follow">Follow publication</a></span></p></div></div></div></div></div></div><div class="ub" role="dialog" aria-modal="true" tabindex="-1"><div class="xk xl bh dw xm xn xo ap hh hc xp" aria-hidden="true" role="presentation"></div><div class="xq xm xr xs xt xk dw fd xu xv xw ms xx xy xz ya yb yc yd ye yf yg ac co yh" aria-hidden="true"><div class="yi ie"></div></div></div><div class="hc fu hd he o hf hg hh yj"><div class="ac cb"><div class="cc cd ce cf cg gd ci bh"><div class="hj m"><div class="hc"><div class="ac cn co"><a href="https://levelup.gitconnected.com/?source=post_page---post_publication_sidebar-5517fd7b58a6-3bc057d27e85---------------------------------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m hm hl" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ.jpg" width="38" height="38" loading="lazy"><div class="hk m hl hm fu o ft hn"></div></div></a><div class="ho m"></div><p class="bf b bg ab du">Coding tutorials and news. The developer homepage <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://gitconnected.com/" rel="noopener  ugc nofollow">gitconnected.com</a> &amp;&amp; <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://skilled.dev/" rel="noopener  ugc nofollow">skilled.dev</a> &amp;&amp; <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://levelup.dev/" rel="noopener  ugc nofollow">levelup.dev</a></p><div class="ho m"></div><p class="bf b bg ab bk"><span><a class="ag ah ai fh ak al am an ao ap aq ar as hb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fgitconnected&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;collection=Level+Up+Coding&amp;collectionId=5517fd7b58a6&amp;source=post_page---post_publication_sidebar-5517fd7b58a6-3bc057d27e85---------------------post_publication_sidebar------------------" rel="noopener follow">Follow publication</a></span></p></div></div></div></div></div></div><div class="hr hs ht hu hv m"><div class="ac cb"><div class="ci bh hw hx hy hz"></div></div><article><div class="m"><div class="m"><span class="m"></span><section><div><div class="fu if yl ih ii hc"></div><div class="hq hp ij ik il"><div class="ac cb"><div class="ci bh hw hx hy hz"><div><h1 id="36bd" class="pw-post-title im in io bf ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo bk" data-testid="storyTitle" data-selectable-paragraph="">How I Built a Tool-Calling Llama Agent with a Custom MCP Server</h1><div><div class="speechify-ignore ac cp"><div class="speechify-ignore bh m"><div class="ac jp jq jr js jt ju jv jw jx jy jz"><div class="ac r jz"><div class="ac ka"><div><div class="bm" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div tabindex="-1" class="be"><a href="https://medium.com/@infin94?source=post_page---byline--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m kb kc bx kd ke"><div class="m fl"><img alt="Hyunjong Lee" class="m fd bx by bz cx" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_YSUBDzfIPKC07AmW14SNkg@2x.jpg" width="32" height="32" loading="lazy" data-testid="authorPhoto"><div class="kf bx m by bz fu o kg fv"></div></div></div></a></div></div></div></div><span class="bf b bg ab bk"><div class="kh ac r"><div class="ac r ki"><div class="ac r"><div><div class="bm" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><div tabindex="-1" class="be"><span class="bf b bg ab bk"><a class="ag ah ai fh ak al am an ao ap aq ar as kj" data-testid="authorName" href="https://medium.com/@infin94?source=post_page---byline--3bc057d27e85---------------------------------------" rel="noopener follow">Hyunjong Lee</a></span></div></div></div></div><div class="kk bm"></div><div class="bm" aria-hidden="false"><button class="we xg ap ac cb r abw abx aby" style="border: 1px solid rgb(36, 36, 36);"><span class="bf b bg ab bk bh"><span class="bm xj">Follow</span></span></button></div></div></div></span></div><div class="ac r kl"><span class="bf b bg ab du"><div class="ac af"><span data-testid="storyReadTime">22 min read</span><div class="km kn m" aria-hidden="true"><span class="m" aria-hidden="true"><span class="bf b bg ab du">·</span></span></div><span data-testid="storyPublishDate">May 19, 2025</span></div></span></div></div><div class="ac cp ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld"><div class="i l x fi fj r"><div class="lt m"><div class="ac r lu lv"><div class="pw-multi-vote-icon fl lw lx ly lz"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;user=Hyunjong+Lee&amp;userId=ecf7619248d7&amp;source=---header_actions--3bc057d27e85---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><div tabindex="-1" class="be"><div class="ma ap mb mc md me an mf mg mh lz" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m mi mj mk ml mm mn mo"><div><div class="bm" aria-hidden="false" aria-describedby="69" aria-labelledby="69"><div tabindex="-1" class="be"><p class="bf b dv ab du"><button class="ag ah ai fh ak al am an ao ap aq ar as at au abv mx">220<span class="m i h g ug uh"></span></button></p></div></div></div></div></div></div><div><div class="bm" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><div tabindex="-1" class="be"><button class="ap ma ms mt ac r fm mu mv" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mr"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bf b dv ab du"><span class="pw-responses-count mq mr">3</span></p></button></div></div></div></div><div class="ac r le lf lg lh li lj lk ll lm ln lo lp lq lr ls"><div class="mw l k j e"></div><div class="i l"><div><div class="bm" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=---header_actions--3bc057d27e85---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="fd my cn"><div class="m af"><div class="ac cb"><div class="mz na nb nc nd fw ci bh"><div class="ac"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=---header_actions--3bc057d27e85---------------------post_audio_button------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="19" aria-labelledby="19"><div tabindex="-1" class="be"><button aria-label="Listen" data-testid="audioPlayButton" class="ag fm ai fh ak al am ne ao ap aq ex nf ng mv nh ni nj nk nl t nm nn no np nq nr ns v nt nu nv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bf b bg ab du">Listen</p></div></button></div></div></div></a></span></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><div tabindex="-1" class="be"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="ag fm ai fh ak al am ne ao ap aq ex nf ng mv nh ni nj nk nl t nm nn no np nq nr ns v nt nu nv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bf b bg ab du">Share</p></div></button></div></div></div></div></div></div></div></div></div></div><figure class="nz oa ob oc od oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx ny"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*atue7XX9h3JTZxhJQuGyxg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*atue7XX9h3JTZxhJQuGyxg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*atue7XX9h3JTZxhJQuGyxg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*atue7XX9h3JTZxhJQuGyxg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*atue7XX9h3JTZxhJQuGyxg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*atue7XX9h3JTZxhJQuGyxg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*atue7XX9h3JTZxhJQuGyxg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*atue7XX9h3JTZxhJQuGyxg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="467" loading="eager" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_atue7XX9h3JTZxhJQuGyxg.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Image generated by ChatGPT</figcaption></figure><h1 id="2437" class="oo op io bf oq or os ot gl ou ov ow gn ox oy oz pa pb pc pd pe pf pg ph pi pj bk" data-selectable-paragraph="">1. Introduction</h1><p id="cd8e" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">In this article, I’ll walk through the development of a local AI agent that communicates with a previously built MCP(Model Context Protocol) server to generate context-aware responses using tool-calling.</p><p id="8cd4" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Why I started this project</strong></p><p id="bab7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This article is a follow-up to my previous article, where I introduced a custom MCP server that connects to my personal Obsidian knowledge base. Rather than using the official MCP server with file system access, I chose to build my own for several reasons:</p><ul class=""><li id="dba5" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe qk ql qm bk" data-selectable-paragraph="">To enforce read-only access to my file system</li><li id="b0cb" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">To avoid exposing directory structure of file paths to external AI model</li><li id="0b48" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">To deeply understand how the MCP works by implementing it</li></ul><p id="6af7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">For more details, please refer to my previous article</p><div class="qs qt qu qv qw qx"><a rel="noopener  ugc nofollow" href="https://levelup.gitconnected.com/how-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985?source=post_page-----3bc057d27e85---------------------------------------" target="_blank" data-discover="true"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">How I Built a Local MCP Server to Connect Obsidian with AI</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Using MCP to link Obsidian with local AI tools for smarter, context-aware assistance</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">levelup.gitconnected.com</p></div></div><div class="rj m"><div class="rk m rl rm rn rj ro fw qx"></div></div></div></a></div><p id="9fb9" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">After building the MCP server, I wanted to address a new challenge: <strong class="pm ip">dependency on external AI models</strong>. While Claude has demonstrated excellent reasoning capabilities, its usage is limited unless you’re on a paid plan. More importantly, relying on external AI services means that the contents of my private knowledge notes are still being sent outside my local environment.</p><p id="70a3" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This article covers the next steps in building a fully local, private agent:</p><ul class=""><li id="0af9" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe qk ql qm bk" data-selectable-paragraph="">Implementing an MCP client that connects to the MCP server</li><li id="f089" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">Integrating a local LLM model for response generation</li><li id="8695" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">Building an LLM agent that uses both MCP and the model to answer questions</li></ul><p id="f4df" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">For this purpose, I chose not to use frameworks like LangChain, so the entire flow is transparent and easy to understand.</p><h1 id="586d" class="oo op io bf oq or os ot gl ou ov ow gn ox oy oz pa pb pc pd pe pf pg ph pi pj bk" data-selectable-paragraph="">2. Integration of sLLM with Tool-Calling Support</h1><h2 id="2364" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">2.1. Small Language Model for Local Use</h2><p id="61dc" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">In agent development, the most critical thing is the brain — the LLM. The quality of the generated responses depends heavily on the model’s reasoning ability. However, since the goal is to run everything locally, using massive LLM is not feasible. Instead, we must rely on small Language Model(sLLM) that can run on a local GPU or CPU environment.</p><p id="d8d9" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">But not all sLLMs are suitable. If the model’s response quality is too low or it lacks the ability to follow tool-calling instructions, it becomes unusable for this kind of agent architecture.</p><p id="9dd2" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Previously, I experimented with the Llama 3.1 8B-Instruct model, which delivered impressive results. I used it in a project where multiple models, each with different system prompts(personas), engaged in discussions on selected topics to generate synthetic(artificial) text data. If you’re interested in the details, please check out the article below.</p><div class="qs qt qu qv qw qx"><a href="https://medium.com/@infin94/kickstart-your-research-instantly-generate-synthetic-text-data-with-llama-3-1-56eaee6fbf48?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">Leveraging AI Conversations to Generate Synthetic Text Data with Llama 3.1</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Exploit Llama to generate synthetic data instead of collecting text data which is hard to find</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">medium.com</p></div></div><div class="rj m"><div class="rw m rl rm rn rj ro fw qx"></div></div></div></a></div><p id="3140" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While the Llama 3.1 8B-Instruct model also supports tool-calling, for this project, I opted for Llama 3.2 version model. The 1B and 3B models from Llama 3.2 are lightweight models designed for on-device agentic applications, which keep all data local and help preserve user privacy.</p><p id="f2c2" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">According to Meta’s benchmarking results, the Llama 3.2 models strike a good balance between size and performance. Despite their smaller size, they offer reasonable response quality and support for tool-calling, making them well-suited for this project.</p><p id="82e1" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">As explained in Meta’s official blog post, the Llama 3.2 models were created by applying structured pruning to the Llama 3.1 8B model in a single-shot manner. To recover performance after pruning, Meta used knowledge distillation from multiple Llama 3.1 models, as illustrated in the diagram below.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx rx"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NsF2TP5CznxZDPG1q-qCtw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*NsF2TP5CznxZDPG1q-qCtw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*NsF2TP5CznxZDPG1q-qCtw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*NsF2TP5CznxZDPG1q-qCtw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*NsF2TP5CznxZDPG1q-qCtw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*NsF2TP5CznxZDPG1q-qCtw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*NsF2TP5CznxZDPG1q-qCtw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*NsF2TP5CznxZDPG1q-qCtw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="370" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_NsF2TP5CznxZDPG1q-qCtw.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Llama 3.2 1B/3B Pruning and Distillation Process (Image by Meta AI)</figcaption></figure><p id="b355" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">I won’t go into the technical details here. If you’re curious, I encourage you to read through Meta’s official blog post.</p><div class="qs qt qu qv qw qx"><a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">Llama 3.2: Revolutionizing edge AI and vision with open, customizable models</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Today, we're releasing Llama 3.2, which includes small and medium-sized vision LLMs, and lightweight, text-only models…</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">ai.meta.com</p></div></div><div class="rj m"><div class="sd m rl rm rn rj ro fw qx"></div></div></div></a></div><h2 id="b499" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">2.1. The Tool Calling Process of LLM</h2><p id="a524" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">How does the LLM invoke a tool and generate a response? The overall tool-calling process is illustrated below.</p><p id="7e3f" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">When information about available tools is provided — either through the system prompt or user prompt — the LLM determines whether a tool should be invoked. If so, it generates a function call definition as its response.</p><p id="c6ad" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The LLM application then parses the function call, executes the corresponding tool, and feeds the result back to the model. Based on the tool’s output, the model can generate a synthesized response.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx se"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMjXIiLr1OPG6UK99UxwpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*GMjXIiLr1OPG6UK99UxwpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GMjXIiLr1OPG6UK99UxwpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GMjXIiLr1OPG6UK99UxwpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GMjXIiLr1OPG6UK99UxwpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GMjXIiLr1OPG6UK99UxwpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GMjXIiLr1OPG6UK99UxwpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GMjXIiLr1OPG6UK99UxwpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="271" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_GMjXIiLr1OPG6UK99UxwpQ.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Response Generation Flow with Tool Calling (Image by Meta AI)</figcaption></figure><p id="bcc7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">In this project, the Tools component in the diagram is replaced by the MCP Client, which is responsible for invoking tools.</p><p id="7da1" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This following explanation is based on the official Llama 3.1 documentation. If you’re already familiar with this, you can skip ahead to the next chapter.</p><div class="qs qt qu qv qw qx"><a href="https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/?source=post_page-----3bc057d27e85---------------------------------------#prompt-template" rel="noopener  ugc nofollow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">Llama 3.1 | Model Cards and Prompt formats</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Llama 3.1 - the most capable open model.</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">www.llama.com</p></div></div><div class="rj m"><div class="sf m rl rm rn rj ro fw qx"></div></div></div></a></div><p id="1a2f" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Let’s briefly review the special tokens and role structure that form the backbone of prompt formatting.</p><p id="a61f" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Special Tokens</strong></p><ul class=""><li id="f3ae" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">&lt;|begin_of_text|&gt;</strong> : Specifies the start of the prompt.</li><li id="42fb" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">&lt;|start_header_id|&gt; {role} &lt;|end_header_id|&gt;</strong> : Enclose the role for a particular message.</li><li id="fc18" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">&lt;|eot_id|&gt;</strong> : (End of turn); signals to the executor that the model has finished generating a response.</li></ul><p id="5c12" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Supported Roles</strong></p><ul class=""><li id="291c" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">system</strong> : Defines the context in which the model operates. It usually includes instructions, rules, guidelines, or background information to help the model’s behavior</li><li id="d846" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">user</strong> : Represents the input from human user. It includes the inputs, commands, and questions to the model</li><li id="26a8" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">assistant</strong>: Represents the response generated by the AI model based on the context</li><li id="6a81" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph=""><strong class="pm ip">ipython</strong>: Semantically, this role means “tool”. This is used to return the output of a tool invocation back to the model from the executor.</li></ul><p id="90aa" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Let’s take a look at how the LLM determines when to invoke and how it generates a response.</p><p id="3d96" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">1) System Prompt with Tool Definition</strong></p><p id="b395" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The system prompt includes tool definitions in JSON format, specifying the available tools and their parameters. This definition can also be included in the user prompt, although placing it in the system prompt is generally preferred for clarity.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="808a" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-string">&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><br><br><span class="hljs-string">You</span> <span class="hljs-string">are</span> <span class="hljs-string">an</span> <span class="hljs-string">expert</span> <span class="hljs-string">in</span> <span class="hljs-string">composing</span> <span class="hljs-string">functions.</span> <span class="hljs-string">You</span> <span class="hljs-string">are</span> <span class="hljs-string">given</span> <span class="hljs-string">a</span> <span class="hljs-string">question</span> <span class="hljs-string">and</span> <span class="hljs-string">a</span> <span class="hljs-string">set</span> <span class="hljs-string">of</span> <span class="hljs-string">possible</span> <span class="hljs-string">functions.</span> <br><span class="hljs-string">Based</span> <span class="hljs-string">on</span> <span class="hljs-string">the</span> <span class="hljs-string">question,</span> <span class="hljs-string">you</span> <span class="hljs-string">will</span> <span class="hljs-string">need</span> <span class="hljs-string">to</span> <span class="hljs-string">make</span> <span class="hljs-string">one</span> <span class="hljs-string">or</span> <span class="hljs-string">more</span> <span class="hljs-string">function/tool</span> <span class="hljs-string">calls</span> <span class="hljs-string">to</span> <span class="hljs-string">achieve</span> <span class="hljs-string">the</span> <span class="hljs-string">purpose.</span> <br><span class="hljs-string">If</span> <span class="hljs-string">none</span> <span class="hljs-string">of</span> <span class="hljs-string">the</span> <span class="hljs-string">functions</span> <span class="hljs-string">can</span> <span class="hljs-string">be</span> <span class="hljs-string">used,</span> <span class="hljs-string">point</span> <span class="hljs-string">it</span> <span class="hljs-string">out.</span> <span class="hljs-string">If</span> <span class="hljs-string">the</span> <span class="hljs-string">given</span> <span class="hljs-string">question</span> <span class="hljs-string">lacks</span> <span class="hljs-string">the</span> <span class="hljs-string">parameters</span> <span class="hljs-string">required</span> <span class="hljs-string">by</span> <span class="hljs-string">the</span> <span class="hljs-string">function,also</span> <span class="hljs-string">point</span> <span class="hljs-string">it</span> <span class="hljs-string">out.</span> <span class="hljs-string">You</span> <span class="hljs-string">should</span> <span class="hljs-string">only</span> <span class="hljs-string">return</span> <span class="hljs-string">the</span> <span class="hljs-string">function</span> <span class="hljs-string">call</span> <span class="hljs-string">in</span> <span class="hljs-string">tools</span> <span class="hljs-string">call</span> <span class="hljs-string">sections.</span><br><span class="hljs-string">If</span> <span class="hljs-string">you</span> <span class="hljs-string">decide</span> <span class="hljs-string">to</span> <span class="hljs-string">invoke</span> <span class="hljs-string">any</span> <span class="hljs-string">of</span> <span class="hljs-string">the</span> <span class="hljs-string">function(s),</span> <span class="hljs-string">you</span> <span class="hljs-string">MUST</span> <span class="hljs-string">put</span> <span class="hljs-string">it</span> <span class="hljs-string">in</span> <span class="hljs-string">the</span> <span class="hljs-string">format</span> <span class="hljs-string">of</span> [<span class="hljs-string">func_name1(params_name1=params_value1</span>, <span class="hljs-string">params_name2=params_value2...)</span>, <span class="hljs-string">func_name2(params)</span>]<br><span class="hljs-string">You</span> <span class="hljs-string">SHOULD</span> <span class="hljs-string">NOT</span> <span class="hljs-string">include</span> <span class="hljs-string">any</span> <span class="hljs-string">other</span> <span class="hljs-string">text</span> <span class="hljs-string">in</span> <span class="hljs-string">the</span> <span class="hljs-string">response.</span><br><br><span class="hljs-string">Here</span> <span class="hljs-string">is</span> <span class="hljs-string">a</span> <span class="hljs-string">list</span> <span class="hljs-string">of</span> <span class="hljs-string">functions</span> <span class="hljs-string">in</span> <span class="hljs-string">JSON</span> <span class="hljs-string">format</span> <span class="hljs-string">that</span> <span class="hljs-string">you</span> <span class="hljs-string">can</span> <span class="hljs-string">invoke.</span><br>[<br>    {<br>        <span class="hljs-attr">"name":</span> <span class="hljs-string">"get_user_name"</span>,<br>        <span class="hljs-attr">"description":</span> <span class="hljs-string">"Retrieve a name for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax."</span>,<br>        <span class="hljs-attr">"parameters":</span> {<br>            <span class="hljs-attr">"type":</span> <span class="hljs-string">"dict"</span>,<br>            <span class="hljs-attr">"required":</span> [<br>                <span class="hljs-string">"user_id"</span><br>            ],<br>            <span class="hljs-attr">"properties":</span> {<br>                <span class="hljs-attr">"user_id":</span> {<br>                 <span class="hljs-attr">"type":</span> <span class="hljs-string">"integer"</span>,<br>                 <span class="hljs-attr">"description":</span> <span class="hljs-string">"The unique identifier of the user. It is used to fetch the specific user details from the database."</span><br>             }<br>            }<br>        }<br>    }<br>]<br><span class="hljs-string">&lt;|eot_id|&gt;</span></span></pre><p id="cd07" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">2) User Prompt to LLM</strong></p><p id="d7c4" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The system prompt, which includes the tool definitions, is combined with the user prompt that contains the actual query. To make the LLM to generate a response by completing the sentence, the message is concluded with an assistant header.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="5c68" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-string">&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><br><br><span class="hljs-string">Can</span> <span class="hljs-string">you</span> <span class="hljs-string">retrieve</span> <span class="hljs-string">the</span> <span class="hljs-string">name</span> <span class="hljs-string">of</span> <span class="hljs-string">the</span> <span class="hljs-string">user</span> <span class="hljs-string">with</span> <span class="hljs-string">the</span> <span class="hljs-string">ID</span> <span class="hljs-number">7890</span><span class="hljs-string">?</span><br><br><span class="hljs-string">&lt;|eot_id|&gt;</span><br><br><span class="hljs-string">&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span></span></pre><p id="98dd" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">3) Response with tool-call</strong></p><p id="0529" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">In this step, the LLM determines that answering the user’s query requires a function call. It responds by generating a function call expression that matches the format specified in the system prompt.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="cfe7" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph="">[<span class="hljs-string">get_user_name(user_id=7890)</span>]<br><span class="hljs-string">&lt;|eot_id|&gt;</span></span></pre><p id="dad8" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">4) Original Prompt + Tool Response</strong></p><p id="fd64" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The application executes the requested function and appends the result back to the prompt. The role ipython is used to mark this tool result when passing it back to the model.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="5976" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-string">...</span><br><br><span class="hljs-string">&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><br><span class="hljs-string">Can</span> <span class="hljs-string">you</span> <span class="hljs-string">retrieve</span> <span class="hljs-string">the</span> <span class="hljs-string">name</span> <span class="hljs-string">of</span> <span class="hljs-string">the</span> <span class="hljs-string">user</span> <span class="hljs-string">with</span> <span class="hljs-string">the</span> <span class="hljs-string">ID</span> <span class="hljs-number">7890</span><span class="hljs-string">?</span><br><span class="hljs-string">&lt;|eot_id|&gt;</span><br><br><span class="hljs-string">&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><br>[<span class="hljs-string">get_user_name(user_id=7890)</span>]<br><span class="hljs-string">&lt;|eot_id|&gt;</span><br><br><span class="hljs-string">&lt;|start_header_id|&gt;ipython&lt;|end_header_id|&gt;</span><br>{<span class="hljs-attr">"output":</span> <span class="hljs-string">"Hyunjong Lee"</span>}<br><span class="hljs-string">&lt;|eot_id|&gt;</span><br><br><span class="hljs-string">&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span></span></pre><p id="8993" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">5) Synthesized Response</strong></p><p id="b406" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Finally, the model produces a complete response using the tool output:</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="2bc8" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-string">The</span> <span class="hljs-string">name</span> <span class="hljs-string">of</span> <span class="hljs-string">user</span> <span class="hljs-string">who</span> <span class="hljs-string">has</span> <span class="hljs-string">the</span> <span class="hljs-string">ID</span> <span class="hljs-string">is</span> <span class="hljs-string">“Hyunjong</span> <span class="hljs-string">Lee”.</span><br><span class="hljs-string">&lt;eot_id&gt;</span></span></pre><p id="a246" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Even lightweight models like Llama 3.2 1B and 3B are capable of performing tool-calling. However, according to Meta’s official documentation, for building stable tool-aware conversational applications, it is recommended to use either the 70B-Instruct or 405B-Instruct models.</p><p id="d231" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While the 8B-Instruct model supports zero-shot tool calling, <a class="ag hb" href="https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#-tool-calling-(8b/70b/405b)-" rel="noopener ugc nofollow" target="_blank">Meta’s blog notes</a> that it cannot reliably maintain a conversation when tool definitions are included in the prompt. Therefore, when working with smaller models, it’s often necessary to remove tool instructions from the prompt to ensure smoother interaction between the user and the AI model.</p><p id="df54" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This is a critical consideration for generating high-quality responses and one you should definitely keep in mind.</p><blockquote class="sp sq sr"><p id="24c6" class="pk pl ss pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Note: We recommend using Llama 70B-instruct or Llama 405B-instruct for applications that combine conversation and tool calling. Llama 8B-Instruct can not reliably maintain a conversation alongside tool calling definitions. It can be used for zero-shot tool calling, but tool instructions should be removed for regular conversations between the model and the user. — from meta AI notes</p></blockquote><p id="1251" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">3. Building LLM Agent</strong></p><p id="e6e5" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Now, let’s take a look at the architecture of the agent I built. It closely follows the tool-calling process described above, with a few additional components to enable communication with MCP server.</p><p id="30ad" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The core components are: MCP Client &amp; Manager, LLM, and Agent</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx st"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9laqwbOF96vVwM23hHTVBg.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*9laqwbOF96vVwM23hHTVBg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*9laqwbOF96vVwM23hHTVBg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*9laqwbOF96vVwM23hHTVBg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*9laqwbOF96vVwM23hHTVBg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*9laqwbOF96vVwM23hHTVBg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*9laqwbOF96vVwM23hHTVBg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*9laqwbOF96vVwM23hHTVBg.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="628" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_9laqwbOF96vVwM23hHTVBg.gif"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Architecture Overview (Image by Author)</figcaption></figure><p id="dc51" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">As this article contains a significant amount of code, only essential parts are shown here for clarity. You can fine the full source code in the GitHub repository below.</p><div class="qs qt qu qv qw qx"><a href="https://github.com/hjlee94/mcp-knowledge-base?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">GitHub - hjlee94/mcp-knowledge-base: MCP agent/client/server implementation for private knowledge…</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">MCP agent/client/server implementation for private knowledge base - hjlee94/mcp-knowledge-base</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">github.com</p></div></div><div class="rj m"><div class="su m rl rm rn rj ro fw qx"></div></div></div></a></div><h2 id="e60d" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">3.1. MCP Client and Manager</h2><p id="0215" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">A. MCP Client</strong></p><p id="41d1" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">First, we need an MCP Client capable of establishing a 1:1 connection with the MCP server. This was implemented using the Python MCP SDK, following the official MCP documentation:</p><div class="qs qt qu qv qw qx"><a href="https://modelcontextprotocol.io/quickstart/client?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">For Client Developers - Model Context Protocol</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Get started building your own client that can integrate with all MCP servers.</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">modelcontextprotocol.io</p></div></div><div class="rj m"><div class="sv m rl rm rn rj ro fw qx"></div></div></div></a></div><p id="7b48" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Below is the <em class="ss">MCPClient</em> class, which handles the connection to the server. Since the custom MCP server I built communicates over standard input/output(stdio), the client spawns the server process, connects to it via its read/write streams.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="5f58" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">MCPClient</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self</span>):<br>        self.session = <span class="hljs-literal">None</span><br>        self.name = <span class="hljs-string">''</span><br>        self.exit_stack = AsyncExitStack()<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">connect_to_server</span>(<span class="hljs-params">self, server_script_path:<span class="hljs-built_in">str</span></span>):<br>        server_params = StdioServerParameters(<br>            command = <span class="hljs-string">"python"</span>,<br>            args=[server_script_path],<br>            env=<span class="hljs-literal">None</span><br>        )<br><br>        <span class="hljs-comment"># spawaning a process for running a mcp server</span><br>        stdio_transport = <span class="hljs-keyword">await</span> self.exit_stack.enter_async_context(stdio_client(server_params))<br>        self.read, self.write = stdio_transport<br><br>        <span class="hljs-comment"># init session using read/write pipes of the process spawned</span><br>        self.session = <span class="hljs-keyword">await</span> self.exit_stack.enter_async_context(ClientSession(self.read, self.write))<br>        <br>        ...</span></pre><p id="7a89" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">After creating the client session, the client follows the MCP connection lifecycle. It first sends an initialize request to the MCP server, waits for a response, and then complete the handshake by sending an initialized notification as an acknowledgement.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx st"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9x2lm9ijlulYGUfKxzBWQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*i9x2lm9ijlulYGUfKxzBWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*i9x2lm9ijlulYGUfKxzBWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*i9x2lm9ijlulYGUfKxzBWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*i9x2lm9ijlulYGUfKxzBWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*i9x2lm9ijlulYGUfKxzBWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*i9x2lm9ijlulYGUfKxzBWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*i9x2lm9ijlulYGUfKxzBWQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="625" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_i9x2lm9ijlulYGUfKxzBWQ.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">MCP Handshake (Image by Anthropic)</figcaption></figure><p id="db35" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">As a result of the initialize request, the client receives information about the server, which is structured as shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="5a1e" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">InitializeResult</span>(<span class="hljs-title.class.inherited">Result</span>):<br>    <span class="hljs-string">"""After receiving an initialize request from the client, the server sends this."""</span><br><br>    protocolVersion: <span class="hljs-built_in">str</span> | <span class="hljs-built_in">int</span><br>    <span class="hljs-string">"""The version of the Model Context Protocol that the server wants to use."""</span><br>    capabilities: ServerCapabilities<br>    serverInfo: Implementation<br>    instructions: <span class="hljs-built_in">str</span> | <span class="hljs-literal">None</span> = <span class="hljs-literal">None</span><br>    <span class="hljs-string">"""Instructions describing how to use the server and its features."""</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title.class">Implementation</span>(<span class="hljs-title.class.inherited">BaseModel</span>):<br>    <span class="hljs-string">"""Describes the name and version of an MCP implementation."""</span><br>    name: <span class="hljs-built_in">str</span><br>    version: <span class="hljs-built_in">str</span></span></pre><p id="b05a" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">After establishing the connection, the MCP Client can obtain the server’s name and version information. If the server is implemented using the <em class="ss">FastMCP</em> class and no explicit version is specified, the version defaults to the MCP SDK’s package version.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="d90d" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">MCPClient</span>:<br> ...<br> <br> <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">connect_to_server</span>(<span class="hljs-params">self, server_script_path:<span class="hljs-built_in">str</span></span>):<br>        ...<br><br>        <span class="hljs-comment"># connect server by sending initialize request</span><br>        init_result = <span class="hljs-keyword">await</span> self.session.initialize()<br>        <br>        server_info = init_result.serverInfo<br>        self.name = <span class="hljs-string">f"<span class="hljs-subst">{server_info.name}</span>(v<span class="hljs-subst">{server_info.version}</span>)"</span></span></pre><p id="78c5" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The MCP Client includes essential methods such as <em class="ss">list_tools()</em> and <em class="ss">list_resources()</em> to enumerate available tools and resources, as well as <em class="ss">call_tool(name, args)</em> to invoke a specific tool. Their implementations are shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="d3cc" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">MCPClient</span>:<br>    ...<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">list_tools</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">list</span>[types.Tool]:<br>        response = <span class="hljs-keyword">await</span> self.session.list_tools()<br>        tools = response.tools<br>        <span class="hljs-keyword">return</span> tools<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">list_resources</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">list</span>[types.Resource]:<br>        response = <span class="hljs-keyword">await</span> self.session.list_resources()<br>        resources = response.resources<br>        <span class="hljs-keyword">return</span> resources<br>    <br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">call_tool</span>(<span class="hljs-params">self, name, args</span>) -&gt; <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">list</span>[types.TextContent]]:<br>        response = <span class="hljs-keyword">await</span> self.session.call_tool(name, args)<br>        <span class="hljs-keyword">return</span> [response.isError, response.content]</span></pre><p id="f6a0" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">B. MCP Manager</strong></p><p id="a872" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Since each MCP Client maintains a one-to-one connection with an MCP server, supporting multiple servers requires managing multiple client instances.</p><p id="e91a" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">To handle this, I defined an MCP Client Manager, which is responsible for initializing and cleaning up clients for each registered MCP server path.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="1283" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">MCPClientMaanger</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self</span>):<br>        self.server_path:<span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>] = []<br>        self.clients:<span class="hljs-built_in">list</span>[MCPClient] = []<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">register_mcp</span>(<span class="hljs-params">self, server_path:<span class="hljs-built_in">str</span></span>):<br>        self.server_path.append(server_path)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">init_mcp_client</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> self.server_path:<br>            c = MCPClient()<br>            <span class="hljs-keyword">await</span> c.connect_to_server(path)<br><br>            self.clients.append(c)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">clean_mcp_client</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> self.clients:<br>            <span class="hljs-keyword">await</span> c.cleanup()</span></pre><p id="8927" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Another important responsibility of the class is to fetch resource and tool information from the appropriate registered MCP client. To support this, the manager maintains a mapping that keeps track of which MCP client is associated with which each tool or resource.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="084a" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">MCPClientMaanger</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self</span>):<br>        ...<br>        self.tool_map:<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>] = <span class="hljs-built_in">dict</span>()<br>        self.tool_info:<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]] = <span class="hljs-built_in">dict</span>()<br>        self.resource_map:<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>] = <span class="hljs-built_in">dict</span>()<br> <br>    ...<br> <br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_resource_list</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]]:<br>        resource_list = []<br><br>        <span class="hljs-keyword">for</span> idx, c <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.clients):<br>            resources = <span class="hljs-keyword">await</span> c.list_resources()<br>            <br>            <span class="hljs-keyword">for</span> rsrc <span class="hljs-keyword">in</span> resources:<br>                resource_list.append(utils.resource2dict(rsrc))<br>                self.resource_map[utils.uri2path(rsrc.uri)] = idx<br><br>        <span class="hljs-keyword">return</span> resource_list<br>    <br> <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_func_scheme</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]]:<br>        func_scheme_list = []<br><br>        <span class="hljs-keyword">for</span> idx, c <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.clients):<br>            tools = <span class="hljs-keyword">await</span> c.list_tools()<br><br>            <span class="hljs-keyword">for</span> tool <span class="hljs-keyword">in</span> tools:<br>                func_scheme_list.append(utils.tool2dict(tool))<br>                self.tool_map[tool.name] = idx<br>                <br>                func_info = self.tool_info.get(self.clients[idx].name, {})<br>                func_info[tool.name] = tool.description<br>                self.tool_info[self.clients[idx].name] = func_info<br><br>        <span class="hljs-keyword">return</span> func_scheme_list<br>    <br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">call_tool</span>(<span class="hljs-params">self, name:<span class="hljs-built_in">str</span>, param:<span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]</span>) -&gt; <span class="hljs-built_in">tuple</span>[<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">list</span>[types.TextContent]]:<br>        idx = self.tool_map.get(name, -<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">if</span> idx &lt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">raise</span> errors.MCPException(<span class="hljs-string">f"Unknown tool name<span class="hljs-subst">{name}</span>"</span>)<br>        <br>        client = self.clients[idx]<br>        result = <span class="hljs-keyword">await</span> client.call_tool(name, param)<br>        <br>        <span class="hljs-keyword">return</span> result</span></pre><h2 id="0ef4" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">3.2. LLM Agent</h2><p id="70cb" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">A. LLM Model</strong></p><p id="7db3" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">For the agent’s language model, I used Llama, running locally on my MacBook via Llama.cpp.</p><div class="qs qt qu qv qw qx"><a href="https://github.com/ggml-org/llama.cpp?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ac qz"><div class="ra ac co cb ca rb"><h2 class="bf ip gz ab fx rc fy rd re rf rg in bk">GitHub - ggml-org/llama.cpp: LLM inference in C/C++</h2><div class="rh m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">LLM inference in C/C++. Contribute to ggml-org/llama.cpp development by creating an account on GitHub.</h3></div><div class="ri m"><p class="bf b dv ab fx rc fy rd re rf rg du">github.com</p></div></div><div class="rj m"><div class="sw m rl rm rn rj ro fw qx"></div></div></div></a></div><p id="6c41" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The first step to using a model with Llama.cpp is to download the model weights from Hugging Face. You can do this using the Hugging Face utility, which allows you to fetch a snapshot of the model repository as shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="eb61" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> snapshot_download<br><br>model_id = <span class="hljs-string">"meta-llama/Llama-3.2-3B-Instruct"</span><br>snapshot_download(repo_id=model_id, local_dir=<span class="hljs-string">"./models/llama-3.2-3B-Instruct"</span>, revision=<span class="hljs-string">"main"</span>)</span></pre><p id="6a52" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Llama.cpp requires language models to be in the GGUF format. After downloading the model from Hugging Face, you can use the conversion script provided by Llama.cpp to convert the model into GGUF format, as shown below:</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="8d5c" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph="">$ python convert_hf_to_gguf.py ./models/llama-3.2-3B-Instruct --outfile ./models/llama-3.2-3B-Instruct.gguf --outtype f16 --verbose</span></pre><p id="39d8" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">A custom wrapper class was implemented using the <a class="ag hb" href="https://github.com/abetlen/llama-cpp-python" rel="noopener ugc nofollow" target="_blank">Llama.cpp Python bindings</a>, allowing prompts to be passed in and responses to be generated programmatically.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="0d96" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">LlamaCPP</span>(<span class="hljs-title.class.inherited">BaseModel</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self, name:<span class="hljs-built_in">str</span>, model:Llama</span>):<br>        self.name = name<br>        self.model = model<br>        self.max_tokens = <span class="hljs-number">1024</span><br><br><span class="hljs-meta">    @classmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">from_path</span>(<span class="hljs-params">cls, model_path:<span class="hljs-built_in">str</span>, n_ctx:<span class="hljs-built_in">int</span>=<span class="hljs-number">0</span>, **kwargs</span>) -&gt; Self:<br>        model = Llama(<br>            model_path=model_path,<br>            n_ctx=n_ctx,<br>            verbose=<span class="hljs-literal">False</span>,<br>            **kwargs<br>        )<br><br>        <span class="hljs-keyword">return</span> cls(name = os.path.basename(model_path), model=model)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">generate</span>(<span class="hljs-params">self, prompt:<span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">'max_tokens'</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> kwargs:<br>            kwargs[<span class="hljs-string">'max_tokens'</span>] = self.max_tokens<br><br>        output = self.model(prompt, **kwargs)<br>        choices = output[<span class="hljs-string">'choices'</span>]<br>        response = choices[<span class="hljs-number">0</span>][<span class="hljs-string">'text'</span>].strip()<br>        <span class="hljs-keyword">return</span> response</span></pre><p id="b99e" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">B. Prompt</strong></p><div class="zm ga zn zo ac r co"><div class="zp zq zr zs zt m ff"><h2 class="zu b zv zw zx zy zz">Get Hyunjong Lee’s stories in&nbsp;your&nbsp;inbox</h2></div><div class="cl m ff"><p class="bf b bg ab du">Join Medium for free to get updates from&nbsp;this&nbsp;writer.</p></div><div class="abd ul abe abf uk abg ac"><span class="bf b bg ab bk"><div class="abh ac co"><div class="ac abh fc fb bp yv abi cx ms abj abk abl abm abn abo abp"><input class="abq ak ai am abr abs abt me bl abu bh" placeholder="Enter your email" type="text" value=""></div></div></span><div class="i l va qz"><div class="aba abb abc"><button class="bf b bg ab ze tq zf zg zh zi wg ev ew zj zk zl fa fb fc fd bm fe ff">Subscribe</button></div></div><div class="bh k j e"><button class="bf b bg ab ze tq zf zg zh zi wg ev ew zj zk zl fa bh fb fc fd bm fe ff">Subscribe</button></div></div><div class="rh m"><div id="g-recaptcha"></div></div></div><p id="f74a" class="pw-post-body-paragraph pk pl io pm b pn pp pq pr pt pu go pw px gr pz qa gu qc qd zo qe hq bk" data-selectable-paragraph="">Llama.cpp provides a high-level API function, <a class="ag hb" href="https://llama-cpp-python.readthedocs.io/en/latest/api-reference/#llama_cpp.Llama.create_chat_completion" rel="noopener ugc nofollow" target="_blank"><em class="ss">create_chat_completion()</em></a>, which allows you to generate responses by passing in structured messages in a simple format, as shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="9893" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph="">response = llm.create_chat_completion(<br>      messages = [<br>          {<br>           <span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>, <br>           <span class="hljs-string">"content"</span>: <span class="hljs-string">"You are an assistant who perfectly describes images."</span><br>    },<br>          {<br>              <span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>,<br>              <span class="hljs-string">"content"</span>: <span class="hljs-string">"Describe this image in detail please."</span><br>          }<br>      ]<br>)</span></pre><p id="33b5" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">However, to gain more control over prompt construction and handling, I implemented helper classes: <em class="ss">LlamaMessage</em> and <em class="ss">LlamaPrompt</em>.</p><p id="26c6" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The <em class="ss">LlamaMessage</em> class is responsible for formatting messages according to the expected Llama prompt structure. It handles the assigned role, content, and optionally a <em class="ss">tool_scheme</em>, depending on whether <em class="ss">tool_enabled</em> is set — I’ll discuss the role of <em class="ss">tool_enabled</em> in a later section.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="18b8" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">LLamaMessage</span>(<span class="hljs-title.class.inherited">BaseMessage</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self, role:<span class="hljs-built_in">str</span>, content:<span class="hljs-built_in">str</span>=<span class="hljs-string">''</span>, tool_scheme:<span class="hljs-built_in">str</span>=<span class="hljs-string">''</span></span>):<br>        self.role:<span class="hljs-built_in">str</span> = role<br>        self.content:<span class="hljs-built_in">str</span> = content<br>        self.tool_scheme:<span class="hljs-built_in">str</span> = tool_scheme<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">template</span>(<span class="hljs-params">self, tool_enabled:<span class="hljs-built_in">bool</span>=<span class="hljs-literal">False</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-comment">#* Llama CPP insert BOS token internally</span><br>        prompt = <span class="hljs-string">f"&lt;|start_header_id|&gt;<span class="hljs-subst">{self.role}</span>&lt;|end_header_id|&gt;"</span><br><br>        <span class="hljs-keyword">if</span> tool_enabled <span class="hljs-keyword">and</span> self.tool_scheme:<br>            prompt += <span class="hljs-string">f"<span class="hljs-subst">{self.tool_scheme}</span>"</span><br><br>        <span class="hljs-keyword">if</span> self.content:<br>            prompt += <span class="hljs-string">f"<span class="hljs-subst">{self.content}</span>&lt;|eot_id|&gt;"</span><br><br>        <span class="hljs-keyword">return</span> prompt</span></pre><p id="c904" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The Prompt class manages the conversation history between the model and the user, and is responsible for constructing multi-turn prompts. This class is used directly by the agent, and provides APIs to add messages according to their roles, such as user or assistant.</p><p id="2daa" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Ultimately, it generates the final input prompt (also known as the generation prompt) that is passed to the LLM for response generation.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="4df0" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">LlamaPrompt</span>(<span class="hljs-title.class.inherited">BasePrompt</span>):<br>    ROLE_SYSTEM = <span class="hljs-string">'system'</span><br>    ROLE_USER = <span class="hljs-string">'user'</span><br>    ROLE_ASSISTANT = <span class="hljs-string">'assistant'</span><br>    ROLE_TOOL = <span class="hljs-string">'ipython'</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        self.system_prompt:BaseMessage = LLamaMessage(<span class="hljs-string">'system'</span>, <span class="hljs-string">"You are a helpful assistant."</span>)<br>        self.history:History = History()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">append_history</span>(<span class="hljs-params">self, message:LLamaMessage</span>):<br>        self.history.append_message(message)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">set_system_prompt</span>(<span class="hljs-params">self, system_prompt:LLamaMessage</span>):<br>        self.system_prompt = system_prompt<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_system_prompt</span>(<span class="hljs-params">self, system_prompt:<span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-keyword">return</span> LLamaMessage(LlamaPrompt.ROLE_SYSTEM, system_prompt)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_user_prompt</span>(<span class="hljs-params">self, question:<span class="hljs-built_in">str</span>, tool_scheme:<span class="hljs-built_in">str</span>=<span class="hljs-string">''</span></span>) -&gt; LLamaMessage:<br>        <span class="hljs-keyword">return</span> LLamaMessage(LlamaPrompt.ROLE_USER, question, tool_scheme=tool_scheme)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_assistant_prompt</span>(<span class="hljs-params">self, answer:<span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>]=<span class="hljs-string">""</span></span>) -&gt; LLamaMessage:<br>        <span class="hljs-keyword">return</span> LLamaMessage(LlamaPrompt.ROLE_ASSISTANT, answer)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_tool_result_prompt</span>(<span class="hljs-params">self, result:<span class="hljs-built_in">str</span></span>) -&gt; LLamaMessage:<br>        <span class="hljs-keyword">return</span> LLamaMessage(LlamaPrompt.ROLE_TOOL, result)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_generation_prompt</span>(<span class="hljs-params">self, tool_enabled:<span class="hljs-built_in">bool</span>=<span class="hljs-literal">False</span>, last:<span class="hljs-built_in">int</span>=<span class="hljs-number">50</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        prompt = [self.system_prompt]<br>        prompt += self.history.get_chat_history(last=last)<br>        prompt += [self.get_assistant_prompt(answer=<span class="hljs-string">''</span>)] <span class="hljs-comment">#* generation prompt</span><br>        <br>        <span class="hljs-keyword">return</span> <span class="hljs-string">''</span>.join([p.template(tool_enabled=tool_enabled) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> prompt])</span></pre><p id="eb38" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Currently, the prompt format follows the Llama prompt template, since the agent uses a Llama model under the hood. However, the design is modular — other AI models can be supported by subclassing and implementing the <em class="ss">BaseMessage</em> and <em class="ss">BaseModel</em> interfaces accordingly.</p><p id="513a" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The <em class="ss">History</em> class, used by the <em class="ss">Prompt</em> class, is responsible for maintaining the record of past messages. It is designed to optionally return only the latest <em class="ss">k</em> messages, depending on the context or application requirements.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="eb86" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">History</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self, max_history:<span class="hljs-built_in">int</span>=<span class="hljs-number">50</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        self._history:<span class="hljs-built_in">list</span>[BaseMessage] = []<br>        self._max_history:<span class="hljs-built_in">int</span> = max_history<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">append_message</span>(<span class="hljs-params">self, msg:BaseMessage</span>):<br>        self._history.append(msg)<br>        self._history = self._history[-self._max_history:]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_chat_history</span>(<span class="hljs-params">self, last:<span class="hljs-built_in">int</span>=<span class="hljs-number">0</span></span>) -&gt; <span class="hljs-built_in">list</span>[BaseMessage]:<br>        <span class="hljs-keyword">if</span> last &lt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> []<br>        <br>        <span class="hljs-keyword">if</span> last &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> self._history[-last:]<br>        <br>        <span class="hljs-keyword">return</span> self._history<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">clear</span>(<span class="hljs-params">self</span>):<br>        self._history = []</span></pre><p id="6d1b" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">C. Agent</strong></p><p id="a180" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Now, let’s bring the previously defined classes together to implement the three core functionalities of the agent:</p><ul class=""><li id="fc9c" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe qk ql qm bk" data-selectable-paragraph="">MCP Client Connection and Initialization</li><li id="9e9a" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">Matching Tool Invocation Pattern and Calling the Appropriate Tool</li><li id="b5e6" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe qk ql qm bk" data-selectable-paragraph="">Synthesizing a Response with Tool Calling</li></ul><p id="8b4a" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Before diving into the implementation, we first provide the Llama model with a prompt that defines the tool-calling format and the available tools.</p><p id="084c" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This tool instruction follows the format defined in the example provided in the official Llama documentation.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="4910" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph="">TOOL_CALL_PROMPT = <span class="hljs-string">"""You are an expert in composing functions. You are given a question and a set of possible functions.<br>Based on the question, you will need to make one or more function/tool calls to achieve the purpose.<br>If none of the function can be used, point it out. If the given question lacks the parameters required by the function,<br>also point it out. You should only return the function call in tools call sections.<br><br>If you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(), func_name2(params_name1=params_value1, params_name2=params_value2...), func_name3(params)]<br>You SHOULD NOT include any other text in the response.<br><br>Here is a list of functions in JSON format that you can invoke.<br>{function_scheme}</span></span></pre><p id="17d7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The function scheme is retrieved from the MCP server, parsed into JSON, and used to define the available tools in the prompt, as shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="3e0a" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">{</span><br>        <span class="hljs-attr">"name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"list_knowledges"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"description"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"List the names and URIs of all knowledges written in the the vault"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"parameters"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span><br>            <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"object"</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">"required"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">"properties"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span><span class="hljs-punctuation">}</span><br>        <span class="hljs-punctuation">}</span><br>    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">{</span><br>        <span class="hljs-attr">"name"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"get_knowledge_by_uri"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"description"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"get contents of the knowledge resource by uri"</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">"parameters"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span><br>            <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"object"</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">"required"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-string">"uri"</span><br>            <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">"properties"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span><br>                <span class="hljs-attr">"uri"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span><br>                    <span class="hljs-attr">"type"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"string"</span><br>                <span class="hljs-punctuation">}</span><br>            <span class="hljs-punctuation">}</span><br>        <span class="hljs-punctuation">}</span><br>    <span class="hljs-punctuation">}</span><br><span class="hljs-punctuation">]</span></span></pre><p id="3356" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">MCP Client Connection and Initialization</strong></p><p id="90c2" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The agent uses the previously implemented MCPManager to register MCP server paths and initialize client sessions for each registered server.</p><p id="ffa3" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Once the MCP client session is established, it sends <em class="ss">tools/list</em> and <em class="ss">resources/list</em> requests to retrieve the tools and resources available on the server.</p><p id="1b39" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The responses are then converted into JSON strings and stored for use in the system prompt.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="2467" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">Agent</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self, name:<span class="hljs-built_in">str</span>, model:BaseModel, prompt:BasePrompt</span>) -&gt; <span class="hljs-literal">None</span>:<br>        self.name:<span class="hljs-built_in">str</span> = name<br><br>        self.llm:BaseModel = model<br>        self.prompt:BasePrompt = prompt<br><br>        self.mcp_manager = MCPClientMaanger()<br><br>        self.func_scheme_prompt = <span class="hljs-string">""</span><br>        self.resource_list = <span class="hljs-string">""</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">register_mcp</span>(<span class="hljs-params">self, path:<span class="hljs-built_in">str</span></span>):<br>        self.mcp_manager.register_mcp(path)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">init_agent</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">await</span> self.mcp_manager.init_mcp_client()<br><br>        func_scheme_list = <span class="hljs-keyword">await</span> self.mcp_manager.get_func_scheme()<br>        resource_list = <span class="hljs-keyword">await</span> self.mcp_manager.get_resource_list()<br><br>        self.func_scheme_prompt = json.dumps(func_scheme_list)<br>        self.resource_list = json.dumps(resource_list)<br>        <br>        p = self.prompt.get_system_prompt(<span class="hljs-string">"You are a helpful assistant"</span>)<br>        self.prompt.set_system_prompt(p)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">clean_agent</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">await</span> self.mcp_manager.clean_mcp_client()</span></pre><p id="ce24" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Matching Tool Invocation Pattern and Calling the Appropriate Tool</strong></p><p id="57c1" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This part of the agent is responsible for determining whether the LLM’s response requires a tool invocation, and if so, it sends a <em class="ss">tools/call</em> request through the appropriate MCP client to retrieve the result.</p><p id="fe91" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">To match tool invocation patterns such as <em class="ss">[func_1(param1=value1, param2=value2), func_2()]</em>, a regular expression is defined.</p><p id="06b9" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The <em class="ss">_is_tool_required(str)</em> method checks whether the LLM’s response includes any tool invocation. The <em class="ss">get_func_props(str)</em> method is a generator that iterates over all matched functions and yields the function name and parsed arguments.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="f043" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">Agent</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">__init__</span>(<span class="hljs-params">self, name:<span class="hljs-built_in">str</span>, model:BaseModel, prompt:BasePrompt</span>) -&gt; <span class="hljs-literal">None</span>:<br>        ...<br><br>        self.tool_pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r'\[([A-Za-z0-9\_]+\(([A-Za-z0-9\_]+=\"?.+\"?,?\s?)*\),?\s?)+\]'</span>)<br>        self.func_pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r'([A-Za-z0-9\_]+)\(([A-Za-z0-9\_]+=\"?.+\"?,?\s?)*\)'</span>)<br><br>    ...<br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">_is_tool_required</span>(<span class="hljs-params">self, response:<span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-keyword">return</span> self.tool_pattern.<span class="hljs-keyword">match</span>(response)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_func_props</span>(<span class="hljs-params">self, response:<span class="hljs-built_in">str</span></span>):<br>        <span class="hljs-keyword">for</span> signature <span class="hljs-keyword">in</span> response.strip(<span class="hljs-string">'[]'</span>).split(<span class="hljs-string">','</span>):<br>            signature = signature.strip()<br><br>            <span class="hljs-keyword">if</span> res := self.func_pattern.findall(signature):<br>                name, param_string = res[<span class="hljs-number">0</span>]<br>                <span class="hljs-keyword">yield</span> name, utils.param2dict(param_string)<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">get_result_tool</span>(<span class="hljs-params">self, response:<span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">list</span>[<span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]]:<br>        result_list = []<br><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.get_func_props(response):<br>            res = <span class="hljs-keyword">await</span> self.mcp_manager.call_tool(name, param)<br>            is_err, content_list = res<br><br>            results = [c.text <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> content_list]<br><br>            result_list.append({<span class="hljs-string">'name'</span>:name, <span class="hljs-string">'output'</span>:results})<br>        <br>        <span class="hljs-keyword">return</span> result_list</span></pre><p id="9765" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Finally, the extracted function name and parameters are used to send a <em class="ss">tools/call</em> request to the corresponding MCP client. The result returned from the tool is a dictionary, which is then converted into a JSON string to be passed back to the AI model in the next step.</p><p id="2a9c" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Synthesizing a Response with Tool Calling</strong></p><p id="66a7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The final step of the agent is to generate the response using the result of the tool call. This process follows the same flow as described in Section 2.1 (Synthesized Response).</p><p id="081b" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The <em class="ss">chat(str)</em> method returns a list of <em class="ss">AgentResponse</em> objects, each categorized by type — such as the tool call, tool result, and text — so that both the user’s answer and relevant tool-related information can be presented clearly.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="0da9" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">AgentResponse</span>(pydantic.BaseModel):<br>    <span class="hljs-built_in">type</span>: <span class="hljs-type">Literal</span>[<span class="hljs-string">"text"</span>, <span class="hljs-string">"tool-calling"</span>, <span class="hljs-string">"tool-result"</span>]<br>    data: <span class="hljs-built_in">str</span><br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title.class">Agent</span>:<br>    ...<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">chat</span>(<span class="hljs-params">self, question:<span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">list</span>[AgentResponse]:<br>        response_list = []<br><br>        <span class="hljs-comment"># Tool Scheme for providing How to call tool and which tool can be called</span><br>        tool_scheme = TOOL_CALL_PROMPT.<span class="hljs-built_in">format</span>(<br>            function_scheme=self.func_scheme_prompt<br>            )<br>  <br>        <span class="hljs-comment"># 1. user query prompt</span><br>        p = self.prompt.get_user_prompt(question=question, tool_scheme=tool_scheme)<br>        self.prompt.append_history(p)<br><br>        <span class="hljs-comment"># 2. LLM response to user query</span><br>        response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=<span class="hljs-literal">True</span>), **kwargs)<br><br>        <span class="hljs-keyword">if</span> self._is_tool_required(response): <span class="hljs-comment"># if tool pattern found</span><br>            response_list.append(AgentResponse(<span class="hljs-built_in">type</span>=<span class="hljs-string">"tool-calling"</span>, data=response))<br><br>            p = self.prompt.get_assistant_prompt(answer=response)<br>            self.prompt.append_history(p)<br><br>            <span class="hljs-comment"># 3. llm requires tool invoke</span><br>            result = <span class="hljs-keyword">await</span> self.get_result_tool(response)<br>            result = json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>)<br><br>            response_list.append(AgentResponse(<span class="hljs-built_in">type</span>=<span class="hljs-string">"tool-result"</span>, data=result))<br><br>            <span class="hljs-comment"># 4. add result of tool-calling into the prompt</span><br>            p = self.prompt.get_tool_result_prompt(result=result)<br>            self.prompt.append_history(p)<br>   <br>            <span class="hljs-comment"># 5. synthesize response with the tool-calling result</span><br>            response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=<span class="hljs-literal">False</span>, last=<span class="hljs-number">3</span>), **kwargs)<br><br>        response_list.append(AgentResponse(<span class="hljs-built_in">type</span>=<span class="hljs-string">"text"</span>, data=response))<br><br>        p = self.prompt.get_assistant_prompt(answer=response)<br>        self.prompt.append_history(p)<br><br>        <span class="hljs-keyword">return</span> response_list</span></pre><p id="f637" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">That wraps up the development journey of the agent so far. Now, as the final step, let’s make this agent interactive — allowing it to engage with users in a real conversation flow.</p><p id="5dda" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">Interactive Interface</strong></p><p id="4c77" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">By instantiating the Agent object and repeatedly calling the <em class="ss">chat()</em> method, you can interact with the agent directly through the terminal, as shown below.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="904b" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">run_agent</span>():<br>    agent = Agent(<br>     name=<span class="hljs-string">"knowledge-agent"</span>, <br>     model=LlamaCPP.from_path(<span class="hljs-string">'./models/llama-3.2-3B-Instruct.gguf'</span>), <br>     prompt=LlamaPrompt()<br>     )<br><br>    agent.register_mcp(path=<span class="hljs-string">"./run_server.py"</span>) <span class="hljs-comment">#Knowledge-vault MCP Server</span><br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">with</span> agent:<br>        <span class="hljs-keyword">while</span> (prompt := <span class="hljs-built_in">input</span>(<span class="hljs-string">'(prompt) '</span>)) != <span class="hljs-string">'bye'</span>:<br>            response = <span class="hljs-keyword">await</span> agent.chat(prompt)<br><br>            <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> response:<br>                <span class="hljs-keyword">if</span> r.<span class="hljs-built_in">type</span> == <span class="hljs-string">'text'</span>:<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"(assistant) <span class="hljs-subst">{r.data}</span>"</span>)<br>                <span class="hljs-keyword">elif</span> r.<span class="hljs-built_in">type</span> == <span class="hljs-string">'tool-calling'</span>:<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"(assistant) tool calling <span class="hljs-subst">{r.data}</span>"</span>)<br>                <span class="hljs-keyword">elif</span> r.<span class="hljs-built_in">type</span> == <span class="hljs-string">'tool-result'</span>:<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"(assistant) tool result <span class="hljs-subst">{r.data}</span>"</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    asyncio.run(run_agent())</span></pre><p id="53bd" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">However, since the agent also outputs tool call results, the terminal output can become quite verbose — making it difficult to follow the conversation as it grows.</p><p id="b6de" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">To improve usability, I built a web user interface using Streamlit, which not only provides an interactive chat interface but also allows dynamic parameter tuning for LLM response generation, making it easier to conduct further experiments.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx sx"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*VD6NT36bb9eronIadaI94g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*VD6NT36bb9eronIadaI94g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*VD6NT36bb9eronIadaI94g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*VD6NT36bb9eronIadaI94g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*VD6NT36bb9eronIadaI94g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*VD6NT36bb9eronIadaI94g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VD6NT36bb9eronIadaI94g.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*VD6NT36bb9eronIadaI94g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*VD6NT36bb9eronIadaI94g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*VD6NT36bb9eronIadaI94g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*VD6NT36bb9eronIadaI94g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*VD6NT36bb9eronIadaI94g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*VD6NT36bb9eronIadaI94g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*VD6NT36bb9eronIadaI94g.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="805" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_VD6NT36bb9eronIadaI94g.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Agent Chat Web Interface (Image by Author)</figcaption></figure><p id="2c14" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Details of the script are beyond the scope of this article. If you’re interested, please check out the implementation in the GitHub repository.</p><h1 id="fb6c" class="oo op io bf oq or os ot gl ou ov ow gn ox oy oz pa pb pc pd pe pf pg ph pi pj bk" data-selectable-paragraph="">4. Result</h1><p id="de04" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">There are two main ways to guide an AI model in deciding when to perform a tool call:</p><ol class=""><li id="a873" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe sy ql qm bk" data-selectable-paragraph="">Providing the tool instructions in the system prompt</li><li id="8d31" class="pk pl io pm b pn qn pp pq pr qo pt pu go qp pw px gr qq pz qa gu qr qc qd qe sy ql qm bk" data-selectable-paragraph="">Providing the tool instructions in the user prompt at request time</li></ol><p id="7b55" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Remember the important note regarding zero-shot tool calling with Llama model?</p><p id="569c" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">For models smaller than 8B, including the tool schema in the prompt often leads to unstable conversations. To maintain consistent and coherent dialogue with the user, tool instructions should be omitted when working with small models.</p><p id="213f" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Let’s now explore how the quality of the generated response differs depending on where the tool instruction is injected.</p><h2 id="fb08" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">4.1. Tool Instruction in System Prompt</h2><p id="5f0a" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">We’ll begin by defining the tool instruction in the system prompt, as shown below, and observe the resulting response.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="05a2" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">Agent</span>:<br>    ...<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">init_agent</span>(<span class="hljs-params">self</span>):<br>        ...<br>        <span class="hljs-comment"># instead of default system prompt, tool Instruction is used</span><br>        p = self.prompt.get_system_prompt(TOOL_CALL_PROMPT.<span class="hljs-built_in">format</span>(<br>            function_scheme=self.func_scheme_prompt<br>            ))  <br>        <br>        self.prompt.set_system_prompt(p)<br><br>    ...<br>    <br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">chat</span>(<span class="hljs-params">self, question:<span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">list</span>[AgentResponse]:<br>        response_list = []<br>        <br>        <span class="hljs-comment"># User prompt has only user query.</span><br>        p = self.prompt.get_user_prompt(question=question)<br>        self.prompt.append_history(p)<br>        <br>        response = self.llm.generate(...)<br>        <br>        <span class="hljs-keyword">if</span> self._is_tool_required(response):<br>            ...<br>            result = <span class="hljs-keyword">await</span> self.get_result_tool(response)<br>            result = json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>)<br><br>            p = self.prompt.get_tool_result_prompt(result=result)<br>            self.prompt.append_history(p)<br><br>            response = self.llm.generate(...)<br>            ...<br><br>        ...<br><br>        <span class="hljs-keyword">return</span> response_list</span></pre><p id="e248" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While the AI model was generally accurate in identifying and invoking the correct tool as requested, it often failed to generate an ideal response during the synthesis step, where the tool result is incorporated into the final answer. The generated responses typically fell into two categories.</p><p id="c47b" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The first case is an empty response, as shown below:</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx sz"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLijCRhRnmLhT9YFZNgr8w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*SLijCRhRnmLhT9YFZNgr8w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*SLijCRhRnmLhT9YFZNgr8w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*SLijCRhRnmLhT9YFZNgr8w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*SLijCRhRnmLhT9YFZNgr8w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*SLijCRhRnmLhT9YFZNgr8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*SLijCRhRnmLhT9YFZNgr8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*SLijCRhRnmLhT9YFZNgr8w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="224" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_SLijCRhRnmLhT9YFZNgr8w.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Case 1.1 Empty Response (Image by Author)</figcaption></figure><p id="f8ce" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The second case involved the model becoming overly focused on tool calling, often issuing unnecessary or even malformed tool invocation requests.</p><p id="b358" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">For example, in the case shown below, the user explicitly asked the model to retrieve information about a specific knowledge item.</p><p id="0b10" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Although the model successfully accessed and extracted the requested knowledge, it unnecessarily attempted to invoke the <em class="ss">list_knowledges()</em> tool, which was irrelevant to the actual task.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx ta"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DHw7cYPSSEe3bEGX_4ay7w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*DHw7cYPSSEe3bEGX_4ay7w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DHw7cYPSSEe3bEGX_4ay7w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DHw7cYPSSEe3bEGX_4ay7w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DHw7cYPSSEe3bEGX_4ay7w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DHw7cYPSSEe3bEGX_4ay7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DHw7cYPSSEe3bEGX_4ay7w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*DHw7cYPSSEe3bEGX_4ay7w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="447" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_DHw7cYPSSEe3bEGX_4ay7w.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Case 1.2 Tool Result Used Incorrectly in Final Response (Image by Author)</figcaption></figure><h2 id="6e02" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">4.2. Tool Instruction in User Prompt (Only at Request Time)</h2><p id="e6b8" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">To address the issues observed earlier, I modified the approach by not exposing the tool instruction in every generation.</p><p id="f5e7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Instead of including it in the system prompt at all times, the tool instruction is now only provided at the point where the model needs to decide whether a tool should be invoked, based on the user’s request.</p><p id="fcbb" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The code below is identical to what was introduced in Section 3.</p><p id="9d2b" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The key point here is the role of the <em class="ss">tool_enabled</em> parameter when calling the <em class="ss">get_generation_prompt()</em> method of the <em class="ss">Prompt</em> object.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="fb71" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">Agent</span>:<br>    ...<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title.function">chat</span>(<span class="hljs-params">self, question:<span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">list</span>[AgentResponse]:<br>        <span class="hljs-comment"># Tool Scheme for providing How to call tool and which tool can be called</span><br>        tool_scheme = TOOL_CALL_PROMPT.<span class="hljs-built_in">format</span>(<br>            function_scheme=self.func_scheme_prompt<br>            )<br>  <br>        <span class="hljs-comment"># 1. user query prompt</span><br>        p = self.prompt.get_user_prompt(question=question, tool_scheme=tool_scheme)<br>        self.prompt.append_history(p)<br><br>        <span class="hljs-comment"># 2. LLM response to user query</span><br>        response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=<span class="hljs-literal">True</span>), ...)<br><br>        <span class="hljs-keyword">if</span> self._is_tool_required(response): <span class="hljs-comment"># if tool pattern found</span><br>            ...<br>            p = self.prompt.get_assistant_prompt(answer=response)<br>            self.prompt.append_history(p)<br><br>            <span class="hljs-comment"># 3. llm requires tool invoke</span><br>            result = <span class="hljs-keyword">await</span> self.get_result_tool(response)<br>            result = json.dumps(result, ensure_ascii=<span class="hljs-literal">False</span>)<br><br>            <span class="hljs-comment"># 4. add result of tool-calling into the prompt</span><br>            p = self.prompt.get_tool_result_prompt(result=result)<br>            self.prompt.append_history(p)<br>   <br>            <span class="hljs-comment"># 5. synthesize response with the tool-calling result</span><br>            response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=<span class="hljs-literal">False</span>), ...)<br><br>        ...<br><br>        <span class="hljs-keyword">return</span> response_list</span></pre><p id="d230" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Depending on the value of <em class="ss">tool_enabled</em>, the tool scheme is either included or omitted when constructing the prompt through the <em class="ss">Prompt</em> object.</p><pre class="ry rz sa sb sc sg sh si bp sj bb bk"><span id="8407" class="sk op io sh b bg sl sm m sn so" data-selectable-paragraph=""><span class="hljs-keyword">class</span> <span class="hljs-title.class">LLamaMessage</span>(<span class="hljs-title.class.inherited">BaseMessage</span>):<br>    ...<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title.function">template</span>(<span class="hljs-params">self, tool_enabled:<span class="hljs-built_in">bool</span>=<span class="hljs-literal">False</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        prompt = <span class="hljs-string">f"&lt;|start_header_id|&gt;<span class="hljs-subst">{self.role}</span>&lt;|end_header_id|&gt;"</span><br><br>        <span class="hljs-keyword">if</span> tool_enabled <span class="hljs-keyword">and</span> self.tool_scheme:<br>            prompt += <span class="hljs-string">f"<span class="hljs-subst">{self.tool_scheme}</span>"</span><br><br>        <span class="hljs-keyword">if</span> self.content:<br>            prompt += <span class="hljs-string">f"<span class="hljs-subst">{self.content}</span>&lt;|eot_id|&gt;"</span><br><br>        <span class="hljs-keyword">return</span> prompt</span></pre><p id="6b60" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">When constructing the prompt to be sent to the AI model, the agent conditionally exposes the tool instruction depending on the context.</p><p id="45d7" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The instruction is included only during the initial response generation, when the model needs to decide whether a tool should be invoked.</p><p id="3730" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">During the final synthesis step — where the model generates a response based on the tool result and the user query — the instruction is intentionally omitted, to keep the output focused and coherent.</p><p id="3e5a" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">As shown in the results below, this approach leads to a notable improvement in response quality.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx tb"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FY8XbNSNZj9qvNCAsigXTQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*FY8XbNSNZj9qvNCAsigXTQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*FY8XbNSNZj9qvNCAsigXTQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*FY8XbNSNZj9qvNCAsigXTQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*FY8XbNSNZj9qvNCAsigXTQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*FY8XbNSNZj9qvNCAsigXTQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*FY8XbNSNZj9qvNCAsigXTQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*FY8XbNSNZj9qvNCAsigXTQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="805" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_FY8XbNSNZj9qvNCAsigXTQ.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Case 2.1 Listing Registered Knowledges (Image by Author)</figcaption></figure><p id="a49c" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Even when asking for the content of a specific knowledge item, the model produced a more relevant and focused response compared to when tool instructions were included in the system prompt.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx tc"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lsh4p2gvvmACVuUmtWKGA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*3lsh4p2gvvmACVuUmtWKGA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3lsh4p2gvvmACVuUmtWKGA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3lsh4p2gvvmACVuUmtWKGA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3lsh4p2gvvmACVuUmtWKGA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3lsh4p2gvvmACVuUmtWKGA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3lsh4p2gvvmACVuUmtWKGA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*3lsh4p2gvvmACVuUmtWKGA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="686" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_3lsh4p2gvvmACVuUmtWKGA.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Case 2.2 Retrieving the Content (Image by Author)</figcaption></figure><p id="4617" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">In cases where the tool call failed due to a typo in the URI, the Llama model still attempted to provide a helpful answer based on its internal knowledge, demonstrating graceful fallback behavior.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx td"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TIECUWiu09EcyFSoF8F5iA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*TIECUWiu09EcyFSoF8F5iA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*TIECUWiu09EcyFSoF8F5iA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*TIECUWiu09EcyFSoF8F5iA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*TIECUWiu09EcyFSoF8F5iA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*TIECUWiu09EcyFSoF8F5iA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*TIECUWiu09EcyFSoF8F5iA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*TIECUWiu09EcyFSoF8F5iA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="713" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_TIECUWiu09EcyFSoF8F5iA.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Case 2.3 When Retrieval Fails (Image by Author)</figcaption></figure><h2 id="febe" class="rp op io bf oq gk rq dy gl gm rr ea gn go rs gp gq gr rt gs gt gu ru gv gw rv bk" data-selectable-paragraph="">4.3. Practical Use Case</h2><p id="acbd" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">Now let’s see how well the agent performs the three core functions that originally motivated the development of the MCP Server.</p><p id="3594" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">In the first test, I asked the agent to retrieve a specific knowledge item and summarize it in Markdown format.</p><p id="ac5e" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Although there were minor errors in the tool call, the model was able to format the note into a structured table based on its content size. Overall, the result was reasonably good.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx te"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MyoIyrS8_5JBxLVKCOWFqg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*MyoIyrS8_5JBxLVKCOWFqg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*MyoIyrS8_5JBxLVKCOWFqg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*MyoIyrS8_5JBxLVKCOWFqg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*MyoIyrS8_5JBxLVKCOWFqg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*MyoIyrS8_5JBxLVKCOWFqg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*MyoIyrS8_5JBxLVKCOWFqg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*MyoIyrS8_5JBxLVKCOWFqg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="814" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_MyoIyrS8_5JBxLVKCOWFqg.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Summarizing a Registered Knowledge Notes (Image by Author)</figcaption></figure><p id="49ed" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Next, I requested a list of notes that have a title but lack content.</p><p id="b57b" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Again, the tool call was slightly off, but the model successfully identified knowledge entries with little to no content by inspecting their byte size.</p><p id="9b73" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">However, the result was only partially complete, with some relevant entries missing.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx tf"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xipAwfxy2_1ZdqVH2XkMzw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*xipAwfxy2_1ZdqVH2XkMzw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xipAwfxy2_1ZdqVH2XkMzw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xipAwfxy2_1ZdqVH2XkMzw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xipAwfxy2_1ZdqVH2XkMzw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xipAwfxy2_1ZdqVH2XkMzw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xipAwfxy2_1ZdqVH2XkMzw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xipAwfxy2_1ZdqVH2XkMzw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="684" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_xipAwfxy2_1ZdqVH2XkMzw.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Identifying Empty Knowledge Notes (Image by Author)</figcaption></figure><p id="1c2e" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Lastly, I asked the model to generate short-answer review questions based on the content of a specific knowledge note.</p><p id="f733" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Although the tool call had the same limitations as before 😅, the final response was well-structured and contextually appropriate.</p><figure class="ry rz sa sb sc oe nw nx paragraph-image"><div role="button" tabindex="0" class="of og fl oh bh oi"><div class="nw nx tf"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwDegW2i6Cd471xrNc5epQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*GwDegW2i6Cd471xrNc5epQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GwDegW2i6Cd471xrNc5epQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GwDegW2i6Cd471xrNc5epQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GwDegW2i6Cd471xrNc5epQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GwDegW2i6Cd471xrNc5epQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GwDegW2i6Cd471xrNc5epQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GwDegW2i6Cd471xrNc5epQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bh fw oj c" width="700" height="650" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_GwDegW2i6Cd471xrNc5epQ.png"></picture></div></div><figcaption class="ok ff ol nw nx om on bf b bg ab du" data-selectable-paragraph="">Generating Short-Answer Question (Image by Author)</figcaption></figure><p id="a1ec" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While the agent doesn’t yet match the performance of Claude AI, it still produced impressively useful outputs — especially considering it runs entirely on a lightweight 3B model.</p><p id="d12c" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">That said, the current version does not consistently generate perfect responses at all the time, and would require further improvements for practical use.</p><h1 id="d47c" class="oo op io bf oq or os ot gl ou ov ow gn ox oy oz pa pb pc pd pe pf pg ph pi pj bk" data-selectable-paragraph="">5. Challenges and My Thoughts</h1><p id="1257" class="pw-post-body-paragraph pk pl io pm b pn po pp pq pr ps pt pu go pv pw px gr py pz qa gu qb qc qd qe hq bk" data-selectable-paragraph="">After building and testing the agent across several use cases, I identified a few key challenges you should consider:</p><ol class=""><li id="d99b" class="pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe sy ql qm bk" data-selectable-paragraph=""><strong class="pm ip">Limitations of sLLM Performance</strong></li></ol><p id="5599" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">The most fundamental limitation is the performance of small language models (sLLMs). Although the agent is designed to be model-agnostic and can work with larger models, it is primarily intended for use with lightweight sLLMs.</p><p id="520e" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Naturally, we shouldn’t expect general-purpose reasoning capabilities on par with larger models. Instead, sLLMs are better suited for specialized tasks with well-defined constraints.</p><p id="7c62" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">2. Over-Focus on Tool Invocation</strong></p><p id="c286" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">When tool instructions are injected into prompts for lightweight models, the model tends to become overly focused on calling tools, even when it’s not necessary. For example, even after retrieving a list of knowledge items in a previous step, the model would often ignore that context and issue redundant tool calls.</p><p id="07b6" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">This suggests a need for dynamic prompt control, where the tool instruction is only included based on the query.</p><p id="b0c9" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph=""><strong class="pm ip">3. Weakness in Iterative Tool Use</strong></p><p id="d265" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Compared to larger models, lightweight Llama models showed limited capability in iterative tool usage. In my earlier experiments with Claude, the model issued tool calls for every knowledge note when searching for empty ones. In contrast, the Llama-3.2–3B-Instruct model typically stopped after one or two invocations, even when more were needed.</p><p id="062f" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While this may vary depending on how the prompt is structured, it highlights a constraint in smaller model’s ability to perform multi-step reasoning with tool feedback loops.</p><p id="58aa" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Despite these limitations, Meta’s lightweight Llama models demonstrate impressive performance relative to their size, both in inference speed and response quality.</p><p id="b218" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">While they may not be ideal for general-purpose agents, sLLMs remain a strong choice for domain-specific applications with constrained requirements.</p></div></div></div><div class="ac cb tg th ti tj" role="separator"><span class="tk bx bm gb tl tm"></span><span class="tk bx bm gb tl tm"></span><span class="tk bx bm gb tl"></span></div><div class="hq hp ij ik il"><div class="ac cb"><div class="ci bh hw hx hy hz"><p id="3cd0" class="pw-post-body-paragraph pk pl io pm b pn qf pp pq pr qg pt pu go qh pw px gr qi pz qa gu qj qc qd qe hq bk" data-selectable-paragraph="">Any feedback about this article or the source code is welcome. If you are interested in future articles, just follow me. If you want to discuss further topics, feel free to connect with me on <a class="ag hb" href="https://www.linkedin.com/in/hyunjong-lee-67913814a/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.</p></div></div></div></div></section></div></div></article></div><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="tn to ac kl"><div class="rh ac"><a class="tp aj an ap" href="https://medium.com/tag/mcp-server?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><div class="tq fl cx tr ib ts tt bf b bg ab bk fz">Mcp Server</div></a></div><div class="rh ac"><a class="tp aj an ap" href="https://medium.com/tag/agents?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><div class="tq fl cx tr ib ts tt bf b bg ab bk fz">Agents</div></a></div><div class="rh ac"><a class="tp aj an ap" href="https://medium.com/tag/llama-3?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><div class="tq fl cx tr ib ts tt bf b bg ab bk fz">Llama 3</div></a></div><div class="rh ac"><a class="tp aj an ap" href="https://medium.com/tag/obsidian?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><div class="tq fl cx tr ib ts tt bf b bg ab bk fz">Obsidian</div></a></div><div class="rh ac"><a class="tp aj an ap" href="https://medium.com/tag/ai?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><div class="tq fl cx tr ib ts tt bf b bg ab bk fz">AI</div></a></div></div></div></div><div class="m"></div><footer class="tu tv tw tx ty ac r tz ua c"><div class="m af"><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="ac cp ub"><div class="ac r lu"><div class="uc m"><span class="m ud ue uf f e"><div class="ac r lu lv"><div class="pw-multi-vote-icon fl lw lx ly lz"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;user=Hyunjong+Lee&amp;userId=ecf7619248d7&amp;source=---footer_actions--3bc057d27e85---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><div tabindex="-1" class="be"><div class="ma ap mb mc md me an mf mg mh lz" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m mi mj mk ml mm mn mo"><div><div class="bm" aria-hidden="false" aria-describedby="75" aria-labelledby="75"><div tabindex="-1" class="be"><p class="bf b dv ab du"><button class="ag ah ai fh ak al am an ao ap aq ar as at au abv mx">220<span class="m i h g ug uh"></span></button></p></div></div></div></div></div></span><span class="m i h g ug uh"><div class="ac r lu lv"><div class="pw-multi-vote-icon fl lw lx ly lz"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;user=Hyunjong+Lee&amp;userId=ecf7619248d7&amp;source=---footer_actions--3bc057d27e85---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><div tabindex="-1" class="be"><div class="ma ap mb mc md me an mf mg mh lz" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m mi mj mk ml mm mn mo"><div><div class="bm" aria-hidden="false" aria-describedby="77" aria-labelledby="77"><div tabindex="-1" class="be"><p class="bf b dv ab du"><button class="ag ah ai fh ak al am an ao ap aq ar as at au abv mx">220</button></p></div></div></div></div></div></span></div><div class="ay ac"><div><div class="bm" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><div tabindex="-1" class="be"><button class="ap ma ms mt ac r fm mu mv" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mr"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bf b bg ab du"><span class="pw-responses-count mq mr">3</span></p></button></div></div></div></div></div><div class="ac r"><div class="tm m qz"><div><div class="bm" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bc057d27e85&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=---footer_actions--3bc057d27e85---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="tm m qz"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><div tabindex="-1" class="be"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="ag fm ai fh ak al am ne ao ap aq ex nf ng mv nh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></footer><div class="ui m"><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="uj m"><div class="ac jy jw ju uk ul"><div class="um un uo up uq ur us ut uu uv ac cp"><div class="i l"><a href="https://levelup.gitconnected.com/?source=post_page---post_publication_info--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m ux uw" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(1).jpg" width="48" height="48" loading="lazy"><div class="hk m uw ux fu o ft hn"></div></div></a></div><div class="k j e"><a href="https://levelup.gitconnected.com/?source=post_page---post_publication_info--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m uz uy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(2).jpg" width="64" height="64" loading="lazy"><div class="hk m uy uz fu o ft hn"></div></div></a></div><div class="k j e va qz"><div class="ac"><button style="border: 1px solid rgb(36, 36, 36);" class="we xg ap ac cb r xh lt xi"><span class="bf b bg ab bk bh"><span class="bm xj">Follow</span></span></button></div></div></div><div class="ac co ca"><div class="vb vc vd ve vf m"><a class="ag ah ai ak al am an ao ap aq ar as at au ac r" href="https://levelup.gitconnected.com/?source=post_page---post_publication_info--3bc057d27e85---------------------------------------" rel="noopener follow"><h2 class="pw-author-name bf gj vh vi vj vk vl vm go gp gq gr gs gt gu gv gw bk"><span class="hq vg">Published in <!-- -->Level Up Coding</span></h2></a><div class="rh ac ka"><div class="m qz"><span class="pw-follower-count bf b bg ab du"><a class="ag ah ai fh ak al am an ao ap aq ar as kj" rel="noopener follow" href="https://levelup.gitconnected.com/followers?source=post_page---post_publication_info--3bc057d27e85---------------------------------------" data-discover="true">256K followers</a></span></div><div class="bf b bg ab du ac vn"><span class="gx m" aria-hidden="true"><span class="bf b bg ab du">·</span></span><a class="ag ah ai fh ak al am an ao ap aq ar as kj" rel="noopener follow" href="https://levelup.gitconnected.com/building-an-ai-agent-to-play-a-3d-fps-game-using-ursina-deepseek-and-mistral-c4996168ed65?source=post_page---post_publication_info--3bc057d27e85---------------------------------------" data-discover="true">Last published&nbsp;<!-- -->1 day ago</a></div></div><div class="ho m"><p class="bf b bg ab bk">Coding tutorials and news. The developer homepage <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://gitconnected.com/" rel="noopener  ugc nofollow">gitconnected.com</a> &amp;&amp; <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://skilled.dev/" rel="noopener  ugc nofollow">skilled.dev</a> &amp;&amp; <a class="ag ah ai fh ak al am an ao ap aq ar as hb hp hq" href="http://levelup.dev/" rel="noopener  ugc nofollow">levelup.dev</a></p></div></div></div><div class="i l"><div class="ac"><button style="border: 1px solid rgb(36, 36, 36);" class="we xg ap ac cb r xh lt xi"><span class="bf b bg ab bk bh"><span class="bm xj">Follow</span></span></button></div></div></div></div><div class="ac jy jw ju uk ul"><div class="um un uo up uq ur us ut uu uv ac cp"><div class="i l"><a tabindex="0" href="https://medium.com/@infin94?source=post_page---post_author_info--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m fl"><img alt="Hyunjong Lee" class="m fd bx uw ux cx" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_YSUBDzfIPKC07AmW14SNkg@2x(1).jpg" width="48" height="48" loading="lazy"><div class="ft bx m uw ux fu o aj hn"></div></div></a></div><div class="k j e"><a tabindex="0" href="https://medium.com/@infin94?source=post_page---post_author_info--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m fl"><img alt="Hyunjong Lee" class="m fd bx uy uz cx" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_YSUBDzfIPKC07AmW14SNkg@2x(2).jpg" width="64" height="64" loading="lazy"><div class="ft bx m uy uz fu o aj hn"></div></div></a></div><div class="k j e va qz"><div class="ac"><div class="bm" aria-hidden="false"><button class="we xg ap ac cb r xh lt xi" style="border: 1px solid rgb(36, 36, 36);"><span class="bf b bg ab bk bh"><span class="bm xj">Follow</span></span></button></div></div></div></div><div class="ac co ca"><div class="vb vc vd ve vf m"><a class="ag ah ai ak al am an ao ap aq ar as at au ac r" href="https://medium.com/@infin94?source=post_page---post_author_info--3bc057d27e85---------------------------------------" rel="noopener follow"><h2 class="pw-author-name bf gj vh vi vj vk vl vm go gp gq gr gs gt gu gv gw bk"><span class="hq vg">Written by <!-- -->Hyunjong Lee</span></h2></a><div class="rh ac ka"><div class="m qz"><span class="pw-follower-count bf b bg ab du"><a class="ag ah ai fh ak al am an ao ap aq ar as kj" href="https://medium.com/@infin94/followers?source=post_page---post_author_info--3bc057d27e85---------------------------------------" rel="noopener follow">74 followers</a></span></div><div class="bf b bg ab du ac vn"><span class="gx m" aria-hidden="true"><span class="bf b bg ab du">·</span></span><a class="ag ah ai fh ak al am an ao ap aq ar as kj" href="https://medium.com/@infin94/following?source=post_page---post_author_info--3bc057d27e85---------------------------------------" rel="noopener follow">35 following</a></div></div><div class="ho m"><p class="bf b bg ab bk"><span class="hq">ML Researcher I love to do some experiments and improve something.</span></p></div></div></div><div class="i l"><div class="ac"><div class="bm" aria-hidden="false"><button class="we xg ap ac cb r xh lt xi" style="border: 1px solid rgb(36, 36, 36);"><span class="bf b bg ab bk bh"><span class="bm xj">Follow</span></span></button></div></div></div></div></div></div></div><div class="vo vp vq vr vs m"><div class="vt bh s ui"></div><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="ac r cp"><h2 class="bf gj or ot gl ou ow gn ox oz pa pb pd pe pf ph pi bk">Responses (<!-- -->3<!-- -->)</h2><div class="ac vu"><div><div class="bm" aria-hidden="false" aria-describedby="13" aria-labelledby="13"><div tabindex="-1" class="be"><a class="vv vw" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--3bc057d27e85---------------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" aria-label="Shield with a checkmark" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div></div><div class="vx ga vy vz wa wb wc m"><div><div class="bf b bg ab bk"><div class="ha"><div class="yt m"><div class="yu ac r"><div class="m fl"><img alt="" class="m fd bx by bz cx" width="32" height="32" loading="lazy" role="presentation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_dmbNkD5D-u45r44go_cf0g.png"><div class="ft bx m by bz fu o aj hn"></div></div><div class="bn ac cn co cb"><p class="bf b bg ab du">Write a response</p></div></div><div class="cx bp ac co ym yn"><div class="ac co fl"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85&amp;source=---post_responses--3bc057d27e85---------------------respond_sidebar------------------" rel="noopener follow"><div class="yv m"><p class="bf b bg ab du">What are your thoughts?</p></div></a></span><div class="cp yo du ac yp hh yq"><span class="bf b bg ab du"><div class="ac"><div><div class="bm" aria-hidden="false" aria-describedby="27" aria-labelledby="27"><div tabindex="-1" class="be"><span role="button" aria-label="Bold (⌘B)" class="yw yx yy yz bp my cb za zb zc" tabindex="0"><svg width="21" height="21"><path fill-rule="evenodd" d="M10.308 17.993h-5.92l.11-.894.783-.12c.56-.11.79-.224.79-.448V5.37c0-.225-.113-.336-.902-.448H4.5l-.114-.894h6.255c4.02 0 5.58 1.23 5.58 3.13 0 1.896-1.78 3.125-3.79 3.463v.11c2.69.34 4.25 1.56 4.25 3.57 0 2.35-2.01 3.69-6.37 3.69l.02.01h-.02zm-.335-12.96H8.967V10.5h1.23c1.788 0 2.79-1.23 2.79-2.683 0-1.685-1.004-2.803-3.006-2.803v.02zm-.223 6.36h-.783v5.588l1.225.23h.22c1.67 0 3.01-1.004 3.01-2.792 0-2.122-1.566-3.016-3.69-3.016h.018z"></path></svg></span></div></div></div><div><div class="bm" aria-hidden="false" aria-describedby="28" aria-labelledby="28"><div tabindex="-1" class="be"><span role="button" aria-label="Italic (⌘I)" class="yw yx yy yz bp my cb za zb zc" tabindex="0"><svg width="21" height="21"><path fill-rule="evenodd" d="M9.847 18.04c-.533 0-2.027-.64-1.92-.853l2.027-7.68-.64-.214-1.387 1.494-.427-.427c.534-1.173 1.707-2.667 2.774-2.667.533 0 2.24.534 2.133.854l-2.133 7.786.533.214 1.6-1.067.427.427c-.64 1.066-1.92 2.133-2.987 2.133m2.347-11.733c-.96 0-1.387-.64-1.387-1.387 0-1.067.747-1.92 1.493-1.92.854 0 1.387.64 1.387 1.493-.107 1.067-.747 1.814-1.493 1.814"></path></svg></span></div></div></div></div></span><div class="yr va ac yp hh yq"><div class="ys"><button class="bf b dv ab bk zd wd we wf mx mu wg ev ew ex wh wi wj fa fb fc fd bm fe ff" data-testid="CancelResponseButton">Cancel</button></div><button class="bf b dv ab ze zd zf zg zh zi wg ev ew zj zk zl fa fb fc fd bm fe ff" disabled="" data-testid="ResponseRespondButton">Respond</button></div></div></div></div></div></div></div></div></div><div class="tg m"><button class="bf b bg ab bk tq wd we wf mx mu wg ev ew ex wh wi wj fa wk wl wm wn wo fb fc fd bm fe ff">See all responses</button></div></div></div></div><div class="wp wq wr ws wt m bw"><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="abz aca dm dn do ho m"><h2 class="bf gj or ot gl ou ow gn ox oz pa pb pd pe pf ph pi bk">More from Hyunjong Lee and Level Up Coding</h2></div><div class="acb ac lu kl acc acd ace acf acg ach aci acj ack acl acm acn aco acp acq"><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://levelup.gitconnected.com/how-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985" tabindex="0"><div class="aec"><div aria-label="How I Built a Local MCP Server to Connect Obsidian with AI"><div class="aee aef aeg aeh aei"><img alt="How I Built a Local MCP Server to Connect Obsidian with AI" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_ll8RQxFadewaqpiZ.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="124" aria-labelledby="124"><div tabindex="-1" class="be"><a href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----0---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(3).jpg"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="125" aria-labelledby="125"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----0---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Level Up Coding</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="126" aria-labelledby="126"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@infin94?source=post_page---author_recirc--3bc057d27e85----0---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Hyunjong Lee</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://levelup.gitconnected.com/how-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985?source=post_page---author_recirc--3bc057d27e85----0---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">How I Built a Local MCP Server to Connect Obsidian with AI</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Using MCP to link Obsidian with local AI tools for smarter, context-aware assistance</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><span>Apr 28</span><div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" rel="noopener follow" href="https://levelup.gitconnected.com/how-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985?source=post_page---author_recirc--3bc057d27e85----0---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div><div class="ac" aria-hidden="false" aria-describedby="202" aria-labelledby="202"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>296</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="127" aria-labelledby="127"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>6</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="128" aria-labelledby="128"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F55121295a985&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985&amp;source=---author_recirc--3bc057d27e85----0-----------------bookmark_preview----35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://levelup.gitconnected.com/why-openai-suddenly-erased-jony-ive-from-their-website-5d6f431e5297" tabindex="0"><div class="aec"><div aria-label="Why OpenAI Suddenly Erased Jony Ive from their Website"><div class="aee aef aeg aeh aei"><img alt="Why OpenAI Suddenly Erased Jony Ive from their Website" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_SzRnP8MBOCYG11qY.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="129" aria-labelledby="129"><div tabindex="-1" class="be"><a href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----1---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(3).jpg"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----1---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Level Up Coding</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="131" aria-labelledby="131"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://dhruvam.medium.com/?source=post_page---author_recirc--3bc057d27e85----1---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Michele Ronan</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://levelup.gitconnected.com/why-openai-suddenly-erased-jony-ive-from-their-website-5d6f431e5297?source=post_page---author_recirc--3bc057d27e85----1---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Why OpenAI Suddenly Erased Jony Ive from their Website</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">A billion-dollar collaboration… quietly wiped out overnight. Here’s what happened.</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="132" aria-labelledby="132"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="133" aria-labelledby="133"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div><span>Jun 25</span><div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" rel="noopener follow" href="https://levelup.gitconnected.com/why-openai-suddenly-erased-jony-ive-from-their-website-5d6f431e5297?source=post_page---author_recirc--3bc057d27e85----1---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div><div class="ac" aria-hidden="false" aria-describedby="204" aria-labelledby="204"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>2.2K</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="134" aria-labelledby="134"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>72</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="135" aria-labelledby="135"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d6f431e5297&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-openai-suddenly-erased-jony-ive-from-their-website-5d6f431e5297&amp;source=---author_recirc--3bc057d27e85----1-----------------bookmark_preview----35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://levelup.gitconnected.com/apple-just-fired-their-liquid-design-team-lead-7d996af48c92" tabindex="0"><div class="aec"><div aria-label="Did Apple Just Fire Their Liquid Design Team Lead"><div class="aee aef aeg aeh aei"><img alt="Did Apple Just Fire Their Liquid Design Team Lead" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_L6vWdfakoImeTEia.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="136" aria-labelledby="136"><div tabindex="-1" class="be"><a href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----2---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(3).jpg"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="137" aria-labelledby="137"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85----2---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Level Up Coding</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="138" aria-labelledby="138"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://dhruvam.medium.com/?source=post_page---author_recirc--3bc057d27e85----2---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Michele Ronan</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://levelup.gitconnected.com/apple-just-fired-their-liquid-design-team-lead-7d996af48c92?source=post_page---author_recirc--3bc057d27e85----2---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Did Apple Just Fire Their Liquid Design Team Lead</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">And lost $75 billion in Market Value as the Stock fell 2.5% during WWDC Live Keynote</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="139" aria-labelledby="139"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="140" aria-labelledby="140"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div><span>Jun 11</span><div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" rel="noopener follow" href="https://levelup.gitconnected.com/apple-just-fired-their-liquid-design-team-lead-7d996af48c92?source=post_page---author_recirc--3bc057d27e85----2---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" data-discover="true"><div><div class="ac" aria-hidden="false" aria-describedby="206" aria-labelledby="206"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1.2K</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="141" aria-labelledby="141"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>58</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="142" aria-labelledby="142"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d996af48c92&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fapple-just-fired-their-liquid-design-team-lead-7d996af48c92&amp;source=---author_recirc--3bc057d27e85----2-----------------bookmark_preview----35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://medium.com/@infin94/understanding-the-seq2seq-model-what-you-should-know-before-understanding-transformers-e5891bcd57ec" tabindex="0"><div class="aec"><div aria-label="Understanding the Seq2Seq Model — What You Should Know Before Understanding Transformers"><div class="aee aef aeg aeh aei"><img alt="Understanding the Seq2Seq Model — What You Should Know Before Understanding Transformers" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_RrkAnCj1dxjRFUj5.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="143" aria-labelledby="143"><div tabindex="-1" class="be"><a tabindex="-1" href="https://medium.com/@infin94?source=post_page---author_recirc--3bc057d27e85----3---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><div class="m fl"><img alt="Hyunjong Lee" class="m fd bx aev aew cx" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_YSUBDzfIPKC07AmW14SNkg@2x(3).jpg"><div class="ft bx m aev aew fu o aj fv"></div></div></a></div></div></div></div></div><div><div class="m" aria-hidden="false" aria-describedby="144" aria-labelledby="144"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@infin94?source=post_page---author_recirc--3bc057d27e85----3---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Hyunjong Lee</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/@infin94/understanding-the-seq2seq-model-what-you-should-know-before-understanding-transformers-e5891bcd57ec?source=post_page---author_recirc--3bc057d27e85----3---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><div title="Understanding the Seq2Seq Model — What You Should Know Before Understanding Transformers"><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Understanding the Seq2Seq Model — What You Should Know Before Understanding Transformers</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">This is a good starting point or review to understand the inner concepts of the Transformer and how the DL models generate text.</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><span>Jul 16, 2024</span><div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://medium.com/@infin94/understanding-the-seq2seq-model-what-you-should-know-before-understanding-transformers-e5891bcd57ec?source=post_page---author_recirc--3bc057d27e85----3---------------------35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="145" aria-labelledby="145"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe5891bcd57ec&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40infin94%2Funderstanding-the-seq2seq-model-what-you-should-know-before-understanding-transformers-e5891bcd57ec&amp;source=---author_recirc--3bc057d27e85----3-----------------bookmark_preview----35131d35_d100_43a1_8468_ba4d4bfe5267--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="vt bh wu dk dl agh agi agj"></div><div class="ac ul uk ju jw jy"><a class="bf b bg ab bk tq wd we wf mx mu wg ev ew ex wh wi wj fa wk wl wm wn wo fb fc fd bm fe ff" href="https://medium.com/@infin94?source=post_page---author_recirc--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m ff">See all from Hyunjong Lee</div></a><div class="agk agl agm agn ago agp agq agr ags mo m"><a class="bf b bg ab bk tq wd we wf mx mu wg ev ew ex wh wi wj fa wk wl wm wn wo fb fc fd bm fe ff" href="https://levelup.gitconnected.com/?source=post_page---author_recirc--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m ff">See all from Level Up Coding</div></a></div></div></div></div><div class="vt bh wu agt agu agv agw agx"></div><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="agy agz m"><h2 class="bf gj or ot gl ou ow gn ox oz pa pb pd pe pf ph pi bk">Recommended from Medium</h2><div class="ry rz sa sb sc m"><div class="acb ac lu kl acc acd ace acf acg ach aci acj ack acl acm acn aco acp acq"><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://levelup.gitconnected.com/implementing-9-techniques-to-optimize-ai-agent-memory-67d813e3d796" tabindex="0"><div class="aec"><div aria-label="Implementing 9 Techniques to Optimize AI Agent Memory"><div class="aee aef aeg aeh aei"><img alt="Implementing 9 Techniques to Optimize AI Agent Memory" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_FR3VjWxc0adX5YfTatKluw.png"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="146" aria-labelledby="146"><div tabindex="-1" class="be"><a href="https://levelup.gitconnected.com/?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="fl"><img alt="Level Up Coding" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_5D9oYBd58pyjMkV_5-zXXQ(3).jpg"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="147" aria-labelledby="147"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://levelup.gitconnected.com/?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Level Up Coding</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="148" aria-labelledby="148"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@fareedkhandev?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Fareed Khan</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" rel="noopener follow" href="https://levelup.gitconnected.com/implementing-9-techniques-to-optimize-ai-agent-memory-67d813e3d796?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" data-discover="true"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Implementing 9 Techniques to Optimize AI Agent Memory</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">From sliding windows to OS-like memory tested and explained</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="149" aria-labelledby="149"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="150" aria-labelledby="150"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div>3d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" rel="noopener follow" href="https://levelup.gitconnected.com/implementing-9-techniques-to-optimize-ai-agent-memory-67d813e3d796?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" data-discover="true"><div><div class="ac" aria-hidden="false" aria-describedby="208" aria-labelledby="208"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>436</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="151" aria-labelledby="151"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>8</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="152" aria-labelledby="152"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67d813e3d796&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fimplementing-9-techniques-to-optimize-ai-agent-memory-67d813e3d796&amp;source=---read_next_recirc--3bc057d27e85----0-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://medium.com/@piyushagni5/build-your-own-mcp-server-and-client-a-complete-guide-ee1451068458" tabindex="0"><div class="aec"><div aria-label="Build Your Own MCP Server and Client: A Complete Guide"><div class="aee aef aeg aeh aei"><img alt="Build Your Own MCP Server and Client: A Complete Guide" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_4ZfJlUrcseoYFFfW.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="153" aria-labelledby="153"><div tabindex="-1" class="be"><a tabindex="-1" href="https://medium.com/@piyushagni5?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="m fl"><img alt="Piyush Agnihotri" class="m fd bx aev aew cx" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_pKV1QsobYv5WWiTJwAF71Q.jpg"><div class="ft bx m aev aew fu o aj fv"></div></div></a></div></div></div></div></div><div><div class="m" aria-hidden="false" aria-describedby="154" aria-labelledby="154"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@piyushagni5?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Piyush Agnihotri</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/@piyushagni5/build-your-own-mcp-server-and-client-a-complete-guide-ee1451068458?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Build Your Own MCP Server and Client: A Complete Guide</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">A beginner-friendly, end-to-end walkthrough of building and testing Model Context Protocol applications.</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="155" aria-labelledby="155"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="156" aria-labelledby="156"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div>3d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://medium.com/@piyushagni5/build-your-own-mcp-server-and-client-a-complete-guide-ee1451068458?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div><div class="ac" aria-hidden="false" aria-describedby="210" aria-labelledby="210"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>533</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="157" aria-labelledby="157"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>4</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="158" aria-labelledby="158"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fee1451068458&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40piyushagni5%2Fbuild-your-own-mcp-server-and-client-a-complete-guide-ee1451068458&amp;source=---read_next_recirc--3bc057d27e85----1-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div class="acb ac lu kl acc acd ace acf acg ach aci acj ack acl acm acn aco acp acq"><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://medium.com/coding-beauty/mcp-servers-479614e4b74c" tabindex="0"><div class="aec"><div aria-label="These MCP servers are amazing for coding"><div class="aee aef aeg aeh aei"><img alt="These MCP servers are amazing for coding" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_SZ0akeZuE4WhwjCntsDo6g.png"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="159" aria-labelledby="159"><div tabindex="-1" class="be"><a href="https://medium.com/coding-beauty?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="fl"><img alt="Coding Beauty" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_ViyWUoh4zqx294no1eENxw.png"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="160" aria-labelledby="160"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/coding-beauty?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Coding Beauty</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="161" aria-labelledby="161"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@tariibaba?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Tari Ibaba</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/coding-beauty/mcp-servers-479614e4b74c?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">These MCP servers are amazing for coding</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Start using MCP. NOW.</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="162" aria-labelledby="162"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="163" aria-labelledby="163"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div>5d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://medium.com/coding-beauty/mcp-servers-479614e4b74c?source=post_page---read_next_recirc--3bc057d27e85----0---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div><div class="ac" aria-hidden="false" aria-describedby="212" aria-labelledby="212"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>347</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="164" aria-labelledby="164"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>5</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="165" aria-labelledby="165"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F479614e4b74c&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fcoding-beauty%2Fmcp-servers-479614e4b74c&amp;source=---read_next_recirc--3bc057d27e85----0-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://garysvenson09.medium.com/how-to-run-kimi-k2-inside-claude-code-the-ultimate-open-source-ai-coding-combo-7b248adcf336" tabindex="0"><div class="aec"><div aria-label="How to Run Kimi K2 Inside Claude Code: The Ultimate Open-Source AI Coding Combo"><div class="aee aef aeg aeh aei"><img alt="How to Run Kimi K2 Inside Claude Code: The Ultimate Open-Source AI Coding Combo" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_baL7_gmS5EbVqimw.png"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="166" aria-labelledby="166"><div tabindex="-1" class="be"><a tabindex="-1" href="https://garysvenson09.medium.com/?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="m fl"><img alt="Gary Svenson" class="m fd bx aev aew cx" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_lZW-IQU2EQXpcFQ3elV9AQ.png"><div class="ft bx m aev aew fu o aj fv"></div></div></a></div></div></div></div></div><div><div class="m" aria-hidden="false" aria-describedby="167" aria-labelledby="167"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://garysvenson09.medium.com/?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Gary Svenson</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://garysvenson09.medium.com/how-to-run-kimi-k2-inside-claude-code-the-ultimate-open-source-ai-coding-combo-7b248adcf336?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div title="How to Run Kimi K2 Inside Claude Code: The Ultimate Open-Source AI Coding Combo"><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">How to Run Kimi K2 Inside Claude Code: The Ultimate Open-Source AI Coding Combo</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">The AI coding landscape just got a major upgrade. Developers are now running Moonshot AI’s Kimi K2 model directly within the Claude Code…</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc">3d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://garysvenson09.medium.com/how-to-run-kimi-k2-inside-claude-code-the-ultimate-open-source-ai-coding-combo-7b248adcf336?source=post_page---read_next_recirc--3bc057d27e85----1---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div><div class="ac" aria-hidden="false" aria-describedby="214" aria-labelledby="214"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>213</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="168" aria-labelledby="168"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>10</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="169" aria-labelledby="169"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b248adcf336&amp;operation=register&amp;redirect=https%3A%2F%2Fgarysvenson09.medium.com%2Fhow-to-run-kimi-k2-inside-claude-code-the-ultimate-open-source-ai-coding-combo-7b248adcf336&amp;source=---read_next_recirc--3bc057d27e85----1-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://medium.com/@AskWithAi/i-used-n8n-chatgpt-reddit-to-make-2-4k-in-7-days-heres-how-96a3c4e25fb6" tabindex="0"><div class="aec"><div aria-label="I Used n8n + ChatGPT + Reddit to Make $2.4K in 7 Days — Here’s How"><div class="aee aef aeg aeh aei"><img alt="I Used n8n + ChatGPT + Reddit to Make $2.4K in 7 Days — Here’s How" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_rF48ROeNIjocBCT-DAht-Q.png"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="170" aria-labelledby="170"><div tabindex="-1" class="be"><a tabindex="-1" href="https://medium.com/@AskWithAi?source=post_page---read_next_recirc--3bc057d27e85----2---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="m fl"><img alt="Ask With Ai" class="m fd bx aev aew cx" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_IGE6n8vMgEkdjA0b_GhXMg.jpg"><div class="ft bx m aev aew fu o aj fv"></div></div></a></div></div></div></div></div><div><div class="m" aria-hidden="false" aria-describedby="171" aria-labelledby="171"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@AskWithAi?source=post_page---read_next_recirc--3bc057d27e85----2---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Ask With Ai</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/@AskWithAi/i-used-n8n-chatgpt-reddit-to-make-2-4k-in-7-days-heres-how-96a3c4e25fb6?source=post_page---read_next_recirc--3bc057d27e85----2---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div title=""><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">I Used n8n + ChatGPT + Reddit to Make $2.4K in 7 Days — Here’s How</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">My side blog— fully automated system (Game Changer)</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="172" aria-labelledby="172"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="173" aria-labelledby="173"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div>3d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://medium.com/@AskWithAi/i-used-n8n-chatgpt-reddit-to-make-2-4k-in-7-days-heres-how-96a3c4e25fb6?source=post_page---read_next_recirc--3bc057d27e85----2---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div><div class="ac" aria-hidden="false" aria-describedby="216" aria-labelledby="216"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>579</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="174" aria-labelledby="174"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>31</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="175" aria-labelledby="175"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96a3c4e25fb6&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40AskWithAi%2Fi-used-n8n-chatgpt-reddit-to-make-2-4k-in-7-days-heres-how-96a3c4e25fb6&amp;source=---read_next_recirc--3bc057d27e85----2-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="vt bh wu mr"></div></div></div></div></div></div></div></div></article></div></div><div class="acr acs act vf acu acv acw ve acx acy acz ada adb adc add ade adf adg adh adi adj"><div class="adk adl adm adn ado dw m"><article class="dw" data-testid="post-preview"><div class="dw ty m"><div class="bh dw"><div class="dw m"><div class="fl dw adp adq adr ads adt adu adv adw adx ady adz aea aeb" role="link" data-href="https://ai.gopubby.com/liberating-api-access-using-agentic-mcp-system-powered-by-a-local-llm-209efc94642e" tabindex="0"><div class="aec"><div aria-label="Liberating API Access using an Agentic MCP System Powered by a Local LLM"><div class="aee aef aeg aeh aei"><img alt="Liberating API Access using an Agentic MCP System Powered by a Local LLM" class="bh aej aek ael bw" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/0_wRFenYG9nfU0ticB.jpg"></div></div></div><div class="aed ac cb co"><div class="ac co yi bh aem aen aeo aep"><div class="aeq aer aes aet aeu ac r"><div class="tp m"><div><div class="m" aria-hidden="false" aria-describedby="176" aria-labelledby="176"><div tabindex="-1" class="be"><a href="https://ai.gopubby.com/?source=post_page---read_next_recirc--3bc057d27e85----3---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div class="fl"><img alt="AI Advances" class="cx hk m aew aev" width="20" height="20" loading="lazy" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1_R8zEd59FDf0l8Re94ImV0Q.png"><div class="hk m aev aew fu o ft fv"></div></div></a></div></div></div></div><div class="vg m fz"><p class="bf b dv ab du">In</p></div><div class="m"><div><div class="m" aria-hidden="false" aria-describedby="177" aria-labelledby="177"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://ai.gopubby.com/?source=post_page---read_next_recirc--3bc057d27e85----3---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">AI Advances</p></a></div></div></div></div><div class="afa m"><p class="bf b dv ab du">by</p></div><div><div class="m" aria-hidden="false" aria-describedby="178" aria-labelledby="178"><div tabindex="-1" class="be"><a class="ag ah ai fh ak al am an ao ap aq ar as kj ac r" href="https://medium.com/@heelara?source=post_page---read_next_recirc--3bc057d27e85----3---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><p class="bf b dv ab fx aex fy rd aey rf aez rg bk">Kennedy Selvadurai, PhD</p></a></div></div></div></div><div class="afb m afc afd afe aff afg hq"><div class="afh afi afj afk afl afm afn afo"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://ai.gopubby.com/liberating-api-access-using-agentic-mcp-system-powered-by-a-local-llm-209efc94642e?source=post_page---read_next_recirc--3bc057d27e85----3---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div title="Liberating API Access using an Agentic MCP System Powered by a Local LLM"><h2 class="bf ip or ot afp afq gl ou ow afr afs gn go gp aft afu gq gr gs afv afw gt gu gv afx afy gw fx fy rd rf rg bk">Liberating API Access using an Agentic MCP System Powered by a Local LLM</h2></div><div class="afz m"><h3 class="bf b gz ab fx rc fy rd re rf rg du">Building a MCP server for RESTful API access and AI agentic MCP client to consume the endpoints made super easy with FastMCP.</h3></div></a></div></div><span class="bf b dv ab du"><div class="uw ac cp af"><div class="ac r agc"><div class="ty ac"><div class="bm" aria-hidden="false" aria-describedby="179" aria-labelledby="179"><button class="m aj ap an" aria-label="Member-only story"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="180" aria-labelledby="180"><div tabindex="-1" class="be"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div></div>6d ago<div class=""><div class="fl aga dh ac r"><div class="fu hh agb ac r agc"><div class="fg dh dj m cx"></div></div><a class="fu ms agb ac r agc" tabindex="-1" href="https://ai.gopubby.com/liberating-api-access-using-agentic-mcp-system-powered-by-a-local-llm-209efc94642e?source=post_page---read_next_recirc--3bc057d27e85----3---------------------43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><div><div class="ac" aria-hidden="false" aria-describedby="218" aria-labelledby="218"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>243</span></div></div></div></div><div><div class="ac" aria-hidden="false" aria-describedby="181" aria-labelledby="181"><div tabindex="-1" class="be"><div class="ac r agd"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#6B6B6B" aria-labelledby="response-filled-16px-desc" viewBox="0 0 16 16"><desc id="response-filled-16px-desc">A response icon</desc><path fill="#6B6B6B" d="M12.344 11.458A5.28 5.28 0 0 0 14 7.526C14 4.483 11.391 2 8.051 2S2 4.483 2 7.527c0 3.051 2.712 5.526 6.059 5.526a6.6 6.6 0 0 0 1.758-.236q.255.223.554.414c.784.51 1.626.768 2.512.768a.37.37 0 0 0 .355-.214.37.37 0 0 0-.03-.384 4.7 4.7 0 0 1-.857-1.958v.014z"></path></svg><span>1</span></div></div></div></div></a></div></div></div><div class="ac r age agf"><div class=""><div><div class="bm" aria-hidden="false" aria-describedby="182" aria-labelledby="182"><div tabindex="-1" class="be"><span><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F209efc94642e&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fliberating-api-access-using-agentic-mcp-system-powered-by-a-local-llm-209efc94642e&amp;source=---read_next_recirc--3bc057d27e85----3-----------------bookmark_preview----43f1c270_3651_4ce6_b831_b3f117dbff4e--------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mx agg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="vt bh wu dk dl agh agi agj"></div><a class="bf b bg ab bk tq wd we wf mx mu wg ev ew ex wh wi wj fa wk wl wm wn wo fb fc fd bm fe ff" href="https://medium.com/?source=post_page---read_next_recirc--3bc057d27e85---------------------------------------" rel="noopener follow"><div class="m ff">See more recommendations</div></a></div></div></div><div class="i l k"><div class="vt bh wu wv"></div><div class="ac cb"><div class="ci bh hw hx hy hz"><div class="ww ac lu kl"><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://help.medium.com/hc/en-us?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Help</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.statuspage.io/?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Status</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/about?autoplay=1&amp;source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">About</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Careers</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="mailto:pressinquiries@medium.com" rel="noopener follow"><p class="bf b dv ab du">Press</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://blog.medium.com/?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Blog</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Privacy</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Rules</p></a></div><div class="wx wy m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Terms</p></a></div><div class="wx m"><a class="ag ah ai fh ak al am an ao ap aq ar as at au" href="https://speechify.com/medium?source=post_page-----3bc057d27e85---------------------------------------" rel="noopener follow"><p class="bf b dv ab du">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20250717-141328-cb0dd1daf8"</script><script>window.__GRAPHQL_URI__ = "https://levelup.gitconnected.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-3bc057d27e85","user-ecf7619248d7","collection-5517fd7b58a6"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"pubFeaturingPostPageLabelEnabled":false,"shouldFollowPostQueryEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"5517fd7b58a6","explicit":true},"viewerIsBot":false},"debug":{"requestId":"cdf9fd2f-6684-4b65-a7c3-3fa9736b8f10","requestTag":"","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-f0cf916795dd0a12a863ca5a0e694526-9ae4ec5b8218456d-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85","host":"levelup.gitconnected.com","hostname":"levelup.gitconnected.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"staticRouterContext":{"route":{"name":"ShowPostUnderCollection"},"statusCode":200},"toastQueue":[],"currentToast":null},"config":{"nodeEnv":"production","version":"main-20250717-141328-cb0dd1daf8","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","iosAppId":"828256236","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20250717-141328-cb0dd1daf8","commit":"cb0dd1daf86b54f9af934b638b0f184263e618c7"}},"datacenter":"us"},"googleAdsCode":"AW-17106321204","googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"167cff2a3d17ac1e64d0762539978f2d54c0058886e8b3c8a03a725a83012ec0","height":630,"width":1200},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"enable_post_publish_permission_check","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_story_page_nofollow_meta_tag","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_eventstats_event_processing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_rating_prompt_stories_read_threshold","valueType":{"__typename":"VariantFlagNumber","value":2}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ranker_v10","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pre_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"num_post_bottom_responses_to_show","valueType":{"__typename":"VariantFlagNumber","value":3}},{"__typename":"VariantFlag","name":"android_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"rex_generator_max_candidates","valueType":{"__typename":"VariantFlagNumber","value":1000}},{"__typename":"VariantFlag","name":"ml_rank_enable_ranker_member_split_v1","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_inline_comments","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_update_explore_wtf","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_update_topic_portals_wtf","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_branch_openinapp_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_gql_client_events","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_branch_openinapp_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_abandoned_paywall_promotion_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_deviant_get_variant_flag_from_medium2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_deprecate_legacy_providers_v3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"goliath_externalsearch_enable_comment_deindexation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_diversification_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hybrid_ranking_model","valueType":{"__typename":"VariantFlagString","value":"experiment"}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recaptcha_enterprise","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_validate_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_bg_post_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_image_sharer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_switch_plan_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_abandoned_cart_promotion_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_user_profile_nofollow_attribute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kiln_enable_new_digest_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_rex_pub_featuring_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reengagement_notification_duration","valueType":{"__typename":"VariantFlagNumber","value":3}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_post_viewed_digest_filtering","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_archive_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_delinquency_and_forfeiture","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_dense_post_preview","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium_com_canonical_urls","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_knock_gift_membership_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mobile_newsletter_setting_in_publishing_details","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_knock_user_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"rex_enable_filter_viewed_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_knock_poc_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_conversion_ranker_v2","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_knock_partner_program_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier_badge","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_sharer_create_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_premium_plan","valueType":{"__typename":"VariantFlagString","value":"12a660186432"}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_maim_the_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"mobile_custom_app_icon","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sunset_lo_non_moc_upsell","valueType":{"__typename":"VariantFlagString","value":"group2"}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_country_expansion","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_knock_story_response_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_bottom_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_premium_plan","valueType":{"__typename":"VariantFlagString","value":"4a442ace1476"}},{"__typename":"VariantFlag","name":"enable_see_pronouns","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_winback_promotion_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_boost_experiment","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lo_homepage","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_all_recs_surfaces","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_intrinsic_automatic_actions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trust_service_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_remove_canonical_url_for_pub_editor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_knock_writer_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mobile_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dynamic_paywall_optin","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_stripe_customers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_engagement_service_publish_response","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_bottom_responses_native","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_topic_portals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notification_unsubscribe_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_bottom_responses_input","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_knock_membership_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_manage_membership_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_reliable_follow_experience_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"get_highlights_from_engagement","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_configure_pronouns","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_conversion_model_v2","valueType":{"__typename":"VariantFlagString","value":"group_2"}},{"__typename":"VariantFlag","name":"enable_cancellation_discount_v1_1","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_c","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_first_story","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recommended_publishers_query","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_pub_recs_ui","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"levelup.gitconnected.com\"})":{"__ref":"Collection:5517fd7b58a6"},"postResult({\"id\":\"3bc057d27e85\"})":{"__ref":"Post:3bc057d27e85"},"variantFlagWithCustomIDs({\"input\":{\"flagName\":\"enable_lite_publications\",\"publicationId\":\"5517fd7b58a6\"}})":{"__typename":"VariantFlag","name":"enable_lite_publications","valueType":{"__typename":"VariantFlagBoolean","value":true}},"collection({\"id\":\"5517fd7b58a6\"})":{"__ref":"Collection:5517fd7b58a6"}},"ImageMetadata:1*MMpkJtmeCME-6BmGNH5l8A.png":{"__typename":"ImageMetadata","id":"1*MMpkJtmeCME-6BmGNH5l8A.png"},"Collection:5517fd7b58a6":{"__typename":"Collection","id":"5517fd7b58a6","favicon":{"__ref":"ImageMetadata:1*MMpkJtmeCME-6BmGNH5l8A.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFE7F4FF","point":0},{"__typename":"ColorPoint","color":"#FFE3F2FF","point":0.1},{"__typename":"ColorPoint","color":"#FFDEF1FF","point":0.2},{"__typename":"ColorPoint","color":"#FFDAEFFF","point":0.3},{"__typename":"ColorPoint","color":"#FFD5EDFF","point":0.4},{"__typename":"ColorPoint","color":"#FFD0ECFF","point":0.5},{"__typename":"ColorPoint","color":"#FFCBEAFF","point":0.6},{"__typename":"ColorPoint","color":"#FFC6E8FF","point":0.7},{"__typename":"ColorPoint","color":"#FFC1E6FF","point":0.8},{"__typename":"ColorPoint","color":"#FFBBE4FF","point":0.9},{"__typename":"ColorPoint","color":"#FFB6E3FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF4B84F3","point":0},{"__typename":"ColorPoint","color":"#FF497CDE","point":0.1},{"__typename":"ColorPoint","color":"#FF4572C9","point":0.2},{"__typename":"ColorPoint","color":"#FF4269B5","point":0.3},{"__typename":"ColorPoint","color":"#FF3D5FA0","point":0.4},{"__typename":"ColorPoint","color":"#FF38558C","point":0.5},{"__typename":"ColorPoint","color":"#FF334B79","point":0.6},{"__typename":"ColorPoint","color":"#FF2C4065","point":0.7},{"__typename":"ColorPoint","color":"#FF253451","point":0.8},{"__typename":"ColorPoint","color":"#FF1C283E","point":0.9},{"__typename":"ColorPoint","color":"#FF121A2A","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF3972E0","colorPoints":[{"__typename":"ColorPoint","color":"#FF3972E0","point":0},{"__typename":"ColorPoint","color":"#FF5083E6","point":0.1},{"__typename":"ColorPoint","color":"#FF6693EC","point":0.2},{"__typename":"ColorPoint","color":"#FF7AA3F1","point":0.3},{"__typename":"ColorPoint","color":"#FF8DB1F7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FBFFC","point":0.5},{"__typename":"ColorPoint","color":"#FFB2CDFF","point":0.6},{"__typename":"ColorPoint","color":"#FFC3DAFF","point":0.7},{"__typename":"ColorPoint","color":"#FFD5E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFE6F3FF","point":0.9},{"__typename":"ColorPoint","color":"#FFF6FFFF","point":1}]}},"domain":"levelup.gitconnected.com","slug":"gitconnected","googleAnalyticsId":"UA-110153932-1","name":"Level Up Coding","avatar":{"__ref":"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"},"description":"Coding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev","subscriberCount":256108,"latestPostsConnection({\"paging\":{\"limit\":1}})":{"__typename":"PostConnection","posts":[{"__ref":"Post:c4996168ed65"}]},"isAuroraVisible":false,"tintColor":"#FF3972E0","compatV3":{"__ref":"Publication:5517fd7b58a6"},"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:5517fd7b58a6-viewerId:lo_165a71c26036"},"twitterUsername":"gitconnected","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*s0Iaylh9dPk6zGjlVZasIA.jpeg"}},"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg":{"__typename":"ImageMetadata","id":"1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"},"User:b856005e5ecd":{"__typename":"User","id":"b856005e5ecd","customDomainState":null,"hasSubdomain":false,"username":"fareedkhandev"},"Post:c4996168ed65":{"__typename":"Post","id":"c4996168ed65","firstPublishedAt":1752676535070,"creator":{"__ref":"User:b856005e5ecd"},"collection":{"__ref":"Collection:5517fd7b58a6"},"isSeries":false,"mediumUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Fbuilding-an-ai-agent-to-play-a-3d-fps-game-using-ursina-deepseek-and-mistral-c4996168ed65","sequence":null,"uniqueSlug":"building-an-ai-agent-to-play-a-3d-fps-game-using-ursina-deepseek-and-mistral-c4996168ed65"},"Publication:5517fd7b58a6":{"__typename":"Publication","id":"5517fd7b58a6","theme":{"__typename":"PublicationTheme","accentColor":{"__typename":"ColorValue","rgb":"#3972E0"}}},"LinkedAccounts:ecf7619248d7":{"__typename":"LinkedAccounts","mastodon":null,"id":"ecf7619248d7"},"NewsletterV3:4cbad2968e52":{"__typename":"NewsletterV3","id":"4cbad2968e52","type":"NEWSLETTER_TYPE_AUTHOR","slug":"ecf7619248d7","name":"ecf7619248d7","collection":null,"user":{"__ref":"User:ecf7619248d7"}},"User:ecf7619248d7":{"__typename":"User","id":"ecf7619248d7","name":"Hyunjong Lee","username":"infin94","newsletterV3":{"__ref":"NewsletterV3:4cbad2968e52"},"linkedAccounts":{"__ref":"LinkedAccounts:ecf7619248d7"},"isSuspended":false,"imageId":"1*YSUBDzfIPKC07AmW14SNkg@2x.jpeg","customDomainState":null,"hasSubdomain":false,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":74,"followingCount":22,"collectionFollowingCount":13},"bio":"ML Researcher I love to do some experiments and improve something.","membership":{"__ref":"Membership:19d23f1a-e698-4ff1-83d3-c46b55765da2"},"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:ecf7619248d7-viewerId:lo_165a71c26036"},"twitterScreenName":""},"Membership:19d23f1a-e698-4ff1-83d3-c46b55765da2":{"__typename":"Membership","tier":"MEMBER","id":"19d23f1a-e698-4ff1-83d3-c46b55765da2"},"Paragraph:437c65dda6a1_0":{"__typename":"Paragraph","id":"437c65dda6a1_0","name":"36bd","type":"H3","href":null,"layout":null,"metadata":null,"text":"How I Built a Tool-Calling Llama Agent with a Custom MCP Server","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*atue7XX9h3JTZxhJQuGyxg.png":{"__typename":"ImageMetadata","id":"1*atue7XX9h3JTZxhJQuGyxg.png","originalHeight":1024,"originalWidth":1536,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_1":{"__typename":"Paragraph","id":"437c65dda6a1_1","name":"e359","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*atue7XX9h3JTZxhJQuGyxg.png"},"text":"Image generated by ChatGPT","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_2":{"__typename":"Paragraph","id":"437c65dda6a1_2","name":"2437","type":"H3","href":null,"layout":null,"metadata":null,"text":"1. Introduction","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_3":{"__typename":"Paragraph","id":"437c65dda6a1_3","name":"cd8e","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, I’ll walk through the development of a local AI agent that communicates with a previously built MCP(Model Context Protocol) server to generate context-aware responses using tool-calling.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_4":{"__typename":"Paragraph","id":"437c65dda6a1_4","name":"8cd4","type":"P","href":null,"layout":null,"metadata":null,"text":"Why I started this project","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_5":{"__typename":"Paragraph","id":"437c65dda6a1_5","name":"bab7","type":"P","href":null,"layout":null,"metadata":null,"text":"This article is a follow-up to my previous article, where I introduced a custom MCP server that connects to my personal Obsidian knowledge base. Rather than using the official MCP server with file system access, I chose to build my own for several reasons:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_6":{"__typename":"Paragraph","id":"437c65dda6a1_6","name":"dba5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"To enforce read-only access to my file system","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_7":{"__typename":"Paragraph","id":"437c65dda6a1_7","name":"b0cb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"To avoid exposing directory structure of file paths to external AI model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_8":{"__typename":"Paragraph","id":"437c65dda6a1_8","name":"0b48","type":"ULI","href":null,"layout":null,"metadata":null,"text":"To deeply understand how the MCP works by implementing it","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_9":{"__typename":"Paragraph","id":"437c65dda6a1_9","name":"6af7","type":"P","href":null,"layout":null,"metadata":null,"text":"For more details, please refer to my previous article","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_10":{"__typename":"Paragraph","id":"437c65dda6a1_10","name":"bace","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"How I Built a Local MCP Server to Connect Obsidian with AI\nUsing MCP to link Obsidian with local AI tools for smarter, context-aware assistancelevelup.gitconnected.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":167,"href":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":58,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":59,"end":143,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-local-mcp-server-to-connect-obsidian-with-ai-55121295a985","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*ll8RQxFadewaqpiZ"}},"Paragraph:437c65dda6a1_11":{"__typename":"Paragraph","id":"437c65dda6a1_11","name":"9fb9","type":"P","href":null,"layout":null,"metadata":null,"text":"After building the MCP server, I wanted to address a new challenge: dependency on external AI models. While Claude has demonstrated excellent reasoning capabilities, its usage is limited unless you’re on a paid plan. More importantly, relying on external AI services means that the contents of my private knowledge notes are still being sent outside my local environment.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":68,"end":100,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_12":{"__typename":"Paragraph","id":"437c65dda6a1_12","name":"70a3","type":"P","href":null,"layout":null,"metadata":null,"text":"This article covers the next steps in building a fully local, private agent:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_13":{"__typename":"Paragraph","id":"437c65dda6a1_13","name":"0af9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Implementing an MCP client that connects to the MCP server","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_14":{"__typename":"Paragraph","id":"437c65dda6a1_14","name":"f089","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Integrating a local LLM model for response generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_15":{"__typename":"Paragraph","id":"437c65dda6a1_15","name":"8695","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Building an LLM agent that uses both MCP and the model to answer questions","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_16":{"__typename":"Paragraph","id":"437c65dda6a1_16","name":"f4df","type":"P","href":null,"layout":null,"metadata":null,"text":"For this purpose, I chose not to use frameworks like LangChain, so the entire flow is transparent and easy to understand.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_17":{"__typename":"Paragraph","id":"437c65dda6a1_17","name":"586d","type":"H3","href":null,"layout":null,"metadata":null,"text":"2. Integration of sLLM with Tool-Calling Support","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_18":{"__typename":"Paragraph","id":"437c65dda6a1_18","name":"2364","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.1. Small Language Model for Local Use","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_19":{"__typename":"Paragraph","id":"437c65dda6a1_19","name":"61dc","type":"P","href":null,"layout":null,"metadata":null,"text":"In agent development, the most critical thing is the brain — the LLM. The quality of the generated responses depends heavily on the model’s reasoning ability. However, since the goal is to run everything locally, using massive LLM is not feasible. Instead, we must rely on small Language Model(sLLM) that can run on a local GPU or CPU environment.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_20":{"__typename":"Paragraph","id":"437c65dda6a1_20","name":"d8d9","type":"P","href":null,"layout":null,"metadata":null,"text":"But not all sLLMs are suitable. If the model’s response quality is too low or it lacks the ability to follow tool-calling instructions, it becomes unusable for this kind of agent architecture.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_21":{"__typename":"Paragraph","id":"437c65dda6a1_21","name":"9dd2","type":"P","href":null,"layout":null,"metadata":null,"text":"Previously, I experimented with the Llama 3.1 8B-Instruct model, which delivered impressive results. I used it in a project where multiple models, each with different system prompts(personas), engaged in discussions on selected topics to generate synthetic(artificial) text data. If you’re interested in the details, please check out the article below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_22":{"__typename":"Paragraph","id":"437c65dda6a1_22","name":"2b75","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Leveraging AI Conversations to Generate Synthetic Text Data with Llama 3.1\nExploit Llama to generate synthetic data instead of collecting text data which is hard to findmedium.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":179,"href":"https:\u002F\u002Fmedium.com\u002F@infin94\u002Fkickstart-your-research-instantly-generate-synthetic-text-data-with-llama-3-1-56eaee6fbf48","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":74,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":75,"end":169,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fmedium.com\u002F@infin94\u002Fkickstart-your-research-instantly-generate-synthetic-text-data-with-llama-3-1-56eaee6fbf48","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"1*53OcJXxL_p9yhhxD-jQ0Hw.png"}},"Paragraph:437c65dda6a1_23":{"__typename":"Paragraph","id":"437c65dda6a1_23","name":"3140","type":"P","href":null,"layout":null,"metadata":null,"text":"While the Llama 3.1 8B-Instruct model also supports tool-calling, for this project, I opted for Llama 3.2 version model. The 1B and 3B models from Llama 3.2 are lightweight models designed for on-device agentic applications, which keep all data local and help preserve user privacy.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_24":{"__typename":"Paragraph","id":"437c65dda6a1_24","name":"f2c2","type":"P","href":null,"layout":null,"metadata":null,"text":"According to Meta’s benchmarking results, the Llama 3.2 models strike a good balance between size and performance. Despite their smaller size, they offer reasonable response quality and support for tool-calling, making them well-suited for this project.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_25":{"__typename":"Paragraph","id":"437c65dda6a1_25","name":"82e1","type":"P","href":null,"layout":null,"metadata":null,"text":"As explained in Meta’s official blog post, the Llama 3.2 models were created by applying structured pruning to the Llama 3.1 8B model in a single-shot manner. To recover performance after pruning, Meta used knowledge distillation from multiple Llama 3.1 models, as illustrated in the diagram below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*NsF2TP5CznxZDPG1q-qCtw.png":{"__typename":"ImageMetadata","id":"1*NsF2TP5CznxZDPG1q-qCtw.png","originalHeight":2029,"originalWidth":3840,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_26":{"__typename":"Paragraph","id":"437c65dda6a1_26","name":"8bf5","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*NsF2TP5CznxZDPG1q-qCtw.png"},"text":"Llama 3.2 1B\u002F3B Pruning and Distillation Process (Image by Meta AI)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_27":{"__typename":"Paragraph","id":"437c65dda6a1_27","name":"b355","type":"P","href":null,"layout":null,"metadata":null,"text":"I won’t go into the technical details here. If you’re curious, I encourage you to read through Meta’s official blog post.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_28":{"__typename":"Paragraph","id":"437c65dda6a1_28","name":"7514","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Llama 3.2: Revolutionizing edge AI and vision with open, customizable models\nToday, we're releasing Llama 3.2, which includes small and medium-sized vision LLMs, and lightweight, text-only models…ai.meta.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":207,"href":"https:\u002F\u002Fai.meta.com\u002Fblog\u002Fllama-3-2-connect-2024-vision-edge-mobile-devices\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":77,"end":196,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fai.meta.com\u002Fblog\u002Fllama-3-2-connect-2024-vision-edge-mobile-devices\u002F","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*q2xQIQiK-PqOM16G"}},"Paragraph:437c65dda6a1_29":{"__typename":"Paragraph","id":"437c65dda6a1_29","name":"b499","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.1. The Tool Calling Process of LLM","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_30":{"__typename":"Paragraph","id":"437c65dda6a1_30","name":"a524","type":"P","href":null,"layout":null,"metadata":null,"text":"How does the LLM invoke a tool and generate a response? The overall tool-calling process is illustrated below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_31":{"__typename":"Paragraph","id":"437c65dda6a1_31","name":"7e3f","type":"P","href":null,"layout":null,"metadata":null,"text":"When information about available tools is provided — either through the system prompt or user prompt — the LLM determines whether a tool should be invoked. If so, it generates a function call definition as its response.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_32":{"__typename":"Paragraph","id":"437c65dda6a1_32","name":"c6ad","type":"P","href":null,"layout":null,"metadata":null,"text":"The LLM application then parses the function call, executes the corresponding tool, and feeds the result back to the model. Based on the tool’s output, the model can generate a synthesized response.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GMjXIiLr1OPG6UK99UxwpQ.png":{"__typename":"ImageMetadata","id":"1*GMjXIiLr1OPG6UK99UxwpQ.png","originalHeight":1279,"originalWidth":3304,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_33":{"__typename":"Paragraph","id":"437c65dda6a1_33","name":"e31f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GMjXIiLr1OPG6UK99UxwpQ.png"},"text":"Response Generation Flow with Tool Calling (Image by Meta AI)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_34":{"__typename":"Paragraph","id":"437c65dda6a1_34","name":"bcc7","type":"P","href":null,"layout":null,"metadata":null,"text":"In this project, the Tools component in the diagram is replaced by the MCP Client, which is responsible for invoking tools.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_35":{"__typename":"Paragraph","id":"437c65dda6a1_35","name":"7da1","type":"P","href":null,"layout":null,"metadata":null,"text":"This following explanation is based on the official Llama 3.1 documentation. If you’re already familiar with this, you can skip ahead to the next chapter.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_36":{"__typename":"Paragraph","id":"437c65dda6a1_36","name":"02a2","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Llama 3.1 | Model Cards and Prompt formats\nLlama 3.1 - the most capable open model.www.llama.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":96,"href":"https:\u002F\u002Fwww.llama.com\u002Fdocs\u002Fmodel-cards-and-prompt-formats\u002Fllama3_1\u002F#prompt-template","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":43,"end":83,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fwww.llama.com\u002Fdocs\u002Fmodel-cards-and-prompt-formats\u002Fllama3_1\u002F#prompt-template","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*BbnA3BdmyA5ynjZq"}},"Paragraph:437c65dda6a1_37":{"__typename":"Paragraph","id":"437c65dda6a1_37","name":"1a2f","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s briefly review the special tokens and role structure that form the backbone of prompt formatting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_38":{"__typename":"Paragraph","id":"437c65dda6a1_38","name":"a61f","type":"P","href":null,"layout":null,"metadata":null,"text":"Special Tokens","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_39":{"__typename":"Paragraph","id":"437c65dda6a1_39","name":"f3ae","type":"ULI","href":null,"layout":null,"metadata":null,"text":"\u003C|begin_of_text|\u003E : Specifies the start of the prompt.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_40":{"__typename":"Paragraph","id":"437c65dda6a1_40","name":"42fb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"\u003C|start_header_id|\u003E {role} \u003C|end_header_id|\u003E : Enclose the role for a particular message.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_41":{"__typename":"Paragraph","id":"437c65dda6a1_41","name":"fc18","type":"ULI","href":null,"layout":null,"metadata":null,"text":"\u003C|eot_id|\u003E : (End of turn); signals to the executor that the model has finished generating a response.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_42":{"__typename":"Paragraph","id":"437c65dda6a1_42","name":"5c12","type":"P","href":null,"layout":null,"metadata":null,"text":"Supported Roles","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_43":{"__typename":"Paragraph","id":"437c65dda6a1_43","name":"291c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"system : Defines the context in which the model operates. It usually includes instructions, rules, guidelines, or background information to help the model’s behavior","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_44":{"__typename":"Paragraph","id":"437c65dda6a1_44","name":"d846","type":"ULI","href":null,"layout":null,"metadata":null,"text":"user : Represents the input from human user. It includes the inputs, commands, and questions to the model","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_45":{"__typename":"Paragraph","id":"437c65dda6a1_45","name":"26a8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"assistant: Represents the response generated by the AI model based on the context","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_46":{"__typename":"Paragraph","id":"437c65dda6a1_46","name":"6a81","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ipython: Semantically, this role means “tool”. This is used to return the output of a tool invocation back to the model from the executor.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_47":{"__typename":"Paragraph","id":"437c65dda6a1_47","name":"90aa","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s take a look at how the LLM determines when to invoke and how it generates a response.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_48":{"__typename":"Paragraph","id":"437c65dda6a1_48","name":"3d96","type":"P","href":null,"layout":null,"metadata":null,"text":"1) System Prompt with Tool Definition","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_49":{"__typename":"Paragraph","id":"437c65dda6a1_49","name":"b395","type":"P","href":null,"layout":null,"metadata":null,"text":"The system prompt includes tool definitions in JSON format, specifying the available tools and their parameters. This definition can also be included in the user prompt, although placing it in the system prompt is generally preferred for clarity.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_50":{"__typename":"Paragraph","id":"437c65dda6a1_50","name":"808a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C|start_header_id|\u003Esystem\u003C|end_header_id|\u003E\n\nYou are an expert in composing functions. You are given a question and a set of possible functions. \nBased on the question, you will need to make one or more function\u002Ftool calls to achieve the purpose. \nIf none of the functions can be used, point it out. If the given question lacks the parameters required by the function,also point it out. You should only return the function call in tools call sections.\nIf you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(params_name1=params_value1, params_name2=params_value2...), func_name2(params)]\nYou SHOULD NOT include any other text in the response.\n\nHere is a list of functions in JSON format that you can invoke.\n[\n    {\n        \"name\": \"get_user_name\",\n        \"description\": \"Retrieve a name for a specific user by their unique identifier. Note that the provided function is in Python 3 syntax.\",\n        \"parameters\": {\n            \"type\": \"dict\",\n            \"required\": [\n                \"user_id\"\n            ],\n            \"properties\": {\n                \"user_id\": {\n                 \"type\": \"integer\",\n                 \"description\": \"The unique identifier of the user. It is used to fetch the specific user details from the database.\"\n             }\n            }\n        }\n    }\n]\n\u003C|eot_id|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"yaml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_51":{"__typename":"Paragraph","id":"437c65dda6a1_51","name":"cd07","type":"P","href":null,"layout":null,"metadata":null,"text":"2) User Prompt to LLM","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_52":{"__typename":"Paragraph","id":"437c65dda6a1_52","name":"d7c4","type":"P","href":null,"layout":null,"metadata":null,"text":"The system prompt, which includes the tool definitions, is combined with the user prompt that contains the actual query. To make the LLM to generate a response by completing the sentence, the message is concluded with an assistant header.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_53":{"__typename":"Paragraph","id":"437c65dda6a1_53","name":"5c68","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\n\nCan you retrieve the name of the user with the ID 7890?\n\n\u003C|eot_id|\u003E\n\n\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"yaml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_54":{"__typename":"Paragraph","id":"437c65dda6a1_54","name":"98dd","type":"P","href":null,"layout":null,"metadata":null,"text":"3) Response with tool-call","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_55":{"__typename":"Paragraph","id":"437c65dda6a1_55","name":"0529","type":"P","href":null,"layout":null,"metadata":null,"text":"In this step, the LLM determines that answering the user’s query requires a function call. It responds by generating a function call expression that matches the format specified in the system prompt.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_56":{"__typename":"Paragraph","id":"437c65dda6a1_56","name":"cfe7","type":"PRE","href":null,"layout":null,"metadata":null,"text":"[get_user_name(user_id=7890)]\n\u003C|eot_id|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"yaml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_57":{"__typename":"Paragraph","id":"437c65dda6a1_57","name":"dad8","type":"P","href":null,"layout":null,"metadata":null,"text":"4) Original Prompt + Tool Response","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":34,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_58":{"__typename":"Paragraph","id":"437c65dda6a1_58","name":"fd64","type":"P","href":null,"layout":null,"metadata":null,"text":"The application executes the requested function and appends the result back to the prompt. The role ipython is used to mark this tool result when passing it back to the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_59":{"__typename":"Paragraph","id":"437c65dda6a1_59","name":"5976","type":"PRE","href":null,"layout":null,"metadata":null,"text":"...\n\n\u003C|start_header_id|\u003Euser\u003C|end_header_id|\u003E\nCan you retrieve the name of the user with the ID 7890?\n\u003C|eot_id|\u003E\n\n\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E\n[get_user_name(user_id=7890)]\n\u003C|eot_id|\u003E\n\n\u003C|start_header_id|\u003Eipython\u003C|end_header_id|\u003E\n{\"output\": \"Hyunjong Lee\"}\n\u003C|eot_id|\u003E\n\n\u003C|start_header_id|\u003Eassistant\u003C|end_header_id|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"yaml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_60":{"__typename":"Paragraph","id":"437c65dda6a1_60","name":"8993","type":"P","href":null,"layout":null,"metadata":null,"text":"5) Synthesized Response","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_61":{"__typename":"Paragraph","id":"437c65dda6a1_61","name":"b406","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, the model produces a complete response using the tool output:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_62":{"__typename":"Paragraph","id":"437c65dda6a1_62","name":"2bc8","type":"PRE","href":null,"layout":null,"metadata":null,"text":"The name of user who has the ID is “Hyunjong Lee”.\n\u003Ceot_id\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"yaml"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_63":{"__typename":"Paragraph","id":"437c65dda6a1_63","name":"a246","type":"P","href":null,"layout":null,"metadata":null,"text":"Even lightweight models like Llama 3.2 1B and 3B are capable of performing tool-calling. However, according to Meta’s official documentation, for building stable tool-aware conversational applications, it is recommended to use either the 70B-Instruct or 405B-Instruct models.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_64":{"__typename":"Paragraph","id":"437c65dda6a1_64","name":"d231","type":"P","href":null,"layout":null,"metadata":null,"text":"While the 8B-Instruct model supports zero-shot tool calling, Meta’s blog notes that it cannot reliably maintain a conversation when tool definitions are included in the prompt. Therefore, when working with smaller models, it’s often necessary to remove tool instructions from the prompt to ensure smoother interaction between the user and the AI model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":61,"end":78,"href":"https:\u002F\u002Fwww.llama.com\u002Fdocs\u002Fmodel-cards-and-prompt-formats\u002Fllama3_1\u002F#-tool-calling-(8b\u002F70b\u002F405b)-","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_65":{"__typename":"Paragraph","id":"437c65dda6a1_65","name":"df54","type":"P","href":null,"layout":null,"metadata":null,"text":"This is a critical consideration for generating high-quality responses and one you should definitely keep in mind.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_66":{"__typename":"Paragraph","id":"437c65dda6a1_66","name":"24c6","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Note: We recommend using Llama 70B-instruct or Llama 405B-instruct for applications that combine conversation and tool calling. Llama 8B-Instruct can not reliably maintain a conversation alongside tool calling definitions. It can be used for zero-shot tool calling, but tool instructions should be removed for regular conversations between the model and the user. — from meta AI notes","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_67":{"__typename":"Paragraph","id":"437c65dda6a1_67","name":"1251","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Building LLM Agent","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_68":{"__typename":"Paragraph","id":"437c65dda6a1_68","name":"e6e5","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, let’s take a look at the architecture of the agent I built. It closely follows the tool-calling process described above, with a few additional components to enable communication with MCP server.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_69":{"__typename":"Paragraph","id":"437c65dda6a1_69","name":"30ad","type":"P","href":null,"layout":null,"metadata":null,"text":"The core components are: MCP Client & Manager, LLM, and Agent","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*9laqwbOF96vVwM23hHTVBg.gif":{"__typename":"ImageMetadata","id":"1*9laqwbOF96vVwM23hHTVBg.gif","originalHeight":753,"originalWidth":840,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_70":{"__typename":"Paragraph","id":"437c65dda6a1_70","name":"e508","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*9laqwbOF96vVwM23hHTVBg.gif"},"text":"Architecture Overview (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_71":{"__typename":"Paragraph","id":"437c65dda6a1_71","name":"dc51","type":"P","href":null,"layout":null,"metadata":null,"text":"As this article contains a significant amount of code, only essential parts are shown here for clarity. You can fine the full source code in the GitHub repository below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_72":{"__typename":"Paragraph","id":"437c65dda6a1_72","name":"39e8","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"GitHub - hjlee94\u002Fmcp-knowledge-base: MCP agent\u002Fclient\u002Fserver implementation for private knowledge…\nMCP agent\u002Fclient\u002Fserver implementation for private knowledge base - hjlee94\u002Fmcp-knowledge-basegithub.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":203,"href":"https:\u002F\u002Fgithub.com\u002Fhjlee94\u002Fmcp-knowledge-base","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":98,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":99,"end":193,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fhjlee94\u002Fmcp-knowledge-base","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*8O6B5Rhy-tLsc9p7"}},"Paragraph:437c65dda6a1_73":{"__typename":"Paragraph","id":"437c65dda6a1_73","name":"e60d","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.1. MCP Client and Manager","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_74":{"__typename":"Paragraph","id":"437c65dda6a1_74","name":"0215","type":"P","href":null,"layout":null,"metadata":null,"text":"A. MCP Client","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_75":{"__typename":"Paragraph","id":"437c65dda6a1_75","name":"41d1","type":"P","href":null,"layout":null,"metadata":null,"text":"First, we need an MCP Client capable of establishing a 1:1 connection with the MCP server. This was implemented using the Python MCP SDK, following the official MCP documentation:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_76":{"__typename":"Paragraph","id":"437c65dda6a1_76","name":"ecb0","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"For Client Developers - Model Context Protocol\nGet started building your own client that can integrate with all MCP servers.modelcontextprotocol.io","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":147,"href":"https:\u002F\u002Fmodelcontextprotocol.io\u002Fquickstart\u002Fclient","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":47,"end":124,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fmodelcontextprotocol.io\u002Fquickstart\u002Fclient","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*VKglBHUo4KfFBn89"}},"Paragraph:437c65dda6a1_77":{"__typename":"Paragraph","id":"437c65dda6a1_77","name":"7b48","type":"P","href":null,"layout":null,"metadata":null,"text":"Below is the MCPClient class, which handles the connection to the server. Since the custom MCP server I built communicates over standard input\u002Foutput(stdio), the client spawns the server process, connects to it via its read\u002Fwrite streams.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":13,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_78":{"__typename":"Paragraph","id":"437c65dda6a1_78","name":"5f58","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class MCPClient:\n    def __init__(self):\n        self.session = None\n        self.name = ''\n        self.exit_stack = AsyncExitStack()\n\n    async def connect_to_server(self, server_script_path:str):\n        server_params = StdioServerParameters(\n            command = \"python\",\n            args=[server_script_path],\n            env=None\n        )\n\n        # spawaning a process for running a mcp server\n        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n        self.read, self.write = stdio_transport\n\n        # init session using read\u002Fwrite pipes of the process spawned\n        self.session = await self.exit_stack.enter_async_context(ClientSession(self.read, self.write))\n        \n        ...","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_79":{"__typename":"Paragraph","id":"437c65dda6a1_79","name":"7a89","type":"P","href":null,"layout":null,"metadata":null,"text":"After creating the client session, the client follows the MCP connection lifecycle. It first sends an initialize request to the MCP server, waits for a response, and then complete the handshake by sending an initialized notification as an acknowledgement.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*i9x2lm9ijlulYGUfKxzBWQ.png":{"__typename":"ImageMetadata","id":"1*i9x2lm9ijlulYGUfKxzBWQ.png","originalHeight":750,"originalWidth":840,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_80":{"__typename":"Paragraph","id":"437c65dda6a1_80","name":"2e2b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*i9x2lm9ijlulYGUfKxzBWQ.png"},"text":"MCP Handshake (Image by Anthropic)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_81":{"__typename":"Paragraph","id":"437c65dda6a1_81","name":"db35","type":"P","href":null,"layout":null,"metadata":null,"text":"As a result of the initialize request, the client receives information about the server, which is structured as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_82":{"__typename":"Paragraph","id":"437c65dda6a1_82","name":"5a1e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class InitializeResult(Result):\n    \"\"\"After receiving an initialize request from the client, the server sends this.\"\"\"\n\n    protocolVersion: str | int\n    \"\"\"The version of the Model Context Protocol that the server wants to use.\"\"\"\n    capabilities: ServerCapabilities\n    serverInfo: Implementation\n    instructions: str | None = None\n    \"\"\"Instructions describing how to use the server and its features.\"\"\"\n\nclass Implementation(BaseModel):\n    \"\"\"Describes the name and version of an MCP implementation.\"\"\"\n    name: str\n    version: str","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_83":{"__typename":"Paragraph","id":"437c65dda6a1_83","name":"b05a","type":"P","href":null,"layout":null,"metadata":null,"text":"After establishing the connection, the MCP Client can obtain the server’s name and version information. If the server is implemented using the FastMCP class and no explicit version is specified, the version defaults to the MCP SDK’s package version.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":143,"end":150,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_84":{"__typename":"Paragraph","id":"437c65dda6a1_84","name":"d90d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class MCPClient:\n ...\n \n async def connect_to_server(self, server_script_path:str):\n        ...\n\n        # connect server by sending initialize request\n        init_result = await self.session.initialize()\n        \n        server_info = init_result.serverInfo\n        self.name = f\"{server_info.name}(v{server_info.version})\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_85":{"__typename":"Paragraph","id":"437c65dda6a1_85","name":"78c5","type":"P","href":null,"layout":null,"metadata":null,"text":"The MCP Client includes essential methods such as list_tools() and list_resources() to enumerate available tools and resources, as well as call_tool(name, args) to invoke a specific tool. Their implementations are shown below.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":50,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":67,"end":83,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":139,"end":160,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_86":{"__typename":"Paragraph","id":"437c65dda6a1_86","name":"d3cc","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class MCPClient:\n    ...\n\n    async def list_tools(self) -\u003E list[types.Tool]:\n        response = await self.session.list_tools()\n        tools = response.tools\n        return tools\n\n    async def list_resources(self) -\u003E list[types.Resource]:\n        response = await self.session.list_resources()\n        resources = response.resources\n        return resources\n    \n    async def call_tool(self, name, args) -\u003E tuple[bool, list[types.TextContent]]:\n        response = await self.session.call_tool(name, args)\n        return [response.isError, response.content]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_87":{"__typename":"Paragraph","id":"437c65dda6a1_87","name":"f6a0","type":"P","href":null,"layout":null,"metadata":null,"text":"B. MCP Manager","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_88":{"__typename":"Paragraph","id":"437c65dda6a1_88","name":"a872","type":"P","href":null,"layout":null,"metadata":null,"text":"Since each MCP Client maintains a one-to-one connection with an MCP server, supporting multiple servers requires managing multiple client instances.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_89":{"__typename":"Paragraph","id":"437c65dda6a1_89","name":"e91a","type":"P","href":null,"layout":null,"metadata":null,"text":"To handle this, I defined an MCP Client Manager, which is responsible for initializing and cleaning up clients for each registered MCP server path.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_90":{"__typename":"Paragraph","id":"437c65dda6a1_90","name":"1283","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class MCPClientMaanger:\n    def __init__(self):\n        self.server_path:list[str] = []\n        self.clients:list[MCPClient] = []\n\n    def register_mcp(self, server_path:str):\n        self.server_path.append(server_path)\n\n    async def init_mcp_client(self):\n        for path in self.server_path:\n            c = MCPClient()\n            await c.connect_to_server(path)\n\n            self.clients.append(c)\n\n    async def clean_mcp_client(self):\n        for c in self.clients:\n            await c.cleanup()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_91":{"__typename":"Paragraph","id":"437c65dda6a1_91","name":"8927","type":"P","href":null,"layout":null,"metadata":null,"text":"Another important responsibility of the class is to fetch resource and tool information from the appropriate registered MCP client. To support this, the manager maintains a mapping that keeps track of which MCP client is associated with which each tool or resource.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_92":{"__typename":"Paragraph","id":"437c65dda6a1_92","name":"084a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class MCPClientMaanger:\n    def __init__(self):\n        ...\n        self.tool_map:dict[str, int] = dict()\n        self.tool_info:dict[str, dict[str, str]] = dict()\n        self.resource_map:dict[str, int] = dict()\n \n    ...\n \n    async def get_resource_list(self) -\u003E list[dict[str, str]]:\n        resource_list = []\n\n        for idx, c in enumerate(self.clients):\n            resources = await c.list_resources()\n            \n            for rsrc in resources:\n                resource_list.append(utils.resource2dict(rsrc))\n                self.resource_map[utils.uri2path(rsrc.uri)] = idx\n\n        return resource_list\n    \n async def get_func_scheme(self) -\u003E list[dict[str, str]]:\n        func_scheme_list = []\n\n        for idx, c in enumerate(self.clients):\n            tools = await c.list_tools()\n\n            for tool in tools:\n                func_scheme_list.append(utils.tool2dict(tool))\n                self.tool_map[tool.name] = idx\n                \n                func_info = self.tool_info.get(self.clients[idx].name, {})\n                func_info[tool.name] = tool.description\n                self.tool_info[self.clients[idx].name] = func_info\n\n        return func_scheme_list\n    \n    async def call_tool(self, name:str, param:dict[str, Any]) -\u003E tuple[bool, list[types.TextContent]]:\n        idx = self.tool_map.get(name, -1)\n\n        if idx \u003C 0:\n            raise errors.MCPException(f\"Unknown tool name{name}\")\n        \n        client = self.clients[idx]\n        result = await client.call_tool(name, param)\n        \n        return result","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_93":{"__typename":"Paragraph","id":"437c65dda6a1_93","name":"0ef4","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.2. LLM Agent","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_94":{"__typename":"Paragraph","id":"437c65dda6a1_94","name":"70cb","type":"P","href":null,"layout":null,"metadata":null,"text":"A. LLM Model","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_95":{"__typename":"Paragraph","id":"437c65dda6a1_95","name":"7db3","type":"P","href":null,"layout":null,"metadata":null,"text":"For the agent’s language model, I used Llama, running locally on my MacBook via Llama.cpp.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_96":{"__typename":"Paragraph","id":"437c65dda6a1_96","name":"0f93","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"GitHub - ggml-org\u002Fllama.cpp: LLM inference in C\u002FC++\nLLM inference in C\u002FC++. Contribute to ggml-org\u002Fllama.cpp development by creating an account on GitHub.github.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":164,"href":"https:\u002F\u002Fgithub.com\u002Fggml-org\u002Fllama.cpp","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":52,"end":154,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fggml-org\u002Fllama.cpp","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*kEiDYW8QvG15UTOz"}},"Paragraph:437c65dda6a1_97":{"__typename":"Paragraph","id":"437c65dda6a1_97","name":"6c41","type":"P","href":null,"layout":null,"metadata":null,"text":"The first step to using a model with Llama.cpp is to download the model weights from Hugging Face. You can do this using the Hugging Face utility, which allows you to fetch a snapshot of the model repository as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_98":{"__typename":"Paragraph","id":"437c65dda6a1_98","name":"eb61","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from huggingface_hub import snapshot_download\n\nmodel_id = \"meta-llama\u002FLlama-3.2-3B-Instruct\"\nsnapshot_download(repo_id=model_id, local_dir=\".\u002Fmodels\u002Fllama-3.2-3B-Instruct\", revision=\"main\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_99":{"__typename":"Paragraph","id":"437c65dda6a1_99","name":"6a52","type":"P","href":null,"layout":null,"metadata":null,"text":"Llama.cpp requires language models to be in the GGUF format. After downloading the model from Hugging Face, you can use the conversion script provided by Llama.cpp to convert the model into GGUF format, as shown below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_100":{"__typename":"Paragraph","id":"437c65dda6a1_100","name":"8d5c","type":"PRE","href":null,"layout":null,"metadata":null,"text":"$ python convert_hf_to_gguf.py .\u002Fmodels\u002Fllama-3.2-3B-Instruct --outfile .\u002Fmodels\u002Fllama-3.2-3B-Instruct.gguf --outtype f16 --verbose","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_101":{"__typename":"Paragraph","id":"437c65dda6a1_101","name":"39d8","type":"P","href":null,"layout":null,"metadata":null,"text":"A custom wrapper class was implemented using the Llama.cpp Python bindings, allowing prompts to be passed in and responses to be generated programmatically.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":49,"end":74,"href":"https:\u002F\u002Fgithub.com\u002Fabetlen\u002Fllama-cpp-python","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_102":{"__typename":"Paragraph","id":"437c65dda6a1_102","name":"0d96","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class LlamaCPP(BaseModel):\n    def __init__(self, name:str, model:Llama):\n        self.name = name\n        self.model = model\n        self.max_tokens = 1024\n\n    @classmethod\n    def from_path(cls, model_path:str, n_ctx:int=0, **kwargs) -\u003E Self:\n        model = Llama(\n            model_path=model_path,\n            n_ctx=n_ctx,\n            verbose=False,\n            **kwargs\n        )\n\n        return cls(name = os.path.basename(model_path), model=model)\n\n    def generate(self, prompt:str, **kwargs) -\u003E str:\n        if 'max_tokens' not in kwargs:\n            kwargs['max_tokens'] = self.max_tokens\n\n        output = self.model(prompt, **kwargs)\n        choices = output['choices']\n        response = choices[0]['text'].strip()\n        return response","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_103":{"__typename":"Paragraph","id":"437c65dda6a1_103","name":"b99e","type":"P","href":null,"layout":null,"metadata":null,"text":"B. Prompt","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_104":{"__typename":"Paragraph","id":"437c65dda6a1_104","name":"f74a","type":"P","href":null,"layout":null,"metadata":null,"text":"Llama.cpp provides a high-level API function, create_chat_completion(), which allows you to generate responses by passing in structured messages in a simple format, as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":46,"end":70,"href":"https:\u002F\u002Fllama-cpp-python.readthedocs.io\u002Fen\u002Flatest\u002Fapi-reference\u002F#llama_cpp.Llama.create_chat_completion","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":46,"end":70,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_105":{"__typename":"Paragraph","id":"437c65dda6a1_105","name":"9893","type":"PRE","href":null,"layout":null,"metadata":null,"text":"response = llm.create_chat_completion(\n      messages = [\n          {\n           \"role\": \"system\", \n           \"content\": \"You are an assistant who perfectly describes images.\"\n    },\n          {\n              \"role\": \"user\",\n              \"content\": \"Describe this image in detail please.\"\n          }\n      ]\n)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_106":{"__typename":"Paragraph","id":"437c65dda6a1_106","name":"33b5","type":"P","href":null,"layout":null,"metadata":null,"text":"However, to gain more control over prompt construction and handling, I implemented helper classes: LlamaMessage and LlamaPrompt.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":99,"end":111,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":116,"end":127,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_107":{"__typename":"Paragraph","id":"437c65dda6a1_107","name":"26c6","type":"P","href":null,"layout":null,"metadata":null,"text":"The LlamaMessage class is responsible for formatting messages according to the expected Llama prompt structure. It handles the assigned role, content, and optionally a tool_scheme, depending on whether tool_enabled is set — I’ll discuss the role of tool_enabled in a later section.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":168,"end":179,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":202,"end":214,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":249,"end":261,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_108":{"__typename":"Paragraph","id":"437c65dda6a1_108","name":"18b8","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class LLamaMessage(BaseMessage):\n    def __init__(self, role:str, content:str='', tool_scheme:str=''):\n        self.role:str = role\n        self.content:str = content\n        self.tool_scheme:str = tool_scheme\n\n    def template(self, tool_enabled:bool=False) -\u003E str:\n        #* Llama CPP insert BOS token internally\n        prompt = f\"\u003C|start_header_id|\u003E{self.role}\u003C|end_header_id|\u003E\"\n\n        if tool_enabled and self.tool_scheme:\n            prompt += f\"{self.tool_scheme}\"\n\n        if self.content:\n            prompt += f\"{self.content}\u003C|eot_id|\u003E\"\n\n        return prompt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_109":{"__typename":"Paragraph","id":"437c65dda6a1_109","name":"c904","type":"P","href":null,"layout":null,"metadata":null,"text":"The Prompt class manages the conversation history between the model and the user, and is responsible for constructing multi-turn prompts. This class is used directly by the agent, and provides APIs to add messages according to their roles, such as user or assistant.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_110":{"__typename":"Paragraph","id":"437c65dda6a1_110","name":"2daa","type":"P","href":null,"layout":null,"metadata":null,"text":"Ultimately, it generates the final input prompt (also known as the generation prompt) that is passed to the LLM for response generation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_111":{"__typename":"Paragraph","id":"437c65dda6a1_111","name":"4df0","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class LlamaPrompt(BasePrompt):\n    ROLE_SYSTEM = 'system'\n    ROLE_USER = 'user'\n    ROLE_ASSISTANT = 'assistant'\n    ROLE_TOOL = 'ipython'\n\n    def __init__(self) -\u003E None:\n        self.system_prompt:BaseMessage = LLamaMessage('system', \"You are a helpful assistant.\")\n        self.history:History = History()\n\n    def append_history(self, message:LLamaMessage):\n        self.history.append_message(message)\n    \n    def set_system_prompt(self, system_prompt:LLamaMessage):\n        self.system_prompt = system_prompt\n\n    def get_system_prompt(self, system_prompt:str):\n        return LLamaMessage(LlamaPrompt.ROLE_SYSTEM, system_prompt)\n\n    def get_user_prompt(self, question:str, tool_scheme:str='') -\u003E LLamaMessage:\n        return LLamaMessage(LlamaPrompt.ROLE_USER, question, tool_scheme=tool_scheme)\n\n    def get_assistant_prompt(self, answer:Optional[str]=\"\") -\u003E LLamaMessage:\n        return LLamaMessage(LlamaPrompt.ROLE_ASSISTANT, answer)\n    \n    def get_tool_result_prompt(self, result:str) -\u003E LLamaMessage:\n        return LLamaMessage(LlamaPrompt.ROLE_TOOL, result)\n    \n    def get_generation_prompt(self, tool_enabled:bool=False, last:int=50) -\u003E str:\n        prompt = [self.system_prompt]\n        prompt += self.history.get_chat_history(last=last)\n        prompt += [self.get_assistant_prompt(answer='')] #* generation prompt\n        \n        return ''.join([p.template(tool_enabled=tool_enabled) for p in prompt])","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_112":{"__typename":"Paragraph","id":"437c65dda6a1_112","name":"eb38","type":"P","href":null,"layout":null,"metadata":null,"text":"Currently, the prompt format follows the Llama prompt template, since the agent uses a Llama model under the hood. However, the design is modular — other AI models can be supported by subclassing and implementing the BaseMessage and BaseModel interfaces accordingly.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":217,"end":228,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":233,"end":242,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_113":{"__typename":"Paragraph","id":"437c65dda6a1_113","name":"513a","type":"P","href":null,"layout":null,"metadata":null,"text":"The History class, used by the Prompt class, is responsible for maintaining the record of past messages. It is designed to optionally return only the latest k messages, depending on the context or application requirements.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":31,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":157,"end":158,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_114":{"__typename":"Paragraph","id":"437c65dda6a1_114","name":"eb86","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class History:\n    def __init__(self, max_history:int=50) -\u003E None:\n        self._history:list[BaseMessage] = []\n        self._max_history:int = max_history\n\n    def append_message(self, msg:BaseMessage):\n        self._history.append(msg)\n        self._history = self._history[-self._max_history:]\n\n    def get_chat_history(self, last:int=0) -\u003E list[BaseMessage]:\n        if last \u003C 0:\n            return []\n        \n        if last \u003E 0:\n            return self._history[-last:]\n        \n        return self._history\n    \n    def clear(self):\n        self._history = []","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_115":{"__typename":"Paragraph","id":"437c65dda6a1_115","name":"6d1b","type":"P","href":null,"layout":null,"metadata":null,"text":"C. Agent","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_116":{"__typename":"Paragraph","id":"437c65dda6a1_116","name":"a180","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, let’s bring the previously defined classes together to implement the three core functionalities of the agent:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_117":{"__typename":"Paragraph","id":"437c65dda6a1_117","name":"fc9c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"MCP Client Connection and Initialization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_118":{"__typename":"Paragraph","id":"437c65dda6a1_118","name":"9e9a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Matching Tool Invocation Pattern and Calling the Appropriate Tool","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_119":{"__typename":"Paragraph","id":"437c65dda6a1_119","name":"b5e6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Synthesizing a Response with Tool Calling","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_120":{"__typename":"Paragraph","id":"437c65dda6a1_120","name":"8b4a","type":"P","href":null,"layout":null,"metadata":null,"text":"Before diving into the implementation, we first provide the Llama model with a prompt that defines the tool-calling format and the available tools.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_121":{"__typename":"Paragraph","id":"437c65dda6a1_121","name":"084c","type":"P","href":null,"layout":null,"metadata":null,"text":"This tool instruction follows the format defined in the example provided in the official Llama documentation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_122":{"__typename":"Paragraph","id":"437c65dda6a1_122","name":"4910","type":"PRE","href":null,"layout":null,"metadata":null,"text":"TOOL_CALL_PROMPT = \"\"\"You are an expert in composing functions. You are given a question and a set of possible functions.\nBased on the question, you will need to make one or more function\u002Ftool calls to achieve the purpose.\nIf none of the function can be used, point it out. If the given question lacks the parameters required by the function,\nalso point it out. You should only return the function call in tools call sections.\n\nIf you decide to invoke any of the function(s), you MUST put it in the format of [func_name1(), func_name2(params_name1=params_value1, params_name2=params_value2...), func_name3(params)]\nYou SHOULD NOT include any other text in the response.\n\nHere is a list of functions in JSON format that you can invoke.\n{function_scheme}","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_123":{"__typename":"Paragraph","id":"437c65dda6a1_123","name":"17d7","type":"P","href":null,"layout":null,"metadata":null,"text":"The function scheme is retrieved from the MCP server, parsed into JSON, and used to define the available tools in the prompt, as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_124":{"__typename":"Paragraph","id":"437c65dda6a1_124","name":"3e0a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"[\n    {\n        \"name\": \"list_knowledges\",\n        \"description\": \"List the names and URIs of all knowledges written in the the vault\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"required\": [],\n            \"properties\": {}\n        }\n    },\n    {\n        \"name\": \"get_knowledge_by_uri\",\n        \"description\": \"get contents of the knowledge resource by uri\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"required\": [\n                \"uri\"\n            ],\n            \"properties\": {\n                \"uri\": {\n                    \"type\": \"string\"\n                }\n            }\n        }\n    }\n]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"json"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_125":{"__typename":"Paragraph","id":"437c65dda6a1_125","name":"3356","type":"P","href":null,"layout":null,"metadata":null,"text":"MCP Client Connection and Initialization","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":40,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_126":{"__typename":"Paragraph","id":"437c65dda6a1_126","name":"90c2","type":"P","href":null,"layout":null,"metadata":null,"text":"The agent uses the previously implemented MCPManager to register MCP server paths and initialize client sessions for each registered server.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_127":{"__typename":"Paragraph","id":"437c65dda6a1_127","name":"ffa3","type":"P","href":null,"layout":null,"metadata":null,"text":"Once the MCP client session is established, it sends tools\u002Flist and resources\u002Flist requests to retrieve the tools and resources available on the server.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":53,"end":63,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":68,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_128":{"__typename":"Paragraph","id":"437c65dda6a1_128","name":"1b39","type":"P","href":null,"layout":null,"metadata":null,"text":"The responses are then converted into JSON strings and stored for use in the system prompt.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_129":{"__typename":"Paragraph","id":"437c65dda6a1_129","name":"2467","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class Agent:\n    def __init__(self, name:str, model:BaseModel, prompt:BasePrompt) -\u003E None:\n        self.name:str = name\n\n        self.llm:BaseModel = model\n        self.prompt:BasePrompt = prompt\n\n        self.mcp_manager = MCPClientMaanger()\n\n        self.func_scheme_prompt = \"\"\n        self.resource_list = \"\"\n    \n    def register_mcp(self, path:str):\n        self.mcp_manager.register_mcp(path)\n\n    async def init_agent(self):\n        await self.mcp_manager.init_mcp_client()\n\n        func_scheme_list = await self.mcp_manager.get_func_scheme()\n        resource_list = await self.mcp_manager.get_resource_list()\n\n        self.func_scheme_prompt = json.dumps(func_scheme_list)\n        self.resource_list = json.dumps(resource_list)\n        \n        p = self.prompt.get_system_prompt(\"You are a helpful assistant\")\n        self.prompt.set_system_prompt(p)\n\n    async def clean_agent(self):\n        await self.mcp_manager.clean_mcp_client()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_130":{"__typename":"Paragraph","id":"437c65dda6a1_130","name":"ce24","type":"P","href":null,"layout":null,"metadata":null,"text":"Matching Tool Invocation Pattern and Calling the Appropriate Tool","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_131":{"__typename":"Paragraph","id":"437c65dda6a1_131","name":"57c1","type":"P","href":null,"layout":null,"metadata":null,"text":"This part of the agent is responsible for determining whether the LLM’s response requires a tool invocation, and if so, it sends a tools\u002Fcall request through the appropriate MCP client to retrieve the result.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":131,"end":141,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_132":{"__typename":"Paragraph","id":"437c65dda6a1_132","name":"fe91","type":"P","href":null,"layout":null,"metadata":null,"text":"To match tool invocation patterns such as [func_1(param1=value1, param2=value2), func_2()], a regular expression is defined.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":42,"end":90,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_133":{"__typename":"Paragraph","id":"437c65dda6a1_133","name":"06b9","type":"P","href":null,"layout":null,"metadata":null,"text":"The _is_tool_required(str) method checks whether the LLM’s response includes any tool invocation. The get_func_props(str) method is a generator that iterates over all matched functions and yields the function name and parsed arguments.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":102,"end":121,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_134":{"__typename":"Paragraph","id":"437c65dda6a1_134","name":"f043","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class Agent:\n    def __init__(self, name:str, model:BaseModel, prompt:BasePrompt) -\u003E None:\n        ...\n\n        self.tool_pattern = re.compile(r'\\[([A-Za-z0-9\\_]+\\(([A-Za-z0-9\\_]+=\\\"?.+\\\"?,?\\s?)*\\),?\\s?)+\\]')\n        self.func_pattern = re.compile(r'([A-Za-z0-9\\_]+)\\(([A-Za-z0-9\\_]+=\\\"?.+\\\"?,?\\s?)*\\)')\n\n    ...\n    def _is_tool_required(self, response:str):\n        return self.tool_pattern.match(response)\n\n    def get_func_props(self, response:str):\n        for signature in response.strip('[]').split(','):\n            signature = signature.strip()\n\n            if res := self.func_pattern.findall(signature):\n                name, param_string = res[0]\n                yield name, utils.param2dict(param_string)\n\n    async def get_result_tool(self, response:str) -\u003E list[list[str]]:\n        result_list = []\n\n        for name, param in self.get_func_props(response):\n            res = await self.mcp_manager.call_tool(name, param)\n            is_err, content_list = res\n\n            results = [c.text for c in content_list]\n\n            result_list.append({'name':name, 'output':results})\n        \n        return result_list","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_135":{"__typename":"Paragraph","id":"437c65dda6a1_135","name":"9765","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, the extracted function name and parameters are used to send a tools\u002Fcall request to the corresponding MCP client. The result returned from the tool is a dictionary, which is then converted into a JSON string to be passed back to the AI model in the next step.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":71,"end":81,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_136":{"__typename":"Paragraph","id":"437c65dda6a1_136","name":"2a9c","type":"P","href":null,"layout":null,"metadata":null,"text":"Synthesizing a Response with Tool Calling","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_137":{"__typename":"Paragraph","id":"437c65dda6a1_137","name":"66a7","type":"P","href":null,"layout":null,"metadata":null,"text":"The final step of the agent is to generate the response using the result of the tool call. This process follows the same flow as described in Section 2.1 (Synthesized Response).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_138":{"__typename":"Paragraph","id":"437c65dda6a1_138","name":"081b","type":"P","href":null,"layout":null,"metadata":null,"text":"The chat(str) method returns a list of AgentResponse objects, each categorized by type — such as the tool call, tool result, and text — so that both the user’s answer and relevant tool-related information can be presented clearly.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":39,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_139":{"__typename":"Paragraph","id":"437c65dda6a1_139","name":"0da9","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class AgentResponse(pydantic.BaseModel):\n    type: Literal[\"text\", \"tool-calling\", \"tool-result\"]\n    data: str\n    \nclass Agent:\n    ...\n\n    async def chat(self, question:str, **kwargs) -\u003E list[AgentResponse]:\n        response_list = []\n\n        # Tool Scheme for providing How to call tool and which tool can be called\n        tool_scheme = TOOL_CALL_PROMPT.format(\n            function_scheme=self.func_scheme_prompt\n            )\n  \n        # 1. user query prompt\n        p = self.prompt.get_user_prompt(question=question, tool_scheme=tool_scheme)\n        self.prompt.append_history(p)\n\n        # 2. LLM response to user query\n        response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=True), **kwargs)\n\n        if self._is_tool_required(response): # if tool pattern found\n            response_list.append(AgentResponse(type=\"tool-calling\", data=response))\n\n            p = self.prompt.get_assistant_prompt(answer=response)\n            self.prompt.append_history(p)\n\n            # 3. llm requires tool invoke\n            result = await self.get_result_tool(response)\n            result = json.dumps(result, ensure_ascii=False)\n\n            response_list.append(AgentResponse(type=\"tool-result\", data=result))\n\n            # 4. add result of tool-calling into the prompt\n            p = self.prompt.get_tool_result_prompt(result=result)\n            self.prompt.append_history(p)\n   \n            # 5. synthesize response with the tool-calling result\n            response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=False, last=3), **kwargs)\n\n        response_list.append(AgentResponse(type=\"text\", data=response))\n\n        p = self.prompt.get_assistant_prompt(answer=response)\n        self.prompt.append_history(p)\n\n        return response_list","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_140":{"__typename":"Paragraph","id":"437c65dda6a1_140","name":"f637","type":"P","href":null,"layout":null,"metadata":null,"text":"That wraps up the development journey of the agent so far. Now, as the final step, let’s make this agent interactive — allowing it to engage with users in a real conversation flow.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_141":{"__typename":"Paragraph","id":"437c65dda6a1_141","name":"5dda","type":"P","href":null,"layout":null,"metadata":null,"text":"Interactive Interface","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_142":{"__typename":"Paragraph","id":"437c65dda6a1_142","name":"4c77","type":"P","href":null,"layout":null,"metadata":null,"text":"By instantiating the Agent object and repeatedly calling the chat() method, you can interact with the agent directly through the terminal, as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":61,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_143":{"__typename":"Paragraph","id":"437c65dda6a1_143","name":"904b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"async def run_agent():\n    agent = Agent(\n     name=\"knowledge-agent\", \n     model=LlamaCPP.from_path('.\u002Fmodels\u002Fllama-3.2-3B-Instruct.gguf'), \n     prompt=LlamaPrompt()\n     )\n\n    agent.register_mcp(path=\".\u002Frun_server.py\") #Knowledge-vault MCP Server\n\n    async with agent:\n        while (prompt := input('(prompt) ')) != 'bye':\n            response = await agent.chat(prompt)\n\n            for r in response:\n                if r.type == 'text':\n                    print(f\"(assistant) {r.data}\")\n                elif r.type == 'tool-calling':\n                    print(f\"(assistant) tool calling {r.data}\")\n                elif r.type == 'tool-result':\n                    print(f\"(assistant) tool result {r.data}\")\n\nif __name__ == '__main__':\n    asyncio.run(run_agent())","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_144":{"__typename":"Paragraph","id":"437c65dda6a1_144","name":"53bd","type":"P","href":null,"layout":null,"metadata":null,"text":"However, since the agent also outputs tool call results, the terminal output can become quite verbose — making it difficult to follow the conversation as it grows.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_145":{"__typename":"Paragraph","id":"437c65dda6a1_145","name":"b6de","type":"P","href":null,"layout":null,"metadata":null,"text":"To improve usability, I built a web user interface using Streamlit, which not only provides an interactive chat interface but also allows dynamic parameter tuning for LLM response generation, making it easier to conduct further experiments.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*VD6NT36bb9eronIadaI94g.png":{"__typename":"ImageMetadata","id":"1*VD6NT36bb9eronIadaI94g.png","originalHeight":1468,"originalWidth":1278,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_146":{"__typename":"Paragraph","id":"437c65dda6a1_146","name":"776b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*VD6NT36bb9eronIadaI94g.png"},"text":"Agent Chat Web Interface (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_147":{"__typename":"Paragraph","id":"437c65dda6a1_147","name":"2c14","type":"P","href":null,"layout":null,"metadata":null,"text":"Details of the script are beyond the scope of this article. If you’re interested, please check out the implementation in the GitHub repository.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_148":{"__typename":"Paragraph","id":"437c65dda6a1_148","name":"fb6c","type":"H3","href":null,"layout":null,"metadata":null,"text":"4. Result","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_149":{"__typename":"Paragraph","id":"437c65dda6a1_149","name":"de04","type":"P","href":null,"layout":null,"metadata":null,"text":"There are two main ways to guide an AI model in deciding when to perform a tool call:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_150":{"__typename":"Paragraph","id":"437c65dda6a1_150","name":"a873","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Providing the tool instructions in the system prompt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_151":{"__typename":"Paragraph","id":"437c65dda6a1_151","name":"8d31","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Providing the tool instructions in the user prompt at request time","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_152":{"__typename":"Paragraph","id":"437c65dda6a1_152","name":"7b55","type":"P","href":null,"layout":null,"metadata":null,"text":"Remember the important note regarding zero-shot tool calling with Llama model?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_153":{"__typename":"Paragraph","id":"437c65dda6a1_153","name":"569c","type":"P","href":null,"layout":null,"metadata":null,"text":"For models smaller than 8B, including the tool schema in the prompt often leads to unstable conversations. To maintain consistent and coherent dialogue with the user, tool instructions should be omitted when working with small models.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_154":{"__typename":"Paragraph","id":"437c65dda6a1_154","name":"213f","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s now explore how the quality of the generated response differs depending on where the tool instruction is injected.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_155":{"__typename":"Paragraph","id":"437c65dda6a1_155","name":"fb08","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.1. Tool Instruction in System Prompt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_156":{"__typename":"Paragraph","id":"437c65dda6a1_156","name":"5f0a","type":"P","href":null,"layout":null,"metadata":null,"text":"We’ll begin by defining the tool instruction in the system prompt, as shown below, and observe the resulting response.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_157":{"__typename":"Paragraph","id":"437c65dda6a1_157","name":"05a2","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class Agent:\n    ...\n    async def init_agent(self):\n        ...\n        # instead of default system prompt, tool Instruction is used\n        p = self.prompt.get_system_prompt(TOOL_CALL_PROMPT.format(\n            function_scheme=self.func_scheme_prompt\n            ))  \n        \n        self.prompt.set_system_prompt(p)\n\n    ...\n    \n    async def chat(self, question:str, **kwargs) -\u003E list[AgentResponse]:\n        response_list = []\n        \n        # User prompt has only user query.\n        p = self.prompt.get_user_prompt(question=question)\n        self.prompt.append_history(p)\n        \n        response = self.llm.generate(...)\n        \n        if self._is_tool_required(response):\n            ...\n            result = await self.get_result_tool(response)\n            result = json.dumps(result, ensure_ascii=False)\n\n            p = self.prompt.get_tool_result_prompt(result=result)\n            self.prompt.append_history(p)\n\n            response = self.llm.generate(...)\n            ...\n\n        ...\n\n        return response_list","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_158":{"__typename":"Paragraph","id":"437c65dda6a1_158","name":"e248","type":"P","href":null,"layout":null,"metadata":null,"text":"While the AI model was generally accurate in identifying and invoking the correct tool as requested, it often failed to generate an ideal response during the synthesis step, where the tool result is incorporated into the final answer. The generated responses typically fell into two categories.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_159":{"__typename":"Paragraph","id":"437c65dda6a1_159","name":"c47b","type":"P","href":null,"layout":null,"metadata":null,"text":"The first case is an empty response, as shown below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*SLijCRhRnmLhT9YFZNgr8w.png":{"__typename":"ImageMetadata","id":"1*SLijCRhRnmLhT9YFZNgr8w.png","originalHeight":1118,"originalWidth":3497,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_160":{"__typename":"Paragraph","id":"437c65dda6a1_160","name":"3b4a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*SLijCRhRnmLhT9YFZNgr8w.png"},"text":"Case 1.1 Empty Response (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_161":{"__typename":"Paragraph","id":"437c65dda6a1_161","name":"f8ce","type":"P","href":null,"layout":null,"metadata":null,"text":"The second case involved the model becoming overly focused on tool calling, often issuing unnecessary or even malformed tool invocation requests.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_162":{"__typename":"Paragraph","id":"437c65dda6a1_162","name":"b358","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, in the case shown below, the user explicitly asked the model to retrieve information about a specific knowledge item.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_163":{"__typename":"Paragraph","id":"437c65dda6a1_163","name":"0b10","type":"P","href":null,"layout":null,"metadata":null,"text":"Although the model successfully accessed and extracted the requested knowledge, it unnecessarily attempted to invoke the list_knowledges() tool, which was irrelevant to the actual task.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":121,"end":138,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*DHw7cYPSSEe3bEGX_4ay7w.png":{"__typename":"ImageMetadata","id":"1*DHw7cYPSSEe3bEGX_4ay7w.png","originalHeight":684,"originalWidth":1072,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_164":{"__typename":"Paragraph","id":"437c65dda6a1_164","name":"6e59","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*DHw7cYPSSEe3bEGX_4ay7w.png"},"text":"Case 1.2 Tool Result Used Incorrectly in Final Response (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_165":{"__typename":"Paragraph","id":"437c65dda6a1_165","name":"6e02","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.2. Tool Instruction in User Prompt (Only at Request Time)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_166":{"__typename":"Paragraph","id":"437c65dda6a1_166","name":"e6b8","type":"P","href":null,"layout":null,"metadata":null,"text":"To address the issues observed earlier, I modified the approach by not exposing the tool instruction in every generation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_167":{"__typename":"Paragraph","id":"437c65dda6a1_167","name":"f5e7","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of including it in the system prompt at all times, the tool instruction is now only provided at the point where the model needs to decide whether a tool should be invoked, based on the user’s request.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_168":{"__typename":"Paragraph","id":"437c65dda6a1_168","name":"fcbb","type":"P","href":null,"layout":null,"metadata":null,"text":"The code below is identical to what was introduced in Section 3.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_169":{"__typename":"Paragraph","id":"437c65dda6a1_169","name":"9d2b","type":"P","href":null,"layout":null,"metadata":null,"text":"The key point here is the role of the tool_enabled parameter when calling the get_generation_prompt() method of the Prompt object.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":38,"end":50,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":78,"end":101,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":116,"end":122,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_170":{"__typename":"Paragraph","id":"437c65dda6a1_170","name":"fb71","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class Agent:\n    ...\n\n    async def chat(self, question:str, **kwargs) -\u003E list[AgentResponse]:\n        # Tool Scheme for providing How to call tool and which tool can be called\n        tool_scheme = TOOL_CALL_PROMPT.format(\n            function_scheme=self.func_scheme_prompt\n            )\n  \n        # 1. user query prompt\n        p = self.prompt.get_user_prompt(question=question, tool_scheme=tool_scheme)\n        self.prompt.append_history(p)\n\n        # 2. LLM response to user query\n        response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=True), ...)\n\n        if self._is_tool_required(response): # if tool pattern found\n            ...\n            p = self.prompt.get_assistant_prompt(answer=response)\n            self.prompt.append_history(p)\n\n            # 3. llm requires tool invoke\n            result = await self.get_result_tool(response)\n            result = json.dumps(result, ensure_ascii=False)\n\n            # 4. add result of tool-calling into the prompt\n            p = self.prompt.get_tool_result_prompt(result=result)\n            self.prompt.append_history(p)\n   \n            # 5. synthesize response with the tool-calling result\n            response = self.llm.generate(self.prompt.get_generation_prompt(tool_enabled=False), ...)\n\n        ...\n\n        return response_list","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_171":{"__typename":"Paragraph","id":"437c65dda6a1_171","name":"d230","type":"P","href":null,"layout":null,"metadata":null,"text":"Depending on the value of tool_enabled, the tool scheme is either included or omitted when constructing the prompt through the Prompt object.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":26,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":127,"end":133,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_172":{"__typename":"Paragraph","id":"437c65dda6a1_172","name":"8407","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class LLamaMessage(BaseMessage):\n    ...\n\n    def template(self, tool_enabled:bool=False) -\u003E str:\n        prompt = f\"\u003C|start_header_id|\u003E{self.role}\u003C|end_header_id|\u003E\"\n\n        if tool_enabled and self.tool_scheme:\n            prompt += f\"{self.tool_scheme}\"\n\n        if self.content:\n            prompt += f\"{self.content}\u003C|eot_id|\u003E\"\n\n        return prompt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_173":{"__typename":"Paragraph","id":"437c65dda6a1_173","name":"6b60","type":"P","href":null,"layout":null,"metadata":null,"text":"When constructing the prompt to be sent to the AI model, the agent conditionally exposes the tool instruction depending on the context.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_174":{"__typename":"Paragraph","id":"437c65dda6a1_174","name":"45d7","type":"P","href":null,"layout":null,"metadata":null,"text":"The instruction is included only during the initial response generation, when the model needs to decide whether a tool should be invoked.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_175":{"__typename":"Paragraph","id":"437c65dda6a1_175","name":"3730","type":"P","href":null,"layout":null,"metadata":null,"text":"During the final synthesis step — where the model generates a response based on the tool result and the user query — the instruction is intentionally omitted, to keep the output focused and coherent.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_176":{"__typename":"Paragraph","id":"437c65dda6a1_176","name":"3e5a","type":"P","href":null,"layout":null,"metadata":null,"text":"As shown in the results below, this approach leads to a notable improvement in response quality.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*FY8XbNSNZj9qvNCAsigXTQ.png":{"__typename":"ImageMetadata","id":"1*FY8XbNSNZj9qvNCAsigXTQ.png","originalHeight":1258,"originalWidth":1094,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_177":{"__typename":"Paragraph","id":"437c65dda6a1_177","name":"99e0","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*FY8XbNSNZj9qvNCAsigXTQ.png"},"text":"Case 2.1 Listing Registered Knowledges (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_178":{"__typename":"Paragraph","id":"437c65dda6a1_178","name":"a49c","type":"P","href":null,"layout":null,"metadata":null,"text":"Even when asking for the content of a specific knowledge item, the model produced a more relevant and focused response compared to when tool instructions were included in the system prompt.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*3lsh4p2gvvmACVuUmtWKGA.png":{"__typename":"ImageMetadata","id":"1*3lsh4p2gvvmACVuUmtWKGA.png","originalHeight":1066,"originalWidth":1088,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_179":{"__typename":"Paragraph","id":"437c65dda6a1_179","name":"faaf","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3lsh4p2gvvmACVuUmtWKGA.png"},"text":"Case 2.2 Retrieving the Content (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_180":{"__typename":"Paragraph","id":"437c65dda6a1_180","name":"4617","type":"P","href":null,"layout":null,"metadata":null,"text":"In cases where the tool call failed due to a typo in the URI, the Llama model still attempted to provide a helpful answer based on its internal knowledge, demonstrating graceful fallback behavior.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*TIECUWiu09EcyFSoF8F5iA.png":{"__typename":"ImageMetadata","id":"1*TIECUWiu09EcyFSoF8F5iA.png","originalHeight":1136,"originalWidth":1116,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_181":{"__typename":"Paragraph","id":"437c65dda6a1_181","name":"431a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*TIECUWiu09EcyFSoF8F5iA.png"},"text":"Case 2.3 When Retrieval Fails (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_182":{"__typename":"Paragraph","id":"437c65dda6a1_182","name":"febe","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.3. Practical Use Case","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_183":{"__typename":"Paragraph","id":"437c65dda6a1_183","name":"acbd","type":"P","href":null,"layout":null,"metadata":null,"text":"Now let’s see how well the agent performs the three core functions that originally motivated the development of the MCP Server.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_184":{"__typename":"Paragraph","id":"437c65dda6a1_184","name":"3594","type":"P","href":null,"layout":null,"metadata":null,"text":"In the first test, I asked the agent to retrieve a specific knowledge item and summarize it in Markdown format.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_185":{"__typename":"Paragraph","id":"437c65dda6a1_185","name":"ac5e","type":"P","href":null,"layout":null,"metadata":null,"text":"Although there were minor errors in the tool call, the model was able to format the note into a structured table based on its content size. Overall, the result was reasonably good.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*MyoIyrS8_5JBxLVKCOWFqg.png":{"__typename":"ImageMetadata","id":"1*MyoIyrS8_5JBxLVKCOWFqg.png","originalHeight":1278,"originalWidth":1100,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_186":{"__typename":"Paragraph","id":"437c65dda6a1_186","name":"9748","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*MyoIyrS8_5JBxLVKCOWFqg.png"},"text":"Summarizing a Registered Knowledge Notes (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_187":{"__typename":"Paragraph","id":"437c65dda6a1_187","name":"49ed","type":"P","href":null,"layout":null,"metadata":null,"text":"Next, I requested a list of notes that have a title but lack content.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_188":{"__typename":"Paragraph","id":"437c65dda6a1_188","name":"b57b","type":"P","href":null,"layout":null,"metadata":null,"text":"Again, the tool call was slightly off, but the model successfully identified knowledge entries with little to no content by inspecting their byte size.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_189":{"__typename":"Paragraph","id":"437c65dda6a1_189","name":"9b73","type":"P","href":null,"layout":null,"metadata":null,"text":"However, the result was only partially complete, with some relevant entries missing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*xipAwfxy2_1ZdqVH2XkMzw.png":{"__typename":"ImageMetadata","id":"1*xipAwfxy2_1ZdqVH2XkMzw.png","originalHeight":1066,"originalWidth":1092,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_190":{"__typename":"Paragraph","id":"437c65dda6a1_190","name":"52da","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xipAwfxy2_1ZdqVH2XkMzw.png"},"text":"Identifying Empty Knowledge Notes (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_191":{"__typename":"Paragraph","id":"437c65dda6a1_191","name":"1c2e","type":"P","href":null,"layout":null,"metadata":null,"text":"Lastly, I asked the model to generate short-answer review questions based on the content of a specific knowledge note.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_192":{"__typename":"Paragraph","id":"437c65dda6a1_192","name":"f733","type":"P","href":null,"layout":null,"metadata":null,"text":"Although the tool call had the same limitations as before 😅, the final response was well-structured and contextually appropriate.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GwDegW2i6Cd471xrNc5epQ.png":{"__typename":"ImageMetadata","id":"1*GwDegW2i6Cd471xrNc5epQ.png","originalHeight":1014,"originalWidth":1092,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:437c65dda6a1_193":{"__typename":"Paragraph","id":"437c65dda6a1_193","name":"61a6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GwDegW2i6Cd471xrNc5epQ.png"},"text":"Generating Short-Answer Question (Image by Author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_194":{"__typename":"Paragraph","id":"437c65dda6a1_194","name":"a1ec","type":"P","href":null,"layout":null,"metadata":null,"text":"While the agent doesn’t yet match the performance of Claude AI, it still produced impressively useful outputs — especially considering it runs entirely on a lightweight 3B model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_195":{"__typename":"Paragraph","id":"437c65dda6a1_195","name":"d12c","type":"P","href":null,"layout":null,"metadata":null,"text":"That said, the current version does not consistently generate perfect responses at all the time, and would require further improvements for practical use.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_196":{"__typename":"Paragraph","id":"437c65dda6a1_196","name":"d47c","type":"H3","href":null,"layout":null,"metadata":null,"text":"5. Challenges and My Thoughts","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_197":{"__typename":"Paragraph","id":"437c65dda6a1_197","name":"1257","type":"P","href":null,"layout":null,"metadata":null,"text":"After building and testing the agent across several use cases, I identified a few key challenges you should consider:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_198":{"__typename":"Paragraph","id":"437c65dda6a1_198","name":"d99b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Limitations of sLLM Performance","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_199":{"__typename":"Paragraph","id":"437c65dda6a1_199","name":"5599","type":"P","href":null,"layout":null,"metadata":null,"text":"The most fundamental limitation is the performance of small language models (sLLMs). Although the agent is designed to be model-agnostic and can work with larger models, it is primarily intended for use with lightweight sLLMs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_200":{"__typename":"Paragraph","id":"437c65dda6a1_200","name":"520e","type":"P","href":null,"layout":null,"metadata":null,"text":"Naturally, we shouldn’t expect general-purpose reasoning capabilities on par with larger models. Instead, sLLMs are better suited for specialized tasks with well-defined constraints.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_201":{"__typename":"Paragraph","id":"437c65dda6a1_201","name":"7c62","type":"P","href":null,"layout":null,"metadata":null,"text":"2. Over-Focus on Tool Invocation","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_202":{"__typename":"Paragraph","id":"437c65dda6a1_202","name":"c286","type":"P","href":null,"layout":null,"metadata":null,"text":"When tool instructions are injected into prompts for lightweight models, the model tends to become overly focused on calling tools, even when it’s not necessary. For example, even after retrieving a list of knowledge items in a previous step, the model would often ignore that context and issue redundant tool calls.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_203":{"__typename":"Paragraph","id":"437c65dda6a1_203","name":"07b6","type":"P","href":null,"layout":null,"metadata":null,"text":"This suggests a need for dynamic prompt control, where the tool instruction is only included based on the query.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_204":{"__typename":"Paragraph","id":"437c65dda6a1_204","name":"b0c9","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Weakness in Iterative Tool Use","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_205":{"__typename":"Paragraph","id":"437c65dda6a1_205","name":"d265","type":"P","href":null,"layout":null,"metadata":null,"text":"Compared to larger models, lightweight Llama models showed limited capability in iterative tool usage. In my earlier experiments with Claude, the model issued tool calls for every knowledge note when searching for empty ones. In contrast, the Llama-3.2–3B-Instruct model typically stopped after one or two invocations, even when more were needed.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_206":{"__typename":"Paragraph","id":"437c65dda6a1_206","name":"062f","type":"P","href":null,"layout":null,"metadata":null,"text":"While this may vary depending on how the prompt is structured, it highlights a constraint in smaller model’s ability to perform multi-step reasoning with tool feedback loops.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_207":{"__typename":"Paragraph","id":"437c65dda6a1_207","name":"58aa","type":"P","href":null,"layout":null,"metadata":null,"text":"Despite these limitations, Meta’s lightweight Llama models demonstrate impressive performance relative to their size, both in inference speed and response quality.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_208":{"__typename":"Paragraph","id":"437c65dda6a1_208","name":"b218","type":"P","href":null,"layout":null,"metadata":null,"text":"While they may not be ideal for general-purpose agents, sLLMs remain a strong choice for domain-specific applications with constrained requirements.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:437c65dda6a1_209":{"__typename":"Paragraph","id":"437c65dda6a1_209","name":"3cd0","type":"P","href":null,"layout":null,"metadata":null,"text":"Any feedback about this article or the source code is welcome. If you are interested in future articles, just follow me. If you want to discuss further topics, feel free to connect with me on LinkedIn.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":192,"end":200,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fhyunjong-lee-67913814a\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:5517fd7b58a6-viewerId:lo_165a71c26036":{"__typename":"CollectionViewerEdge","id":"collectionId:5517fd7b58a6-viewerId:lo_165a71c26036","isEditor":false,"isMuting":false,"canEditOwnPosts":false,"canEditPosts":false,"isFollowing":false,"isSubscribedToLetters":false,"isSubscribedToMediumNewsletter":false,"isSubscribedToEmails":false,"isWriter":false},"UserViewerEdge:userId:ecf7619248d7-viewerId:lo_165a71c26036":{"__typename":"UserViewerEdge","id":"userId:ecf7619248d7-viewerId:lo_165a71c26036","isMuting":false},"ImageMetadata:1*s0Iaylh9dPk6zGjlVZasIA.jpeg":{"__typename":"ImageMetadata","id":"1*s0Iaylh9dPk6zGjlVZasIA.jpeg","originalWidth":2842,"originalHeight":625},"PostViewerEdge:postId:3bc057d27e85-viewerId:lo_165a71c26036":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:3bc057d27e85-viewerId:lo_165a71c26036"},"Tag:mcp-server":{"__typename":"Tag","id":"mcp-server","displayTitle":"Mcp Server","normalizedTagSlug":"mcp-server"},"Tag:agents":{"__typename":"Tag","id":"agents","displayTitle":"Agents","normalizedTagSlug":"agents"},"Tag:llama-3":{"__typename":"Tag","id":"llama-3","displayTitle":"Llama 3","normalizedTagSlug":"llama-3"},"Tag:obsidian":{"__typename":"Tag","id":"obsidian","displayTitle":"Obsidian","normalizedTagSlug":"obsidian"},"Tag:ai":{"__typename":"Tag","id":"ai","displayTitle":"AI","normalizedTagSlug":"ai"},"Post:3bc057d27e85":{"__typename":"Post","id":"3bc057d27e85","collection":{"__ref":"Collection:5517fd7b58a6"},"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"67fd","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"1fc6","startIndex":209,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:437c65dda6a1_0"},{"__ref":"Paragraph:437c65dda6a1_1"},{"__ref":"Paragraph:437c65dda6a1_2"},{"__ref":"Paragraph:437c65dda6a1_3"},{"__ref":"Paragraph:437c65dda6a1_4"},{"__ref":"Paragraph:437c65dda6a1_5"},{"__ref":"Paragraph:437c65dda6a1_6"},{"__ref":"Paragraph:437c65dda6a1_7"},{"__ref":"Paragraph:437c65dda6a1_8"},{"__ref":"Paragraph:437c65dda6a1_9"},{"__ref":"Paragraph:437c65dda6a1_10"},{"__ref":"Paragraph:437c65dda6a1_11"},{"__ref":"Paragraph:437c65dda6a1_12"},{"__ref":"Paragraph:437c65dda6a1_13"},{"__ref":"Paragraph:437c65dda6a1_14"},{"__ref":"Paragraph:437c65dda6a1_15"},{"__ref":"Paragraph:437c65dda6a1_16"},{"__ref":"Paragraph:437c65dda6a1_17"},{"__ref":"Paragraph:437c65dda6a1_18"},{"__ref":"Paragraph:437c65dda6a1_19"},{"__ref":"Paragraph:437c65dda6a1_20"},{"__ref":"Paragraph:437c65dda6a1_21"},{"__ref":"Paragraph:437c65dda6a1_22"},{"__ref":"Paragraph:437c65dda6a1_23"},{"__ref":"Paragraph:437c65dda6a1_24"},{"__ref":"Paragraph:437c65dda6a1_25"},{"__ref":"Paragraph:437c65dda6a1_26"},{"__ref":"Paragraph:437c65dda6a1_27"},{"__ref":"Paragraph:437c65dda6a1_28"},{"__ref":"Paragraph:437c65dda6a1_29"},{"__ref":"Paragraph:437c65dda6a1_30"},{"__ref":"Paragraph:437c65dda6a1_31"},{"__ref":"Paragraph:437c65dda6a1_32"},{"__ref":"Paragraph:437c65dda6a1_33"},{"__ref":"Paragraph:437c65dda6a1_34"},{"__ref":"Paragraph:437c65dda6a1_35"},{"__ref":"Paragraph:437c65dda6a1_36"},{"__ref":"Paragraph:437c65dda6a1_37"},{"__ref":"Paragraph:437c65dda6a1_38"},{"__ref":"Paragraph:437c65dda6a1_39"},{"__ref":"Paragraph:437c65dda6a1_40"},{"__ref":"Paragraph:437c65dda6a1_41"},{"__ref":"Paragraph:437c65dda6a1_42"},{"__ref":"Paragraph:437c65dda6a1_43"},{"__ref":"Paragraph:437c65dda6a1_44"},{"__ref":"Paragraph:437c65dda6a1_45"},{"__ref":"Paragraph:437c65dda6a1_46"},{"__ref":"Paragraph:437c65dda6a1_47"},{"__ref":"Paragraph:437c65dda6a1_48"},{"__ref":"Paragraph:437c65dda6a1_49"},{"__ref":"Paragraph:437c65dda6a1_50"},{"__ref":"Paragraph:437c65dda6a1_51"},{"__ref":"Paragraph:437c65dda6a1_52"},{"__ref":"Paragraph:437c65dda6a1_53"},{"__ref":"Paragraph:437c65dda6a1_54"},{"__ref":"Paragraph:437c65dda6a1_55"},{"__ref":"Paragraph:437c65dda6a1_56"},{"__ref":"Paragraph:437c65dda6a1_57"},{"__ref":"Paragraph:437c65dda6a1_58"},{"__ref":"Paragraph:437c65dda6a1_59"},{"__ref":"Paragraph:437c65dda6a1_60"},{"__ref":"Paragraph:437c65dda6a1_61"},{"__ref":"Paragraph:437c65dda6a1_62"},{"__ref":"Paragraph:437c65dda6a1_63"},{"__ref":"Paragraph:437c65dda6a1_64"},{"__ref":"Paragraph:437c65dda6a1_65"},{"__ref":"Paragraph:437c65dda6a1_66"},{"__ref":"Paragraph:437c65dda6a1_67"},{"__ref":"Paragraph:437c65dda6a1_68"},{"__ref":"Paragraph:437c65dda6a1_69"},{"__ref":"Paragraph:437c65dda6a1_70"},{"__ref":"Paragraph:437c65dda6a1_71"},{"__ref":"Paragraph:437c65dda6a1_72"},{"__ref":"Paragraph:437c65dda6a1_73"},{"__ref":"Paragraph:437c65dda6a1_74"},{"__ref":"Paragraph:437c65dda6a1_75"},{"__ref":"Paragraph:437c65dda6a1_76"},{"__ref":"Paragraph:437c65dda6a1_77"},{"__ref":"Paragraph:437c65dda6a1_78"},{"__ref":"Paragraph:437c65dda6a1_79"},{"__ref":"Paragraph:437c65dda6a1_80"},{"__ref":"Paragraph:437c65dda6a1_81"},{"__ref":"Paragraph:437c65dda6a1_82"},{"__ref":"Paragraph:437c65dda6a1_83"},{"__ref":"Paragraph:437c65dda6a1_84"},{"__ref":"Paragraph:437c65dda6a1_85"},{"__ref":"Paragraph:437c65dda6a1_86"},{"__ref":"Paragraph:437c65dda6a1_87"},{"__ref":"Paragraph:437c65dda6a1_88"},{"__ref":"Paragraph:437c65dda6a1_89"},{"__ref":"Paragraph:437c65dda6a1_90"},{"__ref":"Paragraph:437c65dda6a1_91"},{"__ref":"Paragraph:437c65dda6a1_92"},{"__ref":"Paragraph:437c65dda6a1_93"},{"__ref":"Paragraph:437c65dda6a1_94"},{"__ref":"Paragraph:437c65dda6a1_95"},{"__ref":"Paragraph:437c65dda6a1_96"},{"__ref":"Paragraph:437c65dda6a1_97"},{"__ref":"Paragraph:437c65dda6a1_98"},{"__ref":"Paragraph:437c65dda6a1_99"},{"__ref":"Paragraph:437c65dda6a1_100"},{"__ref":"Paragraph:437c65dda6a1_101"},{"__ref":"Paragraph:437c65dda6a1_102"},{"__ref":"Paragraph:437c65dda6a1_103"},{"__ref":"Paragraph:437c65dda6a1_104"},{"__ref":"Paragraph:437c65dda6a1_105"},{"__ref":"Paragraph:437c65dda6a1_106"},{"__ref":"Paragraph:437c65dda6a1_107"},{"__ref":"Paragraph:437c65dda6a1_108"},{"__ref":"Paragraph:437c65dda6a1_109"},{"__ref":"Paragraph:437c65dda6a1_110"},{"__ref":"Paragraph:437c65dda6a1_111"},{"__ref":"Paragraph:437c65dda6a1_112"},{"__ref":"Paragraph:437c65dda6a1_113"},{"__ref":"Paragraph:437c65dda6a1_114"},{"__ref":"Paragraph:437c65dda6a1_115"},{"__ref":"Paragraph:437c65dda6a1_116"},{"__ref":"Paragraph:437c65dda6a1_117"},{"__ref":"Paragraph:437c65dda6a1_118"},{"__ref":"Paragraph:437c65dda6a1_119"},{"__ref":"Paragraph:437c65dda6a1_120"},{"__ref":"Paragraph:437c65dda6a1_121"},{"__ref":"Paragraph:437c65dda6a1_122"},{"__ref":"Paragraph:437c65dda6a1_123"},{"__ref":"Paragraph:437c65dda6a1_124"},{"__ref":"Paragraph:437c65dda6a1_125"},{"__ref":"Paragraph:437c65dda6a1_126"},{"__ref":"Paragraph:437c65dda6a1_127"},{"__ref":"Paragraph:437c65dda6a1_128"},{"__ref":"Paragraph:437c65dda6a1_129"},{"__ref":"Paragraph:437c65dda6a1_130"},{"__ref":"Paragraph:437c65dda6a1_131"},{"__ref":"Paragraph:437c65dda6a1_132"},{"__ref":"Paragraph:437c65dda6a1_133"},{"__ref":"Paragraph:437c65dda6a1_134"},{"__ref":"Paragraph:437c65dda6a1_135"},{"__ref":"Paragraph:437c65dda6a1_136"},{"__ref":"Paragraph:437c65dda6a1_137"},{"__ref":"Paragraph:437c65dda6a1_138"},{"__ref":"Paragraph:437c65dda6a1_139"},{"__ref":"Paragraph:437c65dda6a1_140"},{"__ref":"Paragraph:437c65dda6a1_141"},{"__ref":"Paragraph:437c65dda6a1_142"},{"__ref":"Paragraph:437c65dda6a1_143"},{"__ref":"Paragraph:437c65dda6a1_144"},{"__ref":"Paragraph:437c65dda6a1_145"},{"__ref":"Paragraph:437c65dda6a1_146"},{"__ref":"Paragraph:437c65dda6a1_147"},{"__ref":"Paragraph:437c65dda6a1_148"},{"__ref":"Paragraph:437c65dda6a1_149"},{"__ref":"Paragraph:437c65dda6a1_150"},{"__ref":"Paragraph:437c65dda6a1_151"},{"__ref":"Paragraph:437c65dda6a1_152"},{"__ref":"Paragraph:437c65dda6a1_153"},{"__ref":"Paragraph:437c65dda6a1_154"},{"__ref":"Paragraph:437c65dda6a1_155"},{"__ref":"Paragraph:437c65dda6a1_156"},{"__ref":"Paragraph:437c65dda6a1_157"},{"__ref":"Paragraph:437c65dda6a1_158"},{"__ref":"Paragraph:437c65dda6a1_159"},{"__ref":"Paragraph:437c65dda6a1_160"},{"__ref":"Paragraph:437c65dda6a1_161"},{"__ref":"Paragraph:437c65dda6a1_162"},{"__ref":"Paragraph:437c65dda6a1_163"},{"__ref":"Paragraph:437c65dda6a1_164"},{"__ref":"Paragraph:437c65dda6a1_165"},{"__ref":"Paragraph:437c65dda6a1_166"},{"__ref":"Paragraph:437c65dda6a1_167"},{"__ref":"Paragraph:437c65dda6a1_168"},{"__ref":"Paragraph:437c65dda6a1_169"},{"__ref":"Paragraph:437c65dda6a1_170"},{"__ref":"Paragraph:437c65dda6a1_171"},{"__ref":"Paragraph:437c65dda6a1_172"},{"__ref":"Paragraph:437c65dda6a1_173"},{"__ref":"Paragraph:437c65dda6a1_174"},{"__ref":"Paragraph:437c65dda6a1_175"},{"__ref":"Paragraph:437c65dda6a1_176"},{"__ref":"Paragraph:437c65dda6a1_177"},{"__ref":"Paragraph:437c65dda6a1_178"},{"__ref":"Paragraph:437c65dda6a1_179"},{"__ref":"Paragraph:437c65dda6a1_180"},{"__ref":"Paragraph:437c65dda6a1_181"},{"__ref":"Paragraph:437c65dda6a1_182"},{"__ref":"Paragraph:437c65dda6a1_183"},{"__ref":"Paragraph:437c65dda6a1_184"},{"__ref":"Paragraph:437c65dda6a1_185"},{"__ref":"Paragraph:437c65dda6a1_186"},{"__ref":"Paragraph:437c65dda6a1_187"},{"__ref":"Paragraph:437c65dda6a1_188"},{"__ref":"Paragraph:437c65dda6a1_189"},{"__ref":"Paragraph:437c65dda6a1_190"},{"__ref":"Paragraph:437c65dda6a1_191"},{"__ref":"Paragraph:437c65dda6a1_192"},{"__ref":"Paragraph:437c65dda6a1_193"},{"__ref":"Paragraph:437c65dda6a1_194"},{"__ref":"Paragraph:437c65dda6a1_195"},{"__ref":"Paragraph:437c65dda6a1_196"},{"__ref":"Paragraph:437c65dda6a1_197"},{"__ref":"Paragraph:437c65dda6a1_198"},{"__ref":"Paragraph:437c65dda6a1_199"},{"__ref":"Paragraph:437c65dda6a1_200"},{"__ref":"Paragraph:437c65dda6a1_201"},{"__ref":"Paragraph:437c65dda6a1_202"},{"__ref":"Paragraph:437c65dda6a1_203"},{"__ref":"Paragraph:437c65dda6a1_204"},{"__ref":"Paragraph:437c65dda6a1_205"},{"__ref":"Paragraph:437c65dda6a1_206"},{"__ref":"Paragraph:437c65dda6a1_207"},{"__ref":"Paragraph:437c65dda6a1_208"},{"__ref":"Paragraph:437c65dda6a1_209"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:ecf7619248d7"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85","primaryTopic":null,"topics":[],"isLimitedState":false,"isPublished":true,"allowResponses":true,"responsesLocked":false,"visibility":"PUBLIC","latestPublishedVersion":"437c65dda6a1","postResponses":{"__typename":"PostResponses","count":3},"responseDistribution":"NOT_DISTRIBUTED","clapCount":220,"title":"How I Built a Tool-Calling Llama Agent with a Custom MCP Server","isSeries":false,"sequence":null,"uniqueSlug":"how-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85","socialTitle":"","socialDek":"","canonicalUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Fhow-i-built-a-tool-calling-llama-agent-with-a-custom-mcp-server-3bc057d27e85","metaDescription":"","latestPublishedAt":1747622762217,"readingTime":21.566981132075473,"previewContent":{"__typename":"PreviewContent","subtitle":"Integrating sLLMs, tool-calling, and custom context retrieval via a private MCP server"},"previewImage":{"__ref":"ImageMetadata:1*atue7XX9h3JTZxhJQuGyxg.png"},"isShortform":false,"seoTitle":"","firstPublishedAt":1747622762217,"updatedAt":1747707988948,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"Learn how to build a local tool-calling LLM agent using Llama 3.2 and a custom MCP server that connects to your personal knowledge base in Obsidian.","viewerEdge":{"__ref":"PostViewerEdge:postId:3bc057d27e85-viewerId:lo_165a71c26036"},"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:mcp-server"},{"__ref":"Tag:agents"},{"__ref":"Tag:llama-3"},{"__ref":"Tag:obsidian"},{"__ref":"Tag:ai"}],"isFeaturedInPublishedPublication":false,"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":5331,"layerCake":1}}</script><script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/manifest.85303e54.js"></script><script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3728.d91f1a0b.js"></script><script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/main.ef73f2e9.js"></script><script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/instrumentation.5007fa9c.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/reporting.e6195768.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/8813.35e55d5c.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/5049.d1ead72d.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/8384.cce0ff92.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/4237.d8c83b38.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/9363.16f65619.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3326.69979fdb.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/7566.c890d213.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/7908.e2424828.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3927.11868a5f.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/8640.a9a2b354.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3191.1014e1e8.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/6372.ee399581.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/7381.21ce652a.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/5429.581e8802.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/5522.32d53933.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/5660.3597cce6.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/4929.13ddd402.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1528.2d922715.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/6834.d8976f5b.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/7979.0797fab1.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/7975.a122a8cf.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3877.f2021045.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/9256.470d9186.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/144.bdab81eb.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3666.95c1034a.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1922.cf4de1a6.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/1069.22883f04.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3523.1fe5b47b.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/PostPage.MainContent.37a99d57.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/2698.a5c8f865.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/3974.60b62858.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/2527.01f84a0f.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/PostResponsesContent.828e7373.chunk.js"></script>
<script src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/responses.editor.aac0754e.chunk.js"></script><script>window.main();</script><deepl-input-controller translate="no"><template shadowrootmode="open"><link rel="stylesheet" href="chrome-extension://cofdbpoegempjloogbagkncekinflcnj/build/content.css"><div dir="ltr" style="visibility: initial !important;"><div class="dl-input-translation-container svelte-95aucy"><div></div></div></div></template></deepl-input-controller><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-fxc0uzespp4i" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./How I Built a Tool-Calling Llama Agent with a Custom MCP Server _ by Hyunjong Lee _ May, 2025 _ Level Up Coding_files/saved_resource.html"></iframe></div></body></html>